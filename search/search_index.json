{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to WorkFlow Launcher \u2693\ufe0e Overview \u2693\ufe0e WorkFlow Launcher (WFL) is a workload manager. For example, a workload could be a set of Whole Genome samples to be reprocessed in a given project/bucket, the workflow is the processing of an individual sample in that workload running WGS reprocessing; a workload could also be a queue of incoming notifications that describe all of the required inputs to launch Arrays scientific pipelines in Cromwell. Most recent efforts leverage the general applicability of a staged workload model which automates fetching data from a source , pushing it into a workflow executor for analysis, and delivering the results of the analysis to an output location (also known as a sink ). WFL is designed to be deployed to run as a service in the cloud, primarily on Kubernetes clusters. For more on Workflow Launcher's role in the Terra infrastructure see Workflow Launcher's role in Terra . Quickstart \u2693\ufe0e Tip This is the Quickstart section, which should cover the most frequent uses cases that interact with WFL. For more detailed information, please check other sections such as the development guide or modules design principles . Build \u2693\ufe0e The easiest way to build WFL is via make , in addition, the following prerequisites are needed: The Docker daemon Clojure ( brew install clojure on macOS) Python3 ( brew install python@3.9 on macOS) NodeJS ( brew install node on macOS) Google Cloud SDK ( brew install --cask google-cloud-sdk on macOS) Arch Linux tips Install clojure from the official repository. Install google-cloud-sdk from the AUR. You could then invoke make at the project level to test and build all workflow-launcher modules: $ make -j8 where 8 can be replaced by any number that represents the concurrent jobs you wish to run. Info If the version of your make is above GNU Make 4.0 (you could check by running make --version ), it's highly recommended to use --output-sync along with -j so the standard outputs are sorted, i.e. $ make -j8 --output-sync make will build each module in workflow-launcher , run tests and generate Docker images. All generated files go into a derived directory under the project root. You can also invoke make on a module from the top level directory by $ make [ MODULE ] TARGET ={ prebuild | build | check | images | clean | distclean } where currently available MODULE s are {api functions/aou docs helm ui} For most of the time, you would want to run something like: $ make clean to clean up the built modules ( -j8 is also available for make clean ). and then run: $ make ui api TARGET = images -j8 to only build the WFL and its docker images without running tests. Info Note if you updated the second party repositories such as pipeline-config or gotc-deploy , you might have to run: $ make distclean to remove them. This is not always needed but can help completely purge the local derived files. Test \u2693\ufe0e If you only want to run tests on specific modules, you could run: $ make [ MODULE ] TARGET = check such as make api TARGET=check or make functions/aou TARGET=check . Note this automatically makes all of check 's prerequisites. Clojure Test \u2693\ufe0e When it comes to clojure tests, sometimes it's useful to only run a subset of tests to save time and filter out noise. You can do this by directly invoke clojure cli from within the api directory, for example, cd api and: $ clojure -M:test integration --focus wfl.integration.modules.copyfile-test In general, we implement Clojure tests under the test/ root directory and use the kaocha test runner. Test suites use a -test namespace suffix. You can pass extra command line arguments to kaocha , such as the above --focus flag. You can see the full list of options with the following: clojure -M:test --help At present, wfl api has three kinds of test, unit , integration , and system . These can be run via the deps.edn , optionally specifying the kind: clojure -M:test [ unit | integration | system ] Note that the integration tests currently require a little more configuration before they can be run, namely, they require a wfl server running locally: ./ops/server.sh Additionally, there is a custom parallel test runner that can be invoked to help speed up the system tests. Rather than clojure -M:test system you'd just specify the namespace(s) to try to parallelize. clojure -M:parallel-test wfl.system.v1-endpoint-test Info Note for system tests, no matter it's kicked off through clojure -M:test system or clojure -M:parallel-test wfl.system.v1-endpoint-test , you can use an environment variable WFL_CROMWELL_URL to override the default Cromwell instance that's used in the test. For example: WFL_CROMWELL_URL = https://cromwell-gotc-auth.gotc-prod.broadinstitute.org/ clojure -M:parallel-test wfl.system.v1-endpoint-test will tell the test to submit workflows to the \"gotc-prod\" Cromwell instance no matter what the default instance was defined in the test. However, you need to make sure the validity of the Cromwell URL you passed in; certain IAM permissions will also be required in order for Cromwell to execute the testing workflows smoothly. Deploy \u2693\ufe0e Currently, we mainly deploy WFL to broad-gotc-dev and broad-gotc-prod projects. When it's time to deploy WFL, for most of the time developers need to release a new version following the steps in Release Guide After which, the developers who have broad VPN connected can go to the Jenkins Page to deploy applicable versions of WFL to various available cloud projects. Implementation \u2693\ufe0e Top-level files \u2693\ufe0e After cloning a new WFL repo, the top-level files are: . \u251c\u2500\u2500 api/ - `workflow-launcher` backend \u251c\u2500\u2500 functions/ - cloud functions deployed separately \u251c\u2500\u2500 database/ - database scheme migration changelog and changeset \u251c\u2500\u2500 derived/ - generated artifacts \u251c\u2500\u2500 docs/ - ancillary documentation \u251c\u2500\u2500 helm/ - helm-managed k8s configuration \u251c\u2500\u2500 LICENSE.txt \u251c\u2500\u2500 Makefile - project level` Makefile` \u251c\u2500\u2500 makerules/ - common `Makefile` functionality \u251c\u2500\u2500 ops/ - scripts to support Operations \u251c\u2500\u2500 README.md - symbolic link to docs/md/README.md \u2514\u2500\u2500 version - holds the current semantic version Tip: Run make at least once after cloning the repo to make sure all the necessary files are in place. api Module \u2693\ufe0e Source code \u2693\ufe0e The Clojure source code is in the api/src/ directory. The entry point for the WFL executable is the -main function in main.clj . It takes the command line arguments as strings, validates the arguments, then launches the appropriate process. The server.clj file implements the WFL server. The server_debug.clj file adds some tools to aid in debugging the server. Some hacks specific to WFL are in wfl.clj . The build.clj file includes build and deployment code. The debug.clj file defines some macros useful when debugging or logging. The util.clj file contains a few functions and macros used in WFL that are not specific to its function. The environments.clj file defines configuration parameters for different execution contexts. It's a placeholder in this repo but will be loaded in build/deploy time from a private repo. The module/xx.clj file implements a command-line starter for reprocessing eXternal eXomes . The module/wgs.clj file helps implements a command-line starter for reprocessing Whole GenomeS . The module/sg.clj file implements Somatic Genomes support. The module/all.clj file hosts some utilities shared across modules. The metadata.clj file implements a tool to extract metadata from Cromwell that can be archived with the outputs generated by a workflow. The dx.clj file implements miscellaneous pipeline debugging tools. The once.clj file defines some initialization functions mostly supporting authentication. The api/handlers.clj file defines the handler functions used by server. The api/routes.clj file defines the routing strategy for server. Each of the other source files implement an interface to one of the services WFL talks to, and are named accordingly. File Service cromwell.clj Cromwell workflow runner datarepo.clj DSP DataRepo db.clj On-prem and Cloud SQL databases gcs.clj Google Cloud Storage jms.clj Java Message Service queues postgres.clj Cloud SQL postgres databases server.clj the WFL server itself Exomes in the Cloud Resources \u2693\ufe0e From Hybrid Selection in the Cloud V1 Clients Google Cloud Storage Client Library (Java) Google Cloud Client Library for Java Diagrams Zamboni Overview Sources /Users/tbl/Broad/zamboni/Client/src/scala/org/broadinstitute/zamboni/client/lightning/clp/Lightning.scala /Users/tbl/Broad/picard-private/src/java/edu/mit/broad/picard/lightning /Users/tbl/Broad/gppipeline-devtools/release client /Users/tbl/Broad/gppipeline-devtools/starter control /picard02:/seq/pipeline/gppipeline-devtools/current/defs/prod.defs","title":"Get Started"},{"location":"#welcome-to-workflow-launcher","text":"","title":"Welcome to WorkFlow Launcher"},{"location":"#overview","text":"WorkFlow Launcher (WFL) is a workload manager. For example, a workload could be a set of Whole Genome samples to be reprocessed in a given project/bucket, the workflow is the processing of an individual sample in that workload running WGS reprocessing; a workload could also be a queue of incoming notifications that describe all of the required inputs to launch Arrays scientific pipelines in Cromwell. Most recent efforts leverage the general applicability of a staged workload model which automates fetching data from a source , pushing it into a workflow executor for analysis, and delivering the results of the analysis to an output location (also known as a sink ). WFL is designed to be deployed to run as a service in the cloud, primarily on Kubernetes clusters. For more on Workflow Launcher's role in the Terra infrastructure see Workflow Launcher's role in Terra .","title":"Overview"},{"location":"#quickstart","text":"Tip This is the Quickstart section, which should cover the most frequent uses cases that interact with WFL. For more detailed information, please check other sections such as the development guide or modules design principles .","title":"Quickstart"},{"location":"#build","text":"The easiest way to build WFL is via make , in addition, the following prerequisites are needed: The Docker daemon Clojure ( brew install clojure on macOS) Python3 ( brew install python@3.9 on macOS) NodeJS ( brew install node on macOS) Google Cloud SDK ( brew install --cask google-cloud-sdk on macOS) Arch Linux tips Install clojure from the official repository. Install google-cloud-sdk from the AUR. You could then invoke make at the project level to test and build all workflow-launcher modules: $ make -j8 where 8 can be replaced by any number that represents the concurrent jobs you wish to run. Info If the version of your make is above GNU Make 4.0 (you could check by running make --version ), it's highly recommended to use --output-sync along with -j so the standard outputs are sorted, i.e. $ make -j8 --output-sync make will build each module in workflow-launcher , run tests and generate Docker images. All generated files go into a derived directory under the project root. You can also invoke make on a module from the top level directory by $ make [ MODULE ] TARGET ={ prebuild | build | check | images | clean | distclean } where currently available MODULE s are {api functions/aou docs helm ui} For most of the time, you would want to run something like: $ make clean to clean up the built modules ( -j8 is also available for make clean ). and then run: $ make ui api TARGET = images -j8 to only build the WFL and its docker images without running tests. Info Note if you updated the second party repositories such as pipeline-config or gotc-deploy , you might have to run: $ make distclean to remove them. This is not always needed but can help completely purge the local derived files.","title":"Build"},{"location":"#test","text":"If you only want to run tests on specific modules, you could run: $ make [ MODULE ] TARGET = check such as make api TARGET=check or make functions/aou TARGET=check . Note this automatically makes all of check 's prerequisites.","title":"Test"},{"location":"#clojure-test","text":"When it comes to clojure tests, sometimes it's useful to only run a subset of tests to save time and filter out noise. You can do this by directly invoke clojure cli from within the api directory, for example, cd api and: $ clojure -M:test integration --focus wfl.integration.modules.copyfile-test In general, we implement Clojure tests under the test/ root directory and use the kaocha test runner. Test suites use a -test namespace suffix. You can pass extra command line arguments to kaocha , such as the above --focus flag. You can see the full list of options with the following: clojure -M:test --help At present, wfl api has three kinds of test, unit , integration , and system . These can be run via the deps.edn , optionally specifying the kind: clojure -M:test [ unit | integration | system ] Note that the integration tests currently require a little more configuration before they can be run, namely, they require a wfl server running locally: ./ops/server.sh Additionally, there is a custom parallel test runner that can be invoked to help speed up the system tests. Rather than clojure -M:test system you'd just specify the namespace(s) to try to parallelize. clojure -M:parallel-test wfl.system.v1-endpoint-test Info Note for system tests, no matter it's kicked off through clojure -M:test system or clojure -M:parallel-test wfl.system.v1-endpoint-test , you can use an environment variable WFL_CROMWELL_URL to override the default Cromwell instance that's used in the test. For example: WFL_CROMWELL_URL = https://cromwell-gotc-auth.gotc-prod.broadinstitute.org/ clojure -M:parallel-test wfl.system.v1-endpoint-test will tell the test to submit workflows to the \"gotc-prod\" Cromwell instance no matter what the default instance was defined in the test. However, you need to make sure the validity of the Cromwell URL you passed in; certain IAM permissions will also be required in order for Cromwell to execute the testing workflows smoothly.","title":"Clojure Test"},{"location":"#deploy","text":"Currently, we mainly deploy WFL to broad-gotc-dev and broad-gotc-prod projects. When it's time to deploy WFL, for most of the time developers need to release a new version following the steps in Release Guide After which, the developers who have broad VPN connected can go to the Jenkins Page to deploy applicable versions of WFL to various available cloud projects.","title":"Deploy"},{"location":"#implementation","text":"","title":"Implementation"},{"location":"#top-level-files","text":"After cloning a new WFL repo, the top-level files are: . \u251c\u2500\u2500 api/ - `workflow-launcher` backend \u251c\u2500\u2500 functions/ - cloud functions deployed separately \u251c\u2500\u2500 database/ - database scheme migration changelog and changeset \u251c\u2500\u2500 derived/ - generated artifacts \u251c\u2500\u2500 docs/ - ancillary documentation \u251c\u2500\u2500 helm/ - helm-managed k8s configuration \u251c\u2500\u2500 LICENSE.txt \u251c\u2500\u2500 Makefile - project level` Makefile` \u251c\u2500\u2500 makerules/ - common `Makefile` functionality \u251c\u2500\u2500 ops/ - scripts to support Operations \u251c\u2500\u2500 README.md - symbolic link to docs/md/README.md \u2514\u2500\u2500 version - holds the current semantic version Tip: Run make at least once after cloning the repo to make sure all the necessary files are in place.","title":"Top-level files"},{"location":"#api-module","text":"","title":"api Module"},{"location":"#source-code","text":"The Clojure source code is in the api/src/ directory. The entry point for the WFL executable is the -main function in main.clj . It takes the command line arguments as strings, validates the arguments, then launches the appropriate process. The server.clj file implements the WFL server. The server_debug.clj file adds some tools to aid in debugging the server. Some hacks specific to WFL are in wfl.clj . The build.clj file includes build and deployment code. The debug.clj file defines some macros useful when debugging or logging. The util.clj file contains a few functions and macros used in WFL that are not specific to its function. The environments.clj file defines configuration parameters for different execution contexts. It's a placeholder in this repo but will be loaded in build/deploy time from a private repo. The module/xx.clj file implements a command-line starter for reprocessing eXternal eXomes . The module/wgs.clj file helps implements a command-line starter for reprocessing Whole GenomeS . The module/sg.clj file implements Somatic Genomes support. The module/all.clj file hosts some utilities shared across modules. The metadata.clj file implements a tool to extract metadata from Cromwell that can be archived with the outputs generated by a workflow. The dx.clj file implements miscellaneous pipeline debugging tools. The once.clj file defines some initialization functions mostly supporting authentication. The api/handlers.clj file defines the handler functions used by server. The api/routes.clj file defines the routing strategy for server. Each of the other source files implement an interface to one of the services WFL talks to, and are named accordingly. File Service cromwell.clj Cromwell workflow runner datarepo.clj DSP DataRepo db.clj On-prem and Cloud SQL databases gcs.clj Google Cloud Storage jms.clj Java Message Service queues postgres.clj Cloud SQL postgres databases server.clj the WFL server itself","title":"Source code"},{"location":"#exomes-in-the-cloud-resources","text":"From Hybrid Selection in the Cloud V1 Clients Google Cloud Storage Client Library (Java) Google Cloud Client Library for Java Diagrams Zamboni Overview Sources /Users/tbl/Broad/zamboni/Client/src/scala/org/broadinstitute/zamboni/client/lightning/clp/Lightning.scala /Users/tbl/Broad/picard-private/src/java/edu/mit/broad/picard/lightning /Users/tbl/Broad/gppipeline-devtools/release client /Users/tbl/Broad/gppipeline-devtools/starter control /picard02:/seq/pipeline/gppipeline-devtools/current/defs/prod.defs","title":"Exomes in the Cloud Resources"},{"location":"dev-logging/","text":"WFL Logging \u2693\ufe0e TL;DR \u2693\ufe0e Import wfl.log :as log and use log/error / log/info etc. The logger will write the logs with a message, severity and timestamp by default. Example: {\"severity\": \"INFO\", \"message\": \"This is an information logging message.\", \"timestamp\": \"2021-07-08T22:02:58.079938Z\"} These logs are eventually sent to Google Cloud Logging and can be queried from there. More information about Google Logging and what some of the fields provided mean can be found here: https://cloud.google.com/logging/docs/agent/logging/configuration#special-fields Below is more detailed information for those interested. Usage \u2693\ufe0e Require it like any other dependency: ( ns \"...\" ( :require ... [ wfl.log :as log ] ... )) ( log/info \"Hello!\" ) There are currently 5 macros for creating simple json logs for INFO, WARN, DEBUG, ERROR, NOTICE . There is also a public method log that can be called with additional fields you may want to provide in the log, such as labels. A list of the Google Cloud supported logging fields and severities can be found here: https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry An example call to log: ( ns \"...\" ( :require ... [ wfl.log :as log ] ... )) ( log/log :info \"This is an information message with a label\" :logging.googleapis.com/labels { :my-label \"label value\" }) This example produces the following json log: { \"severity\" : \"INFO\" , \"message\" : \"This is an information message with a label\" , \"timestamp\" : \"2021-07-09T14:57:22.437485Z\" , \"logging.googleapis.com/labels\" :{ \"my-label\" : \"label value\" }} The logging can also be disabled if you see fit for whatever reason by binding the *logger* instance to disabled-logger . Example: ( binding [ log/*logger* log/disabled-logger ] ( log/info \"This message will not be written\" )) Logging Levels \u2693\ufe0e The severity levels currently supported for WFL logs are, in order: DEBUG, INFO, NOTICE, ERROR, CRITICAL, ALERT, EMERGENCY. By default, all logs of severity INFO and higher are written to stdout. If you desire to change this level, i.e. write only logs ERROR and higher or DEBUG and higher, you can set this configuration with the logging_level endpoint. Calling logging_level with a GET request will return the current level in which the api is writing. Example on a local server below: curl -X GET http://localhost:3000/api/v1/logging_level \\ -H 'accept: application/json' \\ -H \"authorization: Bearer \"$(gcloud auth print-access-token) The result will look something like this: { \"level\" : \"INFO\" } In order to change this level as desired would be done like so: curl -X POST http://localhost:3000/api/v1/logging_level?level=DEBUG \\ -H 'accept: application/json' \\ -H \"authorization: Bearer \"$(gcloud auth print-access-token) The result would be similar: { \"level\" : \"DEBUG\" } The above change would allow all logs DEBUG and higher to be written, i.e. DEBUG, INFO, NOTICE, WARNING, ERROR, CRITICAL, ALERT, EMERGENCY. Testing \u2693\ufe0e Test for this can be found in test/wfl/unit/logging_test.clj . Currently, the tests check whether the logging methods produce json that includes the correct severity and message. Usage in Debugging \u2693\ufe0e In order to be able to search for specific logs locally that could be useful in your debugging you will want to follow these steps: Make sure you have jq installed for your terminal. Run the server with ./ops/server.sh >> path/to/wfl/log 2>&1 Look up logs by severity and only show the message: tail -f path/to/wfl/log | grep --line-buffered -w '\"severity\":\"[YOUR_SEVERITY_HERE]\"' | jq '.message' Look up logs by a label and print the message: tail -f path/to/wfl/log | grep --line-buffered -w 'my-label' | jq '.message' You may also wish to check the Logging Level section for changing the severity of messages being written. An example being that you want to have debug messages that WFL writes that are not always displayed when the app is deployed on a production server. You could set the logging level to DEBUG and then tail the messages like so: tail -f path/to/wfl/log | grep --line-buffered -w '\"severity\":\"DEBUG\"' | jq '.message' Now you can read only the debug messages in stdout as they come and filter out all other severities such as INFO.","title":"Logging"},{"location":"dev-logging/#wfl-logging","text":"","title":"WFL Logging"},{"location":"dev-logging/#tldr","text":"Import wfl.log :as log and use log/error / log/info etc. The logger will write the logs with a message, severity and timestamp by default. Example: {\"severity\": \"INFO\", \"message\": \"This is an information logging message.\", \"timestamp\": \"2021-07-08T22:02:58.079938Z\"} These logs are eventually sent to Google Cloud Logging and can be queried from there. More information about Google Logging and what some of the fields provided mean can be found here: https://cloud.google.com/logging/docs/agent/logging/configuration#special-fields Below is more detailed information for those interested.","title":"TL;DR"},{"location":"dev-logging/#usage","text":"Require it like any other dependency: ( ns \"...\" ( :require ... [ wfl.log :as log ] ... )) ( log/info \"Hello!\" ) There are currently 5 macros for creating simple json logs for INFO, WARN, DEBUG, ERROR, NOTICE . There is also a public method log that can be called with additional fields you may want to provide in the log, such as labels. A list of the Google Cloud supported logging fields and severities can be found here: https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry An example call to log: ( ns \"...\" ( :require ... [ wfl.log :as log ] ... )) ( log/log :info \"This is an information message with a label\" :logging.googleapis.com/labels { :my-label \"label value\" }) This example produces the following json log: { \"severity\" : \"INFO\" , \"message\" : \"This is an information message with a label\" , \"timestamp\" : \"2021-07-09T14:57:22.437485Z\" , \"logging.googleapis.com/labels\" :{ \"my-label\" : \"label value\" }} The logging can also be disabled if you see fit for whatever reason by binding the *logger* instance to disabled-logger . Example: ( binding [ log/*logger* log/disabled-logger ] ( log/info \"This message will not be written\" ))","title":"Usage"},{"location":"dev-logging/#logging-levels","text":"The severity levels currently supported for WFL logs are, in order: DEBUG, INFO, NOTICE, ERROR, CRITICAL, ALERT, EMERGENCY. By default, all logs of severity INFO and higher are written to stdout. If you desire to change this level, i.e. write only logs ERROR and higher or DEBUG and higher, you can set this configuration with the logging_level endpoint. Calling logging_level with a GET request will return the current level in which the api is writing. Example on a local server below: curl -X GET http://localhost:3000/api/v1/logging_level \\ -H 'accept: application/json' \\ -H \"authorization: Bearer \"$(gcloud auth print-access-token) The result will look something like this: { \"level\" : \"INFO\" } In order to change this level as desired would be done like so: curl -X POST http://localhost:3000/api/v1/logging_level?level=DEBUG \\ -H 'accept: application/json' \\ -H \"authorization: Bearer \"$(gcloud auth print-access-token) The result would be similar: { \"level\" : \"DEBUG\" } The above change would allow all logs DEBUG and higher to be written, i.e. DEBUG, INFO, NOTICE, WARNING, ERROR, CRITICAL, ALERT, EMERGENCY.","title":"Logging Levels"},{"location":"dev-logging/#testing","text":"Test for this can be found in test/wfl/unit/logging_test.clj . Currently, the tests check whether the logging methods produce json that includes the correct severity and message.","title":"Testing"},{"location":"dev-logging/#usage-in-debugging","text":"In order to be able to search for specific logs locally that could be useful in your debugging you will want to follow these steps: Make sure you have jq installed for your terminal. Run the server with ./ops/server.sh >> path/to/wfl/log 2>&1 Look up logs by severity and only show the message: tail -f path/to/wfl/log | grep --line-buffered -w '\"severity\":\"[YOUR_SEVERITY_HERE]\"' | jq '.message' Look up logs by a label and print the message: tail -f path/to/wfl/log | grep --line-buffered -w 'my-label' | jq '.message' You may also wish to check the Logging Level section for changing the severity of messages being written. An example being that you want to have debug messages that WFL writes that are not always displayed when the app is deployed on a production server. You could set the logging level to DEBUG and then tail the messages like so: tail -f path/to/wfl/log | grep --line-buffered -w '\"severity\":\"DEBUG\"' | jq '.message' Now you can read only the debug messages in stdout as they come and filter out all other severities such as INFO.","title":"Usage in Debugging"},{"location":"dev-monitoring/","text":"Workflow Launcher Monitoring \u2693\ufe0e Logs from stdout and stderr are sent to Google Logging (Stackdriver) where they can be queried. With the logs, metrics can be created to see developments from those logs over time. From those metrics, we can create alerts that are sent to notification channels of our choosing (slack, email, sms, pubsub, etc.). To create a metric via command line: gcloud auth login gcloud config set project PROJECT_ID gcloud beta logging metrics create MY-METRIC-NAME --description=\"description goes here\" --filter=\"filter goes here\" The log entries for WFL should be located under a container name of workflow-launcher-api so logging queries to find said logs should contain resource.labels.container_name=\"workflow-launcher-api\" . To look for log severities of error and above, include severity>=ERROR in the metric filter as well. You can exclude specific items in the query with the NOT keyword (ex: NOT \"INFO: \" excludes messages that contain \"INFO: \" ) An example query for all wfl errors of severity ERROR and above: resource.labels.container_name=\"workflow-launcher-api\" severity>=ERROR To create an alert via command line: gcloud auth login gcloud config set project PROJECT_ID gcloud alpha monitoring policies create --policy-from-file=\"path/to/file\" Example policies can be found here: https://cloud.google.com/monitoring/alerts/policies-in-json When a metric goes over the threshold set by the policy, an alert is sent via the notification channels provided in the configuration. An incident is created in google cloud monitoring under alerts. These incidents will resolve themselves once the time series shows the metric condition of the alert going back under the configured threshold.","title":"Monitoring"},{"location":"dev-monitoring/#workflow-launcher-monitoring","text":"Logs from stdout and stderr are sent to Google Logging (Stackdriver) where they can be queried. With the logs, metrics can be created to see developments from those logs over time. From those metrics, we can create alerts that are sent to notification channels of our choosing (slack, email, sms, pubsub, etc.). To create a metric via command line: gcloud auth login gcloud config set project PROJECT_ID gcloud beta logging metrics create MY-METRIC-NAME --description=\"description goes here\" --filter=\"filter goes here\" The log entries for WFL should be located under a container name of workflow-launcher-api so logging queries to find said logs should contain resource.labels.container_name=\"workflow-launcher-api\" . To look for log severities of error and above, include severity>=ERROR in the metric filter as well. You can exclude specific items in the query with the NOT keyword (ex: NOT \"INFO: \" excludes messages that contain \"INFO: \" ) An example query for all wfl errors of severity ERROR and above: resource.labels.container_name=\"workflow-launcher-api\" severity>=ERROR To create an alert via command line: gcloud auth login gcloud config set project PROJECT_ID gcloud alpha monitoring policies create --policy-from-file=\"path/to/file\" Example policies can be found here: https://cloud.google.com/monitoring/alerts/policies-in-json When a metric goes over the threshold set by the policy, an alert is sent via the notification channels provided in the configuration. An incident is created in google cloud monitoring under alerts. These incidents will resolve themselves once the time series shows the metric condition of the alert going back under the configured threshold.","title":"Workflow Launcher Monitoring"},{"location":"dev-process/","text":"Development Process \u2693\ufe0e This is a development process we are tying to standardize within the team and encourage ourselves to follow in most cases. The Swagger page \u2693\ufe0e WFL ships with a Swagger UI that documents all available endpoints. It's available at path <host>/swagger . Dev WFL Swagger Prod WFL Swagger For local access, see accessing Swagger Locally . Development Setup \u2693\ufe0e Clojure development feels very different from Scala and Java development. It even differs markedly from development in other dynamic languages such as Python or Ruby. Get a demonstration from someone familiar with Clojure development before you spend too much time trying to figure things out on your own. Find a local Cursive user for guidance if you like IntelliJ. Olivia Kotsopoulos knows how to use it. Cursive licences are available here . If none are available, free non-commercial licenses are suitable for open-source development. The steps for getting this project set up with very recent versions of IntelliJ differ from Cursive's docs: Tip Run make prebuild before launching IntelliJ as it sets up all libraries and derived resources and sources: make TARGET = prebuild -jN Outside of IntelliJ , clone the repo. Now inside of IntelliJ , import the project. Use the Project Structure window (Help -> Find Action -> Project Structure) to set a JDK as the Project SDK There is also a Calva plugin for Visual Studio Code . Tom Lyons hacks Clojure in Emacs using CIDER and nREPL . CIDER is not trivial to set up, but not especially difficult if you are used to Emacs. (I can help if CIDER gives you trouble.) Process \u2693\ufe0e We base feature branches off develop , make pull requests, ask for reviews and merge back to develop on Github. For the release process, please refer to the release guide . Clone the repo git@github.com:broadinstitute/wfl.git Start from the latest copy of the remote develop git checkout develop git pull origin develop Create a feature branch It is highly recommended that you follow the naming convention shown below so JIRA could pick up the branch and link it to our JIRA board. git checkout -b tbl/GH-666-feature-branch-something Start your work, add and commit your changes git add \"README.md\" git commit -m \"Update the readme file.\" [Optional] Rebase onto latest develop if you want to get updates git checkout develop git pull origin develop --ff git checkout tbl/GH-666-feature-branch-something git rebase develop alternatively, you could use the following commands without switching branches: git checkout tbl/GH-666-feature-branch-something git fetch origin develop git merge develop Push branch to Github in the early stage of your development (recommended): git push --set-upstream origin tbl/GH-666-feature-branch-something Create the pull request on Github UI. Be sure to fill out the PR description following the PR template instructions. If the PR is still in development, make sure use the dropdown menu and choose Create draft pull request If the PR is ready for review, click Create pull request . Look for reviewer(s) in the team. Address reviewer comments with more commits. Receive approval from reviewers. Merge the PR. Development Tips \u2693\ufe0e Here are some tips for WFL development. Some of this advice might help when testing Liquibase migration or other changes that affect WFL's Postgres database. setting up a local Postgres \u2693\ufe0e You can test against a local Postgres before running Liquibase or SQL against a shared database in gotc-dev or gasp production. Install Postgres locally. You need version 11 because that is what Google's hosted service supports, and there are differences in the SQL syntax. brew install postgresql@11 Start Postgres. pg_ctl -D /usr/local/var/postgresql@11 start Tip It might be useful to set up some an alias for postgres if you are using zsh, for example: alias pq=\"pg_ctl -D /usr/local/var/postgresql@11\" thus you could use pq start or pq stop to easily spin up and turn down the db. [Optional] Create wfl DB. If you see errors like this when launching a local WFL server or applying liquibase updates: FATAL: database \"wfl\" does not exist You should do as instructed within your terminal: createdb wfl Or to recreate an existing wfl DB: dropdb wfl createdb wfl You are now free to launch a local WFL server pointing to your local DB. Assuming that WFL_POSTGRES_URL in (wfl.environment/defaults) is set to point at a running local Postgres (e.g. jdbc:postgresql:wfl ), running ./ops/server.sh (or however you launch a local WFL server) will connect the server to that running local Postgres. Now any changes to WFL state will affect only your local database. That includes running Liquibase, so don't forget to reset :debug to env before deploying your changes after merging a PR. migrating a database \u2693\ufe0e To change WFL's Postgres database schema, add a changeset XML file in the database/changesets directory. Name the file for a recent or the current date followed by something describing the change. That will ensure that the changesets list in the order in which they apply. Note that the id and logicalFilePath attributes are derived from the changeset's file name. Then add the changeset file to the database/changlog.xml file. Test the changes against a local scratch database . See the next section for suggestions. debugging JDBC SQL \u2693\ufe0e Something seems to swallow SQL exceptions raised by Postgres and the JDBC library. Wrap suspect clojure.java.jdbc calls in wfl.util/do-or-nil to ensure that any exceptions show up in the server logs. debugging API specs \u2693\ufe0e If an API references an undefined spec, HTTP requests and responses might silently fail or the Swagger page will fail to render. Check the clojure.spec.alpha/def s in wfl.api.routes for typos before tearing your hair out. accessing Swagger locally \u2693\ufe0e First, start a local WFL server. ./ops/server.sh To view the rendered Swagger page: open http://localhost:3000/swagger debugging Liquibase locally \u2693\ufe0e Running liquibase update : liquibase --classpath = $( clojure -Spath ) \\ --url = jdbc:postgresql:wfl \\ --changeLogFile = database/changelog.xml \\ --username = $USER update For the above, the username and password need to be correct for the target environment. If you're running a local server with the postgres command above, you don't need a password and can omit it. Otherwise, you may be able to find this data in the Vault entry for the environment's server -- resources/wfl/environments.clj has some environments if you've built locally. You can use --password=$ENV_SOMETHING to supply it. Tip It is more convenient to use the following alias to migrate the database schema from within the api directory: clojure -M:liquibase if you are working with a local database. Override ENVIRONMENT variables for local development \u2693\ufe0e WFL uses src/wfl/api/environment.clj to read and process environment variables. Most of the variables have their default values, which can be overwritten for development purposes. For example, if we want to run system tests in parallel against a local WFL instance, use below under api/ directory: WFL_WFL_URL = http://localhost:3000 clojure -M:parallel-test wfl.system.v1-endpoint-test REPL testing with fixtures. \u2693\ufe0e Now that we're using fixtures, and so on, in our tests, it is no longer good enough to run deftest vars as functions. Running a test like this (test-something) does not set up the necessary fixtures. However, clojure.test/test-vars can run a test with all the surrounding clojure.test mechanism in place. It takes a vector of var s like this. ( comment ( test-vars [ # 'test-something ])) No tests found \u2693\ufe0e When trying to run tests in the command line, you may see the test suite exit prematurely -- but successfully -- with a warning indicating that no tests were found, and thus no tests were run. $ make api TARGET = check export CPCACHE = /Users/okotsopo/wfl/api/.cpcache ; \\ clojure -M:test unit | \\ tee /Users/okotsopo/wfl/derived/api/unit.log ... WARNING: No tests were found, make sure :test-paths and :ns-patterns are configured correctly in tests.edn. api unit finished on Thu Jun 24 15 :03:33 EDT 2021 ... This may indicate a compilation error in code not compiled as part of the build, e.g. tests. Linting can help expose any such errors. Tip By default, linting will halt on the first thrown exception, requiring further linting after fixing until the process succeeds. $ make api TARGET = lint ... == Eastwood 0 .4.2 Clojure 1 .10.3 JVM 11 .0.10 == Directories scanned for source files: src test ... == Linting wfl.system.cdc-covid19-surveillance-demo == Exception thrown during phase :analyze+eval of linting namespace wfl.system.cdc-covid19-surveillance-demo Got exception with extra ex-data: msg = 'No such var: covid' ( keys dat )=( :form :file :end-column :column :line :end-line ) ( :form dat )= ^ { :line 101 } covid/rename-gather ExceptionInfo No such var: covid ... An exception was thrown while analyzing namespace wfl.system.cdc-covid19-surveillance-demo Lint results may be incomplete. If there are compilation errors in your code, try fixing those. If not, check above for info on the exception. Stopped analyzing namespaces after wfl.system.cdc-covid19-surveillance-demo due to exception thrown. 28 namespaces left unanalyzed. If you wish to force continuation of linting after an exception in one namespace, make the option map key :continue-on-exception have the value true. ...","title":"Development Process and Tips"},{"location":"dev-process/#development-process","text":"This is a development process we are tying to standardize within the team and encourage ourselves to follow in most cases.","title":"Development Process"},{"location":"dev-process/#the-swagger-page","text":"WFL ships with a Swagger UI that documents all available endpoints. It's available at path <host>/swagger . Dev WFL Swagger Prod WFL Swagger For local access, see accessing Swagger Locally .","title":"The Swagger page"},{"location":"dev-process/#development-setup","text":"Clojure development feels very different from Scala and Java development. It even differs markedly from development in other dynamic languages such as Python or Ruby. Get a demonstration from someone familiar with Clojure development before you spend too much time trying to figure things out on your own. Find a local Cursive user for guidance if you like IntelliJ. Olivia Kotsopoulos knows how to use it. Cursive licences are available here . If none are available, free non-commercial licenses are suitable for open-source development. The steps for getting this project set up with very recent versions of IntelliJ differ from Cursive's docs: Tip Run make prebuild before launching IntelliJ as it sets up all libraries and derived resources and sources: make TARGET = prebuild -jN Outside of IntelliJ , clone the repo. Now inside of IntelliJ , import the project. Use the Project Structure window (Help -> Find Action -> Project Structure) to set a JDK as the Project SDK There is also a Calva plugin for Visual Studio Code . Tom Lyons hacks Clojure in Emacs using CIDER and nREPL . CIDER is not trivial to set up, but not especially difficult if you are used to Emacs. (I can help if CIDER gives you trouble.)","title":"Development Setup"},{"location":"dev-process/#process","text":"We base feature branches off develop , make pull requests, ask for reviews and merge back to develop on Github. For the release process, please refer to the release guide . Clone the repo git@github.com:broadinstitute/wfl.git Start from the latest copy of the remote develop git checkout develop git pull origin develop Create a feature branch It is highly recommended that you follow the naming convention shown below so JIRA could pick up the branch and link it to our JIRA board. git checkout -b tbl/GH-666-feature-branch-something Start your work, add and commit your changes git add \"README.md\" git commit -m \"Update the readme file.\" [Optional] Rebase onto latest develop if you want to get updates git checkout develop git pull origin develop --ff git checkout tbl/GH-666-feature-branch-something git rebase develop alternatively, you could use the following commands without switching branches: git checkout tbl/GH-666-feature-branch-something git fetch origin develop git merge develop Push branch to Github in the early stage of your development (recommended): git push --set-upstream origin tbl/GH-666-feature-branch-something Create the pull request on Github UI. Be sure to fill out the PR description following the PR template instructions. If the PR is still in development, make sure use the dropdown menu and choose Create draft pull request If the PR is ready for review, click Create pull request . Look for reviewer(s) in the team. Address reviewer comments with more commits. Receive approval from reviewers. Merge the PR.","title":"Process"},{"location":"dev-process/#development-tips","text":"Here are some tips for WFL development. Some of this advice might help when testing Liquibase migration or other changes that affect WFL's Postgres database.","title":"Development Tips"},{"location":"dev-process/#setting-up-a-local-postgres","text":"You can test against a local Postgres before running Liquibase or SQL against a shared database in gotc-dev or gasp production. Install Postgres locally. You need version 11 because that is what Google's hosted service supports, and there are differences in the SQL syntax. brew install postgresql@11 Start Postgres. pg_ctl -D /usr/local/var/postgresql@11 start Tip It might be useful to set up some an alias for postgres if you are using zsh, for example: alias pq=\"pg_ctl -D /usr/local/var/postgresql@11\" thus you could use pq start or pq stop to easily spin up and turn down the db. [Optional] Create wfl DB. If you see errors like this when launching a local WFL server or applying liquibase updates: FATAL: database \"wfl\" does not exist You should do as instructed within your terminal: createdb wfl Or to recreate an existing wfl DB: dropdb wfl createdb wfl You are now free to launch a local WFL server pointing to your local DB. Assuming that WFL_POSTGRES_URL in (wfl.environment/defaults) is set to point at a running local Postgres (e.g. jdbc:postgresql:wfl ), running ./ops/server.sh (or however you launch a local WFL server) will connect the server to that running local Postgres. Now any changes to WFL state will affect only your local database. That includes running Liquibase, so don't forget to reset :debug to env before deploying your changes after merging a PR.","title":"setting up a local Postgres"},{"location":"dev-process/#migrating-a-database","text":"To change WFL's Postgres database schema, add a changeset XML file in the database/changesets directory. Name the file for a recent or the current date followed by something describing the change. That will ensure that the changesets list in the order in which they apply. Note that the id and logicalFilePath attributes are derived from the changeset's file name. Then add the changeset file to the database/changlog.xml file. Test the changes against a local scratch database . See the next section for suggestions.","title":"migrating a database"},{"location":"dev-process/#debugging-jdbc-sql","text":"Something seems to swallow SQL exceptions raised by Postgres and the JDBC library. Wrap suspect clojure.java.jdbc calls in wfl.util/do-or-nil to ensure that any exceptions show up in the server logs.","title":"debugging JDBC SQL"},{"location":"dev-process/#debugging-api-specs","text":"If an API references an undefined spec, HTTP requests and responses might silently fail or the Swagger page will fail to render. Check the clojure.spec.alpha/def s in wfl.api.routes for typos before tearing your hair out.","title":"debugging API specs"},{"location":"dev-process/#accessing-swagger-locally","text":"First, start a local WFL server. ./ops/server.sh To view the rendered Swagger page: open http://localhost:3000/swagger","title":"accessing Swagger locally"},{"location":"dev-process/#debugging-liquibase-locally","text":"Running liquibase update : liquibase --classpath = $( clojure -Spath ) \\ --url = jdbc:postgresql:wfl \\ --changeLogFile = database/changelog.xml \\ --username = $USER update For the above, the username and password need to be correct for the target environment. If you're running a local server with the postgres command above, you don't need a password and can omit it. Otherwise, you may be able to find this data in the Vault entry for the environment's server -- resources/wfl/environments.clj has some environments if you've built locally. You can use --password=$ENV_SOMETHING to supply it. Tip It is more convenient to use the following alias to migrate the database schema from within the api directory: clojure -M:liquibase if you are working with a local database.","title":"debugging Liquibase locally"},{"location":"dev-process/#override-environment-variables-for-local-development","text":"WFL uses src/wfl/api/environment.clj to read and process environment variables. Most of the variables have their default values, which can be overwritten for development purposes. For example, if we want to run system tests in parallel against a local WFL instance, use below under api/ directory: WFL_WFL_URL = http://localhost:3000 clojure -M:parallel-test wfl.system.v1-endpoint-test","title":"Override ENVIRONMENT variables for local development"},{"location":"dev-process/#repl-testing-with-fixtures","text":"Now that we're using fixtures, and so on, in our tests, it is no longer good enough to run deftest vars as functions. Running a test like this (test-something) does not set up the necessary fixtures. However, clojure.test/test-vars can run a test with all the surrounding clojure.test mechanism in place. It takes a vector of var s like this. ( comment ( test-vars [ # 'test-something ]))","title":"REPL testing with fixtures."},{"location":"dev-process/#no-tests-found","text":"When trying to run tests in the command line, you may see the test suite exit prematurely -- but successfully -- with a warning indicating that no tests were found, and thus no tests were run. $ make api TARGET = check export CPCACHE = /Users/okotsopo/wfl/api/.cpcache ; \\ clojure -M:test unit | \\ tee /Users/okotsopo/wfl/derived/api/unit.log ... WARNING: No tests were found, make sure :test-paths and :ns-patterns are configured correctly in tests.edn. api unit finished on Thu Jun 24 15 :03:33 EDT 2021 ... This may indicate a compilation error in code not compiled as part of the build, e.g. tests. Linting can help expose any such errors. Tip By default, linting will halt on the first thrown exception, requiring further linting after fixing until the process succeeds. $ make api TARGET = lint ... == Eastwood 0 .4.2 Clojure 1 .10.3 JVM 11 .0.10 == Directories scanned for source files: src test ... == Linting wfl.system.cdc-covid19-surveillance-demo == Exception thrown during phase :analyze+eval of linting namespace wfl.system.cdc-covid19-surveillance-demo Got exception with extra ex-data: msg = 'No such var: covid' ( keys dat )=( :form :file :end-column :column :line :end-line ) ( :form dat )= ^ { :line 101 } covid/rename-gather ExceptionInfo No such var: covid ... An exception was thrown while analyzing namespace wfl.system.cdc-covid19-surveillance-demo Lint results may be incomplete. If there are compilation errors in your code, try fixing those. If not, check above for info on the exception. Stopped analyzing namespaces after wfl.system.cdc-covid19-surveillance-demo due to exception thrown. 28 namespaces left unanalyzed. If you wish to force continuation of linting after an exception in one namespace, make the option map key :continue-on-exception have the value true. ...","title":"No tests found"},{"location":"dev-release/","text":"Release Process \u2693\ufe0e The main branch contains tagged release commits. We follow a simple process in order to release a new version of WFL: Create a release branch based off develop release branch names follow the convention release/X.Y.Z-rc the version string should match that specified in version Identify and cherry-pick additional commits from develop that you want to release (e.g. late features and bug fixes). Create a release candidate and deploy to a testing environment. See instructions bellow. Bash the release candidate. Add/cherry-pick any bug fixes that result. Create a pull request into main . You will need to run ./ops/cli.py release to generate the changelog for this release (the -d flag can be used to do a dry run without writing to the CHANGELOG.md file). When the PR is approved, merge it into main . The release action will run automatically to build, test and build and push the tagged docker images of WFL to DockerHub . Please merge PRs that have passed all automated tests only. Tip It can take up to 30 minutes for the Github Action to finish! Please be patient! Tip Remember to create a PR to bump the version string in version in develop for the next release, including changes to CHANGELOG.md from the release. Creating a Release Candidate \u2693\ufe0e In this example, we will create a release candidate for vX.Y.Z. We will assume the existence of a release branch release/X.Y.Z-rc . From wfl 's root directory: Ensure your local repository clone is clean $ make distclean Prepare sources $ git checkout release/X.Y.Z-rc $ git pull origin release/X.Y.Z-rc --ff Build the docker images locally $ make TARGET = images Tag the commit and release the images to dockerhub with the release candidate tag. Let us assume that this is the Mth release candidate. $ ./ops/cli.py tag-and-push-images --version = X.Y.Z-rcN Tip You can run make in parallel by adding -jN to the end of your make command, where N is the number of concurrent jobs to run.","title":"Release Process"},{"location":"dev-release/#release-process","text":"The main branch contains tagged release commits. We follow a simple process in order to release a new version of WFL: Create a release branch based off develop release branch names follow the convention release/X.Y.Z-rc the version string should match that specified in version Identify and cherry-pick additional commits from develop that you want to release (e.g. late features and bug fixes). Create a release candidate and deploy to a testing environment. See instructions bellow. Bash the release candidate. Add/cherry-pick any bug fixes that result. Create a pull request into main . You will need to run ./ops/cli.py release to generate the changelog for this release (the -d flag can be used to do a dry run without writing to the CHANGELOG.md file). When the PR is approved, merge it into main . The release action will run automatically to build, test and build and push the tagged docker images of WFL to DockerHub . Please merge PRs that have passed all automated tests only. Tip It can take up to 30 minutes for the Github Action to finish! Please be patient! Tip Remember to create a PR to bump the version string in version in develop for the next release, including changes to CHANGELOG.md from the release.","title":"Release Process"},{"location":"dev-release/#creating-a-release-candidate","text":"In this example, we will create a release candidate for vX.Y.Z. We will assume the existence of a release branch release/X.Y.Z-rc . From wfl 's root directory: Ensure your local repository clone is clean $ make distclean Prepare sources $ git checkout release/X.Y.Z-rc $ git pull origin release/X.Y.Z-rc --ff Build the docker images locally $ make TARGET = images Tag the commit and release the images to dockerhub with the release candidate tag. Let us assume that this is the Mth release candidate. $ ./ops/cli.py tag-and-push-images --version = X.Y.Z-rcN Tip You can run make in parallel by adding -jN to the end of your make command, where N is the number of concurrent jobs to run.","title":"Creating a Release Candidate"},{"location":"executor/","text":"Executor \u2693\ufe0e The workload Executor models an intermediate stage of a processing pipeline. In a typical workload configuration, an Executor uses a supported service in the cloud to execute workflows. User Guide \u2693\ufe0e You can configure the type of Executor used in your workload by changing the executor attribute of your workload request. Terra Executor \u2693\ufe0e You can execute workflows in a Terra workspace using the Terra executor. The Terra executor will... Coerce available outputs from an upstream Source to a data type acceptable for submission creation (i.e. import a snapshot to the executor workspace as a reference) Update the method configuration with the coerced object as its root entity type Launch a submission Periodically update the statuses of eligible workflows to enable a downstream Sink to consume their outputs A typical Terra executor configuration in the workload request looks like: { \"name\" : \"Terra\" , \"workspace\" : \"{workspace-namespace}/{workspace-name}\" , \"methodConfiguration\" : \"{method-configuration-namespace}/{method-configuration-name}\" , \"methodConfigurationVersion\" : 1 , \"fromSource\" : \"importSnapshot\" } And a real-life example for a known method configuration: { \"name\" : \"Terra\" , \"workspace\" : \"wfl-dev/CDC_Viral_Sequencing\" , \"methodConfiguration\" : \"wfl-dev/sarscov2_illumina_full\" , \"methodConfigurationVersion\" : 1 , \"fromSource\" : \"importSnapshot\" } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the Terra executor implementation. workspace Terra Workspace in which to execute workflows. methodConfiguration Method configuration from which to generate submissions. methodConfigurationVersion Expected version of the method configuration. fromSource Instruction to coerce an output from an upstream Source to a type understood by this executor . workspace \u2693\ufe0e A {workspace-namespace}/{workspace-name} string as it appears in the URL path in the Terra UI. Prerequisites: The workspace must exist prior to workload creation. workflow-launcher@firecloud.org must be a workspace \"Owner\" in order to import snapshots to the workspace. The workspace must be compatible with any downstream processing stage that consumes its workflows. methodConfiguration \u2693\ufe0e A {method-configuration-namespace}/{method-configuration-name} string as it appears in the URL path in the Terra UI. Prerequisites: The method configuration must exist within workspace prior to workload creation. methodConfigurationVersion \u2693\ufe0e The expected version of methodConfiguration , stored as an integer in Firecloud . Example fetch of a method configuration's version from the appropriate Firecloud instance (prod): curl -X 'GET' \\ 'https://firecloud-orchestration.dsde-prod.broadinstitute.org/api/workspaces/emerge_prod/Arrays_test/method_configs/warp-pipelines/Arrays' \\ -H 'accept: */*' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ | jq .methodConfigVersion 7 Prerequisites: The methodConfiguration version when fetched from Firecloud at workload creation should match methodConfigurationVersion . Implications of Version Mismatch A version mismatch may indicate a possible concurrent modification of the method configuration used for launching submissions. Modification is possible programmatically or via the Terra UI. An unexpected modification may cause submission and/or workflow creation to fail. fromSource \u2693\ufe0e This attribute tells workflow-launcher how to coerce an output from an upstream Source into a data type understood by the executor. Prerequisites: Must be one of the following supported coercion instructions. importSnapshot \u2693\ufe0e Workflow-launcher should import Terra Data Repository (TDR) snapshots into workspace as snapshot references, updating methodConfiguration with the reference as its root entity type. Developer Guide \u2693\ufe0e An executor is a Queue that satisfies the Executor protocol below: ( defprotocol Executor ( update-executor! ^ Workload [ ^ Workload workload ] \"Consume items from the `workload`'s source queue and enqueue to its executor queue for consumption by a later processing stage, performing any external effects as necessary. Implementations should avoid maintaining in-memory state and making long- running external calls, favouring internal queues to manage such tasks asynchronously between invocations. Note that the `Workload`'s Source queue and Executor are parameterised types and the Source queue's parameterisation must be convertible to the Executor's.\" ) ( executor-workflows ^ IPersistentVector [ ^ Connection transaction ;; JDBC Connection ^ Executor executor ;; This executor instance ] \"Use database `transaction` to return workflows created by the `executor`.\" ) ( executor-workflows-by-filters ^ IPersistentVector [ ^ Connection transaction ;; JDBC Connection ^ Executor executor ;; This executor instance ^ IPersistentVector filters ;; Workflow filters to match ;; (ex. status, submission) ] \"Use database `transaction` to return workflows created by the `executor` matching the workflow `filters` (ex. status, submission).\" ) ( executor-throw-if-invalid-retry-filters ;; Executed for side effects [ ^ IPersistentHashmap workload ;; Workload for which a retry is requested ^ IPersistentVector filters ;; Workflow filters ] \"Throw if workflow `filters` are invalid for `workload`'s retry request.\" ) ( executor-retry-workflows! ;; Executed for side effects [ ^ Executor executor ;; This executor instance ^ IPersistentVector workflows ;; Workflows to retry ] \"Retry/resubmit the `workflows` managed by the `executor`.\" )) Note The Executor protocol is implemented by a set of multimethods of the same name. The use of a protocol is to illustrate the difference between the in-memory data model of a Executor and the metadata seen by a user. To be used in a workload, an Executor implementation should satisfy the processing Stage protocol and the to-edn multimethod in addition to the following multimethods specific to executors: ( defmulti create-executor \"Create an `Executor` instance using the database `transaction` and configuration in the executor `request` and return a `[type items]` pair to be written to a workload record as `executor_type` and `executor_items`. Notes: - This is a factory method registered for workload creation. - The `Executor` type string must match a value of the `executor` enum in the database schema. - This multimethod is type-dispatched on the `:name` association in the `request`.\" ( fn ^ [ ^ String ^ String ] [ ^ Connection transaction ;; JDBC Connection ^ long workload-id ;; ID of the workload being created ^ IPersistentHashMap request ;; Data forwarded to the handler ] ( :name request ))) ( defmulti load-executor! \"Return the `Executor` implementation associated with the `executor_type` and `executor_items` fields of the `workload` row in the database. Note that this multimethod is type-dispatched on the `:executor_type` association in the `workload`.\" ( fn ^ Executor [ ^ Connection transaction ;; JDBC Connection ^ IPersistentHashMap workload ;; Row from workload table ] ( :executor_type workload )))","title":"Executor"},{"location":"executor/#executor","text":"The workload Executor models an intermediate stage of a processing pipeline. In a typical workload configuration, an Executor uses a supported service in the cloud to execute workflows.","title":"Executor"},{"location":"executor/#user-guide","text":"You can configure the type of Executor used in your workload by changing the executor attribute of your workload request.","title":"User Guide"},{"location":"executor/#terra-executor","text":"You can execute workflows in a Terra workspace using the Terra executor. The Terra executor will... Coerce available outputs from an upstream Source to a data type acceptable for submission creation (i.e. import a snapshot to the executor workspace as a reference) Update the method configuration with the coerced object as its root entity type Launch a submission Periodically update the statuses of eligible workflows to enable a downstream Sink to consume their outputs A typical Terra executor configuration in the workload request looks like: { \"name\" : \"Terra\" , \"workspace\" : \"{workspace-namespace}/{workspace-name}\" , \"methodConfiguration\" : \"{method-configuration-namespace}/{method-configuration-name}\" , \"methodConfigurationVersion\" : 1 , \"fromSource\" : \"importSnapshot\" } And a real-life example for a known method configuration: { \"name\" : \"Terra\" , \"workspace\" : \"wfl-dev/CDC_Viral_Sequencing\" , \"methodConfiguration\" : \"wfl-dev/sarscov2_illumina_full\" , \"methodConfigurationVersion\" : 1 , \"fromSource\" : \"importSnapshot\" } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the Terra executor implementation. workspace Terra Workspace in which to execute workflows. methodConfiguration Method configuration from which to generate submissions. methodConfigurationVersion Expected version of the method configuration. fromSource Instruction to coerce an output from an upstream Source to a type understood by this executor .","title":"Terra Executor"},{"location":"executor/#workspace","text":"A {workspace-namespace}/{workspace-name} string as it appears in the URL path in the Terra UI. Prerequisites: The workspace must exist prior to workload creation. workflow-launcher@firecloud.org must be a workspace \"Owner\" in order to import snapshots to the workspace. The workspace must be compatible with any downstream processing stage that consumes its workflows.","title":"workspace"},{"location":"executor/#methodconfiguration","text":"A {method-configuration-namespace}/{method-configuration-name} string as it appears in the URL path in the Terra UI. Prerequisites: The method configuration must exist within workspace prior to workload creation.","title":"methodConfiguration"},{"location":"executor/#methodconfigurationversion","text":"The expected version of methodConfiguration , stored as an integer in Firecloud . Example fetch of a method configuration's version from the appropriate Firecloud instance (prod): curl -X 'GET' \\ 'https://firecloud-orchestration.dsde-prod.broadinstitute.org/api/workspaces/emerge_prod/Arrays_test/method_configs/warp-pipelines/Arrays' \\ -H 'accept: */*' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ | jq .methodConfigVersion 7 Prerequisites: The methodConfiguration version when fetched from Firecloud at workload creation should match methodConfigurationVersion . Implications of Version Mismatch A version mismatch may indicate a possible concurrent modification of the method configuration used for launching submissions. Modification is possible programmatically or via the Terra UI. An unexpected modification may cause submission and/or workflow creation to fail.","title":"methodConfigurationVersion"},{"location":"executor/#fromsource","text":"This attribute tells workflow-launcher how to coerce an output from an upstream Source into a data type understood by the executor. Prerequisites: Must be one of the following supported coercion instructions.","title":"fromSource"},{"location":"executor/#importsnapshot","text":"Workflow-launcher should import Terra Data Repository (TDR) snapshots into workspace as snapshot references, updating methodConfiguration with the reference as its root entity type.","title":"importSnapshot"},{"location":"executor/#developer-guide","text":"An executor is a Queue that satisfies the Executor protocol below: ( defprotocol Executor ( update-executor! ^ Workload [ ^ Workload workload ] \"Consume items from the `workload`'s source queue and enqueue to its executor queue for consumption by a later processing stage, performing any external effects as necessary. Implementations should avoid maintaining in-memory state and making long- running external calls, favouring internal queues to manage such tasks asynchronously between invocations. Note that the `Workload`'s Source queue and Executor are parameterised types and the Source queue's parameterisation must be convertible to the Executor's.\" ) ( executor-workflows ^ IPersistentVector [ ^ Connection transaction ;; JDBC Connection ^ Executor executor ;; This executor instance ] \"Use database `transaction` to return workflows created by the `executor`.\" ) ( executor-workflows-by-filters ^ IPersistentVector [ ^ Connection transaction ;; JDBC Connection ^ Executor executor ;; This executor instance ^ IPersistentVector filters ;; Workflow filters to match ;; (ex. status, submission) ] \"Use database `transaction` to return workflows created by the `executor` matching the workflow `filters` (ex. status, submission).\" ) ( executor-throw-if-invalid-retry-filters ;; Executed for side effects [ ^ IPersistentHashmap workload ;; Workload for which a retry is requested ^ IPersistentVector filters ;; Workflow filters ] \"Throw if workflow `filters` are invalid for `workload`'s retry request.\" ) ( executor-retry-workflows! ;; Executed for side effects [ ^ Executor executor ;; This executor instance ^ IPersistentVector workflows ;; Workflows to retry ] \"Retry/resubmit the `workflows` managed by the `executor`.\" )) Note The Executor protocol is implemented by a set of multimethods of the same name. The use of a protocol is to illustrate the difference between the in-memory data model of a Executor and the metadata seen by a user. To be used in a workload, an Executor implementation should satisfy the processing Stage protocol and the to-edn multimethod in addition to the following multimethods specific to executors: ( defmulti create-executor \"Create an `Executor` instance using the database `transaction` and configuration in the executor `request` and return a `[type items]` pair to be written to a workload record as `executor_type` and `executor_items`. Notes: - This is a factory method registered for workload creation. - The `Executor` type string must match a value of the `executor` enum in the database schema. - This multimethod is type-dispatched on the `:name` association in the `request`.\" ( fn ^ [ ^ String ^ String ] [ ^ Connection transaction ;; JDBC Connection ^ long workload-id ;; ID of the workload being created ^ IPersistentHashMap request ;; Data forwarded to the handler ] ( :name request ))) ( defmulti load-executor! \"Return the `Executor` implementation associated with the `executor_type` and `executor_items` fields of the `workload` row in the database. Note that this multimethod is type-dispatched on the `:executor_type` association in the `workload`.\" ( fn ^ Executor [ ^ Connection transaction ;; JDBC Connection ^ IPersistentHashMap workload ;; Row from workload table ] ( :executor_type workload )))","title":"Developer Guide"},{"location":"modules-aou-arrays/","text":"All Of Us Arrays module \u2693\ufe0e WorkFlow Launcher (WFL) implements aou-arrays module to support secure and efficient processing of the AllOfUs Arrays samples. This page documents the design principles and assumptions of the module as well as summarizes the general process of module development. aou-arrays module implements arrays workload as a continuous workload , which means all samples are coming in like a continuous stream, and WFL does not make any assumption of how many samples will be in the workload or how to group the samples together: it hands off the workload creation and starting process to its caller. API \u2693\ufe0e aou-arrays module, like others, implements the following multimethod dispatchers : start-workload! add-workload! It supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload POST /api/v1/append_to_aou Append one or more sample(s) to an existing AOU workload, unless stopped Different from the fixed workload types that caller only needs to create a workload with a series of sample inputs and then simply start the workload, aou-arrays module requires the caller to manage the life cycle of a workload on their own in a multi-stage manner: The caller needs to create a workload and specify the type to be AllOfUsArrays , the caller will receive the information of the created workload if everything goes well, one of which is the uuid of the workload. Once the workload information is being reviewed, the caller needs to \"start\" the newly created workload to tell WFL that \"this workload is ready to accept incoming samples\". Without this \"start\" signal WFL will refuse to append any sample to this workload. The caller can append new individual samples to an existing started workload, and these new samples will be analyzed, processed and submitted to Cromwell as long as it has valid information. To give more information, here are some example inputs to the above endpoints: GET /api/v1/workload Request curl 'http://localhost:8080/api/v1/workload' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' GET /api/v1/workload?uuid={uuid} Request curl 'http://localhost:8080/api/v1/workload?uuid=00000000-0000-0000-0000-000000000000' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' GET /api/v1/workload?project={project} Request curl 'http://localhost:8080/api/v1/workload?project=(Test)%20WFL%20Local%20Testing' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' Note project and uuid are optional path parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together. GET /api/v1/workload/{uuid}/workflows Request curl 'http://localhost:8080/api/v1/workload/00000000-0000-0000-0000-000000000000/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) POST /api/v1/create Request curl -X POST 'http://localhost:8080/api/v1/create' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/aou-test-output/\", \"project\": \"Example Project\", \"pipeline\": \"AllOfUsArrays\" }' POST /api/v1/start Request curl -X POST 'http://localhost:8080/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\" }' POST /api/v1/stop Stops the workload from accepting new samples. See also: /api/v1/append_to_aou . Request curl -X POST 'http://localhost:8080/api/v1/stop' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\" }' POST /api/v1/workload/append_to_aou Request curl -X POST 'http://localhost:8080/api/v1/append_to_aou' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\", \"notifications\": [ { \"zcall_thresholds_file\": \"foo\", \"sample_lsid\": \"foo\", \"bead_pool_manifest_file\": \"foo\", \"chip_well_barcode\": \"foo\", \"sample_alias\": \"foo\", \"green_idat_cloud_path\": \"foo\", \"red_idat_cloud_path\": \"foo\", \"cluster_file\": \"foo\", \"reported_gender\": \"foo\", \"gender_cluster_file\": \"foo\", \"params_file\": \"foo\", \"extended_chip_manifest_file\": \"foo\", \"analysis_version_number\": 1 }, { \"zcall_thresholds_file\": \"foo\", \"sample_lsid\": \"foo\", \"bead_pool_manifest_file\": \"foo\", \"chip_well_barcode\": \"foo\", \"sample_alias\": \"foo\", \"green_idat_cloud_path\": \"foo\", \"red_idat_cloud_path\": \"foo\", \"cluster_file\": \"foo\", \"reported_gender\": \"foo\", \"gender_cluster_file\": \"foo\", \"params_file\": \"foo\", \"extended_chip_manifest_file\": \"foo\", \"analysis_version_number\": 5 } ] }' Workload Model \u2693\ufe0e WFL designed the following workload model in order to support the above API and workload submission mechanism. Initially, it has the following schema: List of relations Schema | Name | Type | Owner | Size | Description --------+--------------------------------+----------+----------+------------+------------- public | databasechangelog | table | foo | 16 kB | public | databasechangeloglock | table | foo | 8192 bytes | public | workload | table | foo | 16 kB | public | workload_id_seq | sequence | foo | 8192 bytes | the workload table looks like: id | commit | created | creator | cromwell | finished | input | items | output | pipeline | project | release | started | uuid | version | wdl ----+--------+---------+---------+----------+----------+-------+-------+--------+----------+---------+---------+---------+------+---------+----- (0 rows) Note that different from the fixed workload types, input , output and items are not useful to aou-arrays workload since these fields vary from sample to sample. Any information the caller provided to these fields will stored as placeholders. More importantly, even though id is the primary key here, (pipeline, project, release) works as the unique identifier for arrays workloads, for instance, if there's already a workload with values: (AllOfUsArrays, gotc-dev, Arrays_v1.9) , any further attempts to create a new workload with exact the same values will return the information of this existing workload rather than create a new row. Once the caller successfully creates a new sample, there will be a new row added to the above workload table, and a new table will be created accordingly: List of relations Schema | Name | Type | Owner | Size | Description --------+--------------------------------+----------+----------+------------+------------- public | allofusarrays_000000001 | table | foo | 16 kB | public | allofusarrays_000000001_id_seq | sequence | foo | 8192 bytes | public | databasechangelog | table | foo | 16 kB | public | databasechangeloglock | table | foo | 8192 bytes | public | workload | table | foo | 16 kB | public | workload_id_seq | sequence | foo | 8192 bytes | The allofusarrays_00000000X table has the following fields: id | analysis_version_number | chip_well_barcode | status | updated | uuid ----+-------------------------+-------------------+-----------+-------------------------------+-------------------------------------- 1 | 1 | 0000000000_R01C01 | Succeeded | 2020-07-21 00:00:00.241218-04 | 00000000-0000-0000-0000-000000000000 2 | 5 | 0000000000_R01C01 | Failed | 2020-07-21 00:00:00.028976-04 | 00000000-0000-0000-0000-000000000000 Among which (analysis_version_number, chip_well_barcode) works as the primary key , any new samples that collide with the existing primary-keys will be omitted.","title":"Arrays"},{"location":"modules-aou-arrays/#all-of-us-arrays-module","text":"WorkFlow Launcher (WFL) implements aou-arrays module to support secure and efficient processing of the AllOfUs Arrays samples. This page documents the design principles and assumptions of the module as well as summarizes the general process of module development. aou-arrays module implements arrays workload as a continuous workload , which means all samples are coming in like a continuous stream, and WFL does not make any assumption of how many samples will be in the workload or how to group the samples together: it hands off the workload creation and starting process to its caller.","title":"All Of Us Arrays module"},{"location":"modules-aou-arrays/#api","text":"aou-arrays module, like others, implements the following multimethod dispatchers : start-workload! add-workload! It supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload POST /api/v1/append_to_aou Append one or more sample(s) to an existing AOU workload, unless stopped Different from the fixed workload types that caller only needs to create a workload with a series of sample inputs and then simply start the workload, aou-arrays module requires the caller to manage the life cycle of a workload on their own in a multi-stage manner: The caller needs to create a workload and specify the type to be AllOfUsArrays , the caller will receive the information of the created workload if everything goes well, one of which is the uuid of the workload. Once the workload information is being reviewed, the caller needs to \"start\" the newly created workload to tell WFL that \"this workload is ready to accept incoming samples\". Without this \"start\" signal WFL will refuse to append any sample to this workload. The caller can append new individual samples to an existing started workload, and these new samples will be analyzed, processed and submitted to Cromwell as long as it has valid information. To give more information, here are some example inputs to the above endpoints: GET /api/v1/workload Request curl 'http://localhost:8080/api/v1/workload' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' GET /api/v1/workload?uuid={uuid} Request curl 'http://localhost:8080/api/v1/workload?uuid=00000000-0000-0000-0000-000000000000' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' GET /api/v1/workload?project={project} Request curl 'http://localhost:8080/api/v1/workload?project=(Test)%20WFL%20Local%20Testing' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' Note project and uuid are optional path parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together. GET /api/v1/workload/{uuid}/workflows Request curl 'http://localhost:8080/api/v1/workload/00000000-0000-0000-0000-000000000000/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) POST /api/v1/create Request curl -X POST 'http://localhost:8080/api/v1/create' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/aou-test-output/\", \"project\": \"Example Project\", \"pipeline\": \"AllOfUsArrays\" }' POST /api/v1/start Request curl -X POST 'http://localhost:8080/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\" }' POST /api/v1/stop Stops the workload from accepting new samples. See also: /api/v1/append_to_aou . Request curl -X POST 'http://localhost:8080/api/v1/stop' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\" }' POST /api/v1/workload/append_to_aou Request curl -X POST 'http://localhost:8080/api/v1/append_to_aou' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\", \"notifications\": [ { \"zcall_thresholds_file\": \"foo\", \"sample_lsid\": \"foo\", \"bead_pool_manifest_file\": \"foo\", \"chip_well_barcode\": \"foo\", \"sample_alias\": \"foo\", \"green_idat_cloud_path\": \"foo\", \"red_idat_cloud_path\": \"foo\", \"cluster_file\": \"foo\", \"reported_gender\": \"foo\", \"gender_cluster_file\": \"foo\", \"params_file\": \"foo\", \"extended_chip_manifest_file\": \"foo\", \"analysis_version_number\": 1 }, { \"zcall_thresholds_file\": \"foo\", \"sample_lsid\": \"foo\", \"bead_pool_manifest_file\": \"foo\", \"chip_well_barcode\": \"foo\", \"sample_alias\": \"foo\", \"green_idat_cloud_path\": \"foo\", \"red_idat_cloud_path\": \"foo\", \"cluster_file\": \"foo\", \"reported_gender\": \"foo\", \"gender_cluster_file\": \"foo\", \"params_file\": \"foo\", \"extended_chip_manifest_file\": \"foo\", \"analysis_version_number\": 5 } ] }'","title":"API"},{"location":"modules-aou-arrays/#workload-model","text":"WFL designed the following workload model in order to support the above API and workload submission mechanism. Initially, it has the following schema: List of relations Schema | Name | Type | Owner | Size | Description --------+--------------------------------+----------+----------+------------+------------- public | databasechangelog | table | foo | 16 kB | public | databasechangeloglock | table | foo | 8192 bytes | public | workload | table | foo | 16 kB | public | workload_id_seq | sequence | foo | 8192 bytes | the workload table looks like: id | commit | created | creator | cromwell | finished | input | items | output | pipeline | project | release | started | uuid | version | wdl ----+--------+---------+---------+----------+----------+-------+-------+--------+----------+---------+---------+---------+------+---------+----- (0 rows) Note that different from the fixed workload types, input , output and items are not useful to aou-arrays workload since these fields vary from sample to sample. Any information the caller provided to these fields will stored as placeholders. More importantly, even though id is the primary key here, (pipeline, project, release) works as the unique identifier for arrays workloads, for instance, if there's already a workload with values: (AllOfUsArrays, gotc-dev, Arrays_v1.9) , any further attempts to create a new workload with exact the same values will return the information of this existing workload rather than create a new row. Once the caller successfully creates a new sample, there will be a new row added to the above workload table, and a new table will be created accordingly: List of relations Schema | Name | Type | Owner | Size | Description --------+--------------------------------+----------+----------+------------+------------- public | allofusarrays_000000001 | table | foo | 16 kB | public | allofusarrays_000000001_id_seq | sequence | foo | 8192 bytes | public | databasechangelog | table | foo | 16 kB | public | databasechangeloglock | table | foo | 8192 bytes | public | workload | table | foo | 16 kB | public | workload_id_seq | sequence | foo | 8192 bytes | The allofusarrays_00000000X table has the following fields: id | analysis_version_number | chip_well_barcode | status | updated | uuid ----+-------------------------+-------------------+-----------+-------------------------------+-------------------------------------- 1 | 1 | 0000000000_R01C01 | Succeeded | 2020-07-21 00:00:00.241218-04 | 00000000-0000-0000-0000-000000000000 2 | 5 | 0000000000_R01C01 | Failed | 2020-07-21 00:00:00.028976-04 | 00000000-0000-0000-0000-000000000000 Among which (analysis_version_number, chip_well_barcode) works as the primary key , any new samples that collide with the existing primary-keys will be omitted.","title":"Workload Model"},{"location":"modules-covid/","text":"COVID module \u2693\ufe0e WorkFlow Launcher (WFL) uses the covid module to automate the sequencing of COVID-positive samples in Terra workspaces for better understanding of SARS-CoV-2 spread and evolution. For this processing, WFL follows a staged workload model which includes a source, executor, and sink. API Overview \u2693\ufe0e The covid module supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for workload uuid , filtering by supplied filters POST /api/v1/workload/{uuid}/retry Retry workflows matching given filters in workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload The life-cycle of a workload is a multi-stage process: The caller needs to create a workload and specify the source, executor, and sink. For continuous processing, the Source request is expected to have name Terra DataRepo and specify a Terra Data Repository (TDR) dataset to poll and snapshot. In one-off processing or development, we may instead use name TDR Snapshots Source to specify a list of existing TDR snapshots. The Executor request is expected to have name Terra and specify the Terra workspace configuration for executing workflows. The Sink request is expected to have name Terra Workspace and specify the Terra workspace configuration for saving workflow outputs. If all stage requests pass verification, in response the caller will receive the newly created workload object with an assigned uuid . Next, the caller needs to start the newly created workload, which will begin the analysis. Once started, WFL will continue to poll for new inputs to the source until it is stopped. WFL can, in addition, stop watching a workflow. This will not cancel analysis, but WFL will stop polling for new inputs to that workload, and will mark the workload finished once any previously-identified inputs have undergone processing. Example: the caller may wish to stop a continuous workflow if maintenance is required on the underlying method. The caller can also retry workflows in a workload matching a Terra submission ID and optional workflow status (ex. \"Failed\"). API Usage Examples \u2693\ufe0e Here you'll find example requests and responses for the endpoints enumerated above. Workload Response Format \u2693\ufe0e Many of the API endpoints return COVID workloads in their responses. An example workload response at the time of this writing is formatted thusly: { \"started\" : \"2021-07-14T15:36:47Z\", \"watchers\" : [ [\"slack\", \"C000XXX0XXX\"], [\"email\", \"okotsopo@broadinstitute.org\"] ], \"labels\" : [ \"hornet:test\", \"project:okotsopo testing enhanced source, executor, sink logging\" ], \"creator\" : \"okotsopo@broadinstitute.org\", \"updated\" : \"2021-08-06T21:41:28Z\", \"created\" : \"2021-07-14T15:36:07Z\", \"source\" : { \"snapshots\" : [ \"67a2bfd7-88e4-4adf-9e41-9b0d04fb32ea\" ], \"name\" : \"TDR Snapshots\" }, \"finished\" : \"2021-08-06T21:41:28Z\", \"commit\" : \"9719eda7424bf5b0804f5493875681fa014cdb29\", \"uuid\" : \"e66c86b2-120d-4f7f-9c3a-b9eaadeb1919\", \"executor\" : { \"workspace\" : \"wfl-dev/CDC_Viral_Sequencing_okotsopo_20210707\", \"methodConfiguration\" : \"wfl-dev/sarscov2_illumina_full\", \"methodConfigurationVersion\" : 41, \"fromSource\" : \"importSnapshot\", \"name\" : \"Terra\" }, \"version\" : \"0.8.0\", \"sink\" : { \"workspace\" : \"wfl-dev/CDC_Viral_Sequencing_okotsopo_20210707\", \"entityType\" : \"flowcell\", \"fromOutputs\" : { \"submission_xml\" : \"submission_xml\", \"assembled_ids\" : \"assembled_ids\", ... }, \"identifier\" : \"run_id\", \"name\" : \"Terra Workspace\" } } Worth mentioning is that the contents of the source , executor and sink blocks within the response will be formatted according to the corresponding stage implementation. Get Workloads \u2693\ufe0e Note A request to the /api/v1/workload endpoint without a uuid or project parameter returns all workloads known to WFL. That response might be large and take awhile to process. GET /api/v1/workload?uuid={uuid} Query WFL for a workload by its UUID. Note that a successful response from /api/v1/workload will always be an array of workload objects , but specifying a uuid will return a singleton array. Request curl -X GET 'http://localhost:3000/api/v1/workload' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Accept: application/json' \\ -d $'{ \"uuid\": \"e66c86b2-120d-4f7f-9c3a-b9eaadeb1919\" }' GET /api/v1/workload?project={project} Query WFL for all workloads with a specified project label. The response is an array of workload objects . Request curl -X GET 'http://localhost:3000/api/v1/workload' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Accept: application/json' \\ -d $'{ \"project\": \"PO-1234\" }' Get Workflows \u2693\ufe0e GET /api/v1/workload/{uuid}/workflows Query WFL for all unretried workflows associated with workload uuid . The response is a list of Firecloud-derived workflows and their outputs when available (when the workflow has succeeded). Request curl -X GET 'http://localhost:3000/api/v1/workload/8d67a71e-9afd-4fca-bcf6-a7a74984a0e8/workflows' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Accept: application/json' Response [ { \"inputs\" : { \"biosample_to_genbank.docker\" : \"quay.io/broadinstitute/viral-phylo:2.1.19.1\", \"instrument_model\" : \"Illumina NovaSeq 6000\", ... }, \"uuid\" : \"53f70344-6f0f-47fb-adee-4e780fb3f19a\", \"status\" : \"Failed\", \"outputs\" : { }, \"updated\" : \"2021-08-06T21:41:28Z\" } ] GET /api/v1/workload/{uuid}/workflows?submission={submission}&status={status} Query WFL for all unretried workflows associated with workload uuid , filtering by any workflow filters specified as query params: submission - Terra submission ID (must be a valid UUID) status - Workflow status (must be a valid Cromwell workflow status) The response has the same format as when querying without filters. Request curl -X GET 'http://localhost:3000/api/v1/workload/8d67a71e-9afd-4fca-bcf6-a7a74984a0e8/workflows?submission=14bffc69-6ce7-4615-b318-7ef1c457c894&status=Succeeded' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Accept: application/json' Retry Workload \u2693\ufe0e POST /api/v1/workload/{uuid}/retry Resubmit all unretried workflows associated with workload uuid and request body filters. Prerequisites: The request body filters must be valid Workflows must exist in the workload for the specified filters The workload should be started With all prerequisite fulfilled, WFL will then... Submit the retry to the executor (If necessary) remark the workload as active so that it will be visible in the update loop The response is the updated workload object . Further information found in general retry documentation . Request curl -X POST \"http://localhost:3000/api/v1/workload/e66c86b2-120d-4f7f-9c3a-b9eaadeb1919/retry\" \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H \"Content-Type: application/json\" \\ -d '{ \"submission\": \"14bffc69-6ce7-4615-b318-7ef1c457c894\" }' Create Workload \u2693\ufe0e POST /api/v1/create Create a new workload from a request. Expected request format documented within staged workload navigation. The response is the newly created workload object with an assigned uuid . Request curl -X \"POST\" \"http://localhost:3000/api/v1/create\" \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Content-Type: application/json' \\ -d '{ \"watchers\": [ [\"slack\", \"C000XXX0XXX\"], [\"email\", \"tester@broadinstitute.org\"] ], \"labels\": [ \"hornet:test\" ], \"project\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"source\": { \"name\": \"Terra DataRepo\", \"dataset\": \"4bb51d98-b4aa-4c72-b76a-1a96a2ee3057\", \"table\": \"flowcells\", \"column\": \"last_modified_date\", \"snapshotReaders\": [ \"workflow-launcher-dev@firecloud.org\" ] }, \"executor\": { \"name\": \"Terra\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"methodConfiguration\": \"wfl-dev/sarscov2_illumina_full\", \"methodConfigurationVersion\": 2, \"fromSource\": \"importSnapshot\" }, \"sink\": { \"name\": \"Terra Workspace\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"entityType\": \"flowcell\", \"identifier\": \"run_id\", \"fromOutputs\": { \"submission_xml\" : \"submission_xml\", \"assembled_ids\" : \"assembled_ids\", \"num_failed_assembly\" : \"num_failed_assembly\", ... } } }' Start Workload \u2693\ufe0e POST /api/v1/start?uuid={uuid} Start an existing, unstarted workload uuid . The response is the updated workload object . Request curl -X POST 'http://localhost:3000/api/v1/start' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"fb06bcf3-bc10-471b-a309-b2f99e4f5a67\" }' Stop Workload \u2693\ufe0e POST /api/v1/stop?uuid={uuid} Stop a running workload uuid . The response is the updated workload object . Request curl -X POST 'http://localhost:3000/api/v1/stop' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"fb06bcf3-bc10-471b-a309-b2f99e4f5a67\" }' Execute Workload \u2693\ufe0e POST /api/v1/exec Create and start (execute) a workload from a request. Expected request format documented within staged workload navigation. The response is the newly created and started workload object with an assigned uuid . Request curl -X \"POST\" \"http://localhost:3000/api/v1/exec\" \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Content-Type: application/json' \\ -d '{ \"watchers\": [ [\"slack\", \"C000XXX0XXX\"], [\"email\", \"tester@broadinstitute.org\"] ], \"labels\": [ \"hornet:test\" ], \"project\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"source\": { \"name\": \"Terra DataRepo\", \"dataset\": \"4bb51d98-b4aa-4c72-b76a-1a96a2ee3057\", \"table\": \"flowcells\", \"column\": \"last_modified_date\", \"snapshotReaders\": [ \"workflow-launcher-dev@firecloud.org\" ] }, \"executor\": { \"name\": \"Terra\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"methodConfiguration\": \"wfl-dev/sarscov2_illumina_full\", \"methodConfigurationVersion\": 2, \"fromSource\": \"importSnapshot\" }, \"sink\": { \"name\": \"Terra Workspace\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"entityType\": \"flowcell\", \"identifier\": \"run_id\", \"fromOutputs\": { \"submission_xml\" : \"submission_xml\", \"assembled_ids\" : \"assembled_ids\", \"num_failed_assembly\" : \"num_failed_assembly\", ... } } }'","title":"Covid"},{"location":"modules-covid/#covid-module","text":"WorkFlow Launcher (WFL) uses the covid module to automate the sequencing of COVID-positive samples in Terra workspaces for better understanding of SARS-CoV-2 spread and evolution. For this processing, WFL follows a staged workload model which includes a source, executor, and sink.","title":"COVID module"},{"location":"modules-covid/#api-overview","text":"The covid module supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for workload uuid , filtering by supplied filters POST /api/v1/workload/{uuid}/retry Retry workflows matching given filters in workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload The life-cycle of a workload is a multi-stage process: The caller needs to create a workload and specify the source, executor, and sink. For continuous processing, the Source request is expected to have name Terra DataRepo and specify a Terra Data Repository (TDR) dataset to poll and snapshot. In one-off processing or development, we may instead use name TDR Snapshots Source to specify a list of existing TDR snapshots. The Executor request is expected to have name Terra and specify the Terra workspace configuration for executing workflows. The Sink request is expected to have name Terra Workspace and specify the Terra workspace configuration for saving workflow outputs. If all stage requests pass verification, in response the caller will receive the newly created workload object with an assigned uuid . Next, the caller needs to start the newly created workload, which will begin the analysis. Once started, WFL will continue to poll for new inputs to the source until it is stopped. WFL can, in addition, stop watching a workflow. This will not cancel analysis, but WFL will stop polling for new inputs to that workload, and will mark the workload finished once any previously-identified inputs have undergone processing. Example: the caller may wish to stop a continuous workflow if maintenance is required on the underlying method. The caller can also retry workflows in a workload matching a Terra submission ID and optional workflow status (ex. \"Failed\").","title":"API Overview"},{"location":"modules-covid/#api-usage-examples","text":"Here you'll find example requests and responses for the endpoints enumerated above.","title":"API Usage Examples"},{"location":"modules-covid/#workload-response-format","text":"Many of the API endpoints return COVID workloads in their responses. An example workload response at the time of this writing is formatted thusly: { \"started\" : \"2021-07-14T15:36:47Z\", \"watchers\" : [ [\"slack\", \"C000XXX0XXX\"], [\"email\", \"okotsopo@broadinstitute.org\"] ], \"labels\" : [ \"hornet:test\", \"project:okotsopo testing enhanced source, executor, sink logging\" ], \"creator\" : \"okotsopo@broadinstitute.org\", \"updated\" : \"2021-08-06T21:41:28Z\", \"created\" : \"2021-07-14T15:36:07Z\", \"source\" : { \"snapshots\" : [ \"67a2bfd7-88e4-4adf-9e41-9b0d04fb32ea\" ], \"name\" : \"TDR Snapshots\" }, \"finished\" : \"2021-08-06T21:41:28Z\", \"commit\" : \"9719eda7424bf5b0804f5493875681fa014cdb29\", \"uuid\" : \"e66c86b2-120d-4f7f-9c3a-b9eaadeb1919\", \"executor\" : { \"workspace\" : \"wfl-dev/CDC_Viral_Sequencing_okotsopo_20210707\", \"methodConfiguration\" : \"wfl-dev/sarscov2_illumina_full\", \"methodConfigurationVersion\" : 41, \"fromSource\" : \"importSnapshot\", \"name\" : \"Terra\" }, \"version\" : \"0.8.0\", \"sink\" : { \"workspace\" : \"wfl-dev/CDC_Viral_Sequencing_okotsopo_20210707\", \"entityType\" : \"flowcell\", \"fromOutputs\" : { \"submission_xml\" : \"submission_xml\", \"assembled_ids\" : \"assembled_ids\", ... }, \"identifier\" : \"run_id\", \"name\" : \"Terra Workspace\" } } Worth mentioning is that the contents of the source , executor and sink blocks within the response will be formatted according to the corresponding stage implementation.","title":"Workload Response Format"},{"location":"modules-covid/#get-workloads","text":"Note A request to the /api/v1/workload endpoint without a uuid or project parameter returns all workloads known to WFL. That response might be large and take awhile to process. GET /api/v1/workload?uuid={uuid} Query WFL for a workload by its UUID. Note that a successful response from /api/v1/workload will always be an array of workload objects , but specifying a uuid will return a singleton array. Request curl -X GET 'http://localhost:3000/api/v1/workload' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Accept: application/json' \\ -d $'{ \"uuid\": \"e66c86b2-120d-4f7f-9c3a-b9eaadeb1919\" }' GET /api/v1/workload?project={project} Query WFL for all workloads with a specified project label. The response is an array of workload objects . Request curl -X GET 'http://localhost:3000/api/v1/workload' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Accept: application/json' \\ -d $'{ \"project\": \"PO-1234\" }'","title":"Get Workloads"},{"location":"modules-covid/#get-workflows","text":"GET /api/v1/workload/{uuid}/workflows Query WFL for all unretried workflows associated with workload uuid . The response is a list of Firecloud-derived workflows and their outputs when available (when the workflow has succeeded). Request curl -X GET 'http://localhost:3000/api/v1/workload/8d67a71e-9afd-4fca-bcf6-a7a74984a0e8/workflows' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Accept: application/json' Response [ { \"inputs\" : { \"biosample_to_genbank.docker\" : \"quay.io/broadinstitute/viral-phylo:2.1.19.1\", \"instrument_model\" : \"Illumina NovaSeq 6000\", ... }, \"uuid\" : \"53f70344-6f0f-47fb-adee-4e780fb3f19a\", \"status\" : \"Failed\", \"outputs\" : { }, \"updated\" : \"2021-08-06T21:41:28Z\" } ] GET /api/v1/workload/{uuid}/workflows?submission={submission}&status={status} Query WFL for all unretried workflows associated with workload uuid , filtering by any workflow filters specified as query params: submission - Terra submission ID (must be a valid UUID) status - Workflow status (must be a valid Cromwell workflow status) The response has the same format as when querying without filters. Request curl -X GET 'http://localhost:3000/api/v1/workload/8d67a71e-9afd-4fca-bcf6-a7a74984a0e8/workflows?submission=14bffc69-6ce7-4615-b318-7ef1c457c894&status=Succeeded' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Accept: application/json'","title":"Get Workflows"},{"location":"modules-covid/#retry-workload","text":"POST /api/v1/workload/{uuid}/retry Resubmit all unretried workflows associated with workload uuid and request body filters. Prerequisites: The request body filters must be valid Workflows must exist in the workload for the specified filters The workload should be started With all prerequisite fulfilled, WFL will then... Submit the retry to the executor (If necessary) remark the workload as active so that it will be visible in the update loop The response is the updated workload object . Further information found in general retry documentation . Request curl -X POST \"http://localhost:3000/api/v1/workload/e66c86b2-120d-4f7f-9c3a-b9eaadeb1919/retry\" \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H \"Content-Type: application/json\" \\ -d '{ \"submission\": \"14bffc69-6ce7-4615-b318-7ef1c457c894\" }'","title":"Retry Workload"},{"location":"modules-covid/#create-workload","text":"POST /api/v1/create Create a new workload from a request. Expected request format documented within staged workload navigation. The response is the newly created workload object with an assigned uuid . Request curl -X \"POST\" \"http://localhost:3000/api/v1/create\" \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Content-Type: application/json' \\ -d '{ \"watchers\": [ [\"slack\", \"C000XXX0XXX\"], [\"email\", \"tester@broadinstitute.org\"] ], \"labels\": [ \"hornet:test\" ], \"project\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"source\": { \"name\": \"Terra DataRepo\", \"dataset\": \"4bb51d98-b4aa-4c72-b76a-1a96a2ee3057\", \"table\": \"flowcells\", \"column\": \"last_modified_date\", \"snapshotReaders\": [ \"workflow-launcher-dev@firecloud.org\" ] }, \"executor\": { \"name\": \"Terra\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"methodConfiguration\": \"wfl-dev/sarscov2_illumina_full\", \"methodConfigurationVersion\": 2, \"fromSource\": \"importSnapshot\" }, \"sink\": { \"name\": \"Terra Workspace\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"entityType\": \"flowcell\", \"identifier\": \"run_id\", \"fromOutputs\": { \"submission_xml\" : \"submission_xml\", \"assembled_ids\" : \"assembled_ids\", \"num_failed_assembly\" : \"num_failed_assembly\", ... } } }'","title":"Create Workload"},{"location":"modules-covid/#start-workload","text":"POST /api/v1/start?uuid={uuid} Start an existing, unstarted workload uuid . The response is the updated workload object . Request curl -X POST 'http://localhost:3000/api/v1/start' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"fb06bcf3-bc10-471b-a309-b2f99e4f5a67\" }'","title":"Start Workload"},{"location":"modules-covid/#stop-workload","text":"POST /api/v1/stop?uuid={uuid} Stop a running workload uuid . The response is the updated workload object . Request curl -X POST 'http://localhost:3000/api/v1/stop' \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"fb06bcf3-bc10-471b-a309-b2f99e4f5a67\" }'","title":"Stop Workload"},{"location":"modules-covid/#execute-workload","text":"POST /api/v1/exec Create and start (execute) a workload from a request. Expected request format documented within staged workload navigation. The response is the newly created and started workload object with an assigned uuid . Request curl -X \"POST\" \"http://localhost:3000/api/v1/exec\" \\ -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\ -H 'Content-Type: application/json' \\ -d '{ \"watchers\": [ [\"slack\", \"C000XXX0XXX\"], [\"email\", \"tester@broadinstitute.org\"] ], \"labels\": [ \"hornet:test\" ], \"project\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"source\": { \"name\": \"Terra DataRepo\", \"dataset\": \"4bb51d98-b4aa-4c72-b76a-1a96a2ee3057\", \"table\": \"flowcells\", \"column\": \"last_modified_date\", \"snapshotReaders\": [ \"workflow-launcher-dev@firecloud.org\" ] }, \"executor\": { \"name\": \"Terra\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"methodConfiguration\": \"wfl-dev/sarscov2_illumina_full\", \"methodConfigurationVersion\": 2, \"fromSource\": \"importSnapshot\" }, \"sink\": { \"name\": \"Terra Workspace\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing _ranthony_bashing_copy\", \"entityType\": \"flowcell\", \"identifier\": \"run_id\", \"fromOutputs\": { \"submission_xml\" : \"submission_xml\", \"assembled_ids\" : \"assembled_ids\", \"num_failed_assembly\" : \"num_failed_assembly\", ... } } }'","title":"Execute Workload"},{"location":"modules-external-exome-reprocessing/","text":"External Exome Reprocessing workload \u2693\ufe0e Inputs \u2693\ufe0e An ExternalExomeReprocessing workload requires the specification of exactly one the following inputs for each workflow: input_bam , OR input_cram Where input_bam and input_cram are GS URLs of the file to reprocess. Note that the input_bam and input_cram inputs should only be used with CRAM and BAM files, respectively. All other WDL inputs are optional - see the output below for all options. Usage \u2693\ufe0e External Exome Reprocessing workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Exome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions. Create Workload: POST /api/v1/create \u2693\ufe0e Create a new workload. Ensure that workflow-launcher and cromwell 's service accounts have at least read access to the input files. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/create' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\", \"pipeline\": \"ExternalExomeReprocessing\", \"project\": \"Example Project\", \"items\": [{ \"inputs\": { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" } }] }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Note that the ExternalExomeReprocessing pipeline supports specifying cromwell \"workflowOptions\" via the options map. See the reference page for more information. Start Workload: POST /api/v1/start \u2693\ufe0e Starts a Cromwell workflow for each item in the workload. If an output already exists in the output bucket for a particular input cram, WFL will not re-submit that workflow. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/start' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{\"uuid\": \"1337254e-f7d8-438d-a2b3-a74b199fee3c\"}' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Stop Workload: POST /api/v1/stop \u2693\ufe0e Included for compatibility with continuous workloads. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/stop' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"started\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"stopped\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Exec Workload: POST /api/v1/exec \u2693\ufe0e Creates and then starts a Cromwell workflow for each item in the workload. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\", \"pipeline\": \"ExternalExomeReprocessing\", \"project\": \"Example Project\", \"items\": [{ \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", } }] }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Query Workload: GET /api/v1/workload?uuid=<uuid> \u2693\ufe0e Queries the WFL database for workloads. Specify the uuid to query for a specific workload. Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?uuid=1337254e-f7d8-438d-a2b3-a74b199fee3c' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }] Query Workload with project: GET /api/v1/workload?project=<project> \u2693\ufe0e Queries the WFL database for workloads. Specify the project name to query for a list of specific workload(s). Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?project=PO-1234' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }] Note project and uuid are optional query parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together. List Workflows in a Workload: GET /api/v1/workload/{uuid}/workflows \u2693\ufe0e Returns the workflows created and managed by the workload with uuid . Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload/1337254e-f7d8-438d-a2b3-a74b199fee3c/workflows' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"status\" : \"Submitted\" , \"updated\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"uuid\" : \"bb0d93e3-1a6a-4816-82d9-713fa58fb235\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"destination_cloud_path\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/8600be1a-48df-4a51-bdba-0044e0af8d33/single_sample/plumbing/truth/develop/20k\" , \"sample_name\" : \"NA12878_PLUMBING\" , \"base_file_name\" : \"NA12878_PLUMBING.cram\" , \"final_gvcf_base_name\" : \"NA12878_PLUMBING.cram\" } }] \"workflows\" lists out each workflow managed by this workload, including their status. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures. A1 External Exome Workload-Request JSON Spec \u2693\ufe0e { \"pipeline\" : \"string\" , \"executor\" : \"string\" , \"output\" : \"string\" , \"project\" : \"string\" , \"common\" : { \"options\" : {}, // see work fl ow - op t io ns \"inputs\" : { \"unmapped_bam_suffix\" : \"string\" , \"cram_ref_fasta\" : \"string\" , \"cram_ref_fasta_index\" : \"string\" , \"bait_set_name\" : \"string\" , \"bait_interval_list\" : \"string\" , \"target_interval_list\" : \"string\" , \"references\" : { \"calling_interval_list\" : \"string\" , \"contamination_sites_bed\" : \"string\" , \"contamination_sites_mu\" : \"string\" , \"contamination_sites_ud\" : \"string\" , \"dbsnp_vcf\" : \"string\" , \"dbsnp_vcf_index\" : \"string\" , \"evaluation_interval_list\" : \"string\" , \"haplotype_database_file\" : \"string\" , \"known_indels_sites_vcfs\" : [ \"string\" ], \"known_indels_sites_indices\" : [ \"string\" ], \"reference_fasta\" : { \"ref_pac\" : \"string\" , \"ref_bwt\" : \"string\" , \"ref_dict\" : \"string\" , \"ref_ann\" : \"string\" , \"ref_fasta_index\" : \"string\" , \"ref_alt\" : \"string\" , \"ref_fasta\" : \"string\" , \"ref_sa\" : \"string\" , \"ref_amb\" : \"string\" } }, \"scatter_settings\" : { \"haplotype_scatter_count\" : \"integer\" , \"break_bands_at_multiples_of\" : \"integer\" }, \"papi_settings\" : { \"agg_preemptible_tries\" : \"integer\" , \"preemptible_tries\" : \"integer\" }, \"fingerprint_genotypes_file\" : \"string\" , \"fingerprint_genotypes_index\" : \"string\" } }, \"items\" : [{ \"options\" : {}, // see work fl ow - op t io ns \"inputs\" : { // required - speci f y ei t her \"input_bam\" or \"input_cram\" \"input_bam\" : \"string\" , \"input_cram\" : \"string\" , // op t io nal i n pu ts \"sample_name\" : \"string\" , \"final_gvcf_base_name\" : \"string\" , \"unmapped_bam_suffix\" : \"string\" , \"cram_ref_fasta\" : \"string\" , \"cram_ref_fasta_index\" : \"string\" , \"bait_set_name\" : \"string\" , \"bait_interval_list\" : \"string\" , \"target_interval_list\" : \"string\" , \"references\" : { \"calling_interval_list\" : \"string\" , \"contamination_sites_bed\" : \"string\" , \"contamination_sites_mu\" : \"string\" , \"contamination_sites_ud\" : \"string\" , \"dbsnp_vcf\" : \"string\" , \"dbsnp_vcf_index\" : \"string\" , \"evaluation_interval_list\" : \"string\" , \"haplotype_database_file\" : \"string\" , \"known_indels_sites_vcfs\" : [ \"string\" ], \"known_indels_sites_indices\" : [ \"string\" ], \"reference_fasta\" : { \"ref_pac\" : \"string\" , \"ref_bwt\" : \"string\" , \"ref_dict\" : \"string\" , \"ref_ann\" : \"string\" , \"ref_fasta_index\" : \"string\" , \"ref_alt\" : \"string\" , \"ref_fasta\" : \"string\" , \"ref_sa\" : \"string\" , \"ref_amb\" : \"string\" } }, \"scatter_settings\" : { \"haplotype_scatter_count\" : \"integer\" , \"break_bands_at_multiples_of\" : \"integer\" }, \"papi_settings\" : { \"agg_preemptible_tries\" : \"integer\" , \"preemptible_tries\" : \"integer\" }, \"fingerprint_genotypes_file\" : \"string\" , \"fingerprint_genotypes_index\" : \"string\" , \"destination_cloud_path\" : \"string\" } }] }","title":"External Exome"},{"location":"modules-external-exome-reprocessing/#external-exome-reprocessing-workload","text":"","title":"External Exome Reprocessing workload"},{"location":"modules-external-exome-reprocessing/#inputs","text":"An ExternalExomeReprocessing workload requires the specification of exactly one the following inputs for each workflow: input_bam , OR input_cram Where input_bam and input_cram are GS URLs of the file to reprocess. Note that the input_bam and input_cram inputs should only be used with CRAM and BAM files, respectively. All other WDL inputs are optional - see the output below for all options.","title":"Inputs"},{"location":"modules-external-exome-reprocessing/#usage","text":"External Exome Reprocessing workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Exome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions.","title":"Usage"},{"location":"modules-external-exome-reprocessing/#create-workload-post-apiv1create","text":"Create a new workload. Ensure that workflow-launcher and cromwell 's service accounts have at least read access to the input files. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/create' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\", \"pipeline\": \"ExternalExomeReprocessing\", \"project\": \"Example Project\", \"items\": [{ \"inputs\": { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" } }] }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Note that the ExternalExomeReprocessing pipeline supports specifying cromwell \"workflowOptions\" via the options map. See the reference page for more information.","title":"Create Workload: POST /api/v1/create"},{"location":"modules-external-exome-reprocessing/#start-workload-post-apiv1start","text":"Starts a Cromwell workflow for each item in the workload. If an output already exists in the output bucket for a particular input cram, WFL will not re-submit that workflow. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/start' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{\"uuid\": \"1337254e-f7d8-438d-a2b3-a74b199fee3c\"}' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }","title":"Start Workload: POST /api/v1/start"},{"location":"modules-external-exome-reprocessing/#stop-workload-post-apiv1stop","text":"Included for compatibility with continuous workloads. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/stop' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"started\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"stopped\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }","title":"Stop Workload: POST /api/v1/stop"},{"location":"modules-external-exome-reprocessing/#exec-workload-post-apiv1exec","text":"Creates and then starts a Cromwell workflow for each item in the workload. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\", \"pipeline\": \"ExternalExomeReprocessing\", \"project\": \"Example Project\", \"items\": [{ \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", } }] }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }","title":"Exec Workload: POST /api/v1/exec"},{"location":"modules-external-exome-reprocessing/#query-workload-get-apiv1workloaduuiduuid","text":"Queries the WFL database for workloads. Specify the uuid to query for a specific workload. Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?uuid=1337254e-f7d8-438d-a2b3-a74b199fee3c' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }]","title":"Query Workload: GET /api/v1/workload?uuid=&lt;uuid&gt;"},{"location":"modules-external-exome-reprocessing/#query-workload-with-project-get-apiv1workloadprojectproject","text":"Queries the WFL database for workloads. Specify the project name to query for a list of specific workload(s). Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?project=PO-1234' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }] Note project and uuid are optional query parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together.","title":"Query Workload with project: GET /api/v1/workload?project=&lt;project&gt;"},{"location":"modules-external-exome-reprocessing/#list-workflows-in-a-workload-get-apiv1workloaduuidworkflows","text":"Returns the workflows created and managed by the workload with uuid . Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload/1337254e-f7d8-438d-a2b3-a74b199fee3c/workflows' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"status\" : \"Submitted\" , \"updated\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"uuid\" : \"bb0d93e3-1a6a-4816-82d9-713fa58fb235\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"destination_cloud_path\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/8600be1a-48df-4a51-bdba-0044e0af8d33/single_sample/plumbing/truth/develop/20k\" , \"sample_name\" : \"NA12878_PLUMBING\" , \"base_file_name\" : \"NA12878_PLUMBING.cram\" , \"final_gvcf_base_name\" : \"NA12878_PLUMBING.cram\" } }] \"workflows\" lists out each workflow managed by this workload, including their status. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures.","title":"List Workflows in a Workload: GET /api/v1/workload/{uuid}/workflows"},{"location":"modules-external-exome-reprocessing/#a1-external-exome-workload-request-json-spec","text":"{ \"pipeline\" : \"string\" , \"executor\" : \"string\" , \"output\" : \"string\" , \"project\" : \"string\" , \"common\" : { \"options\" : {}, // see work fl ow - op t io ns \"inputs\" : { \"unmapped_bam_suffix\" : \"string\" , \"cram_ref_fasta\" : \"string\" , \"cram_ref_fasta_index\" : \"string\" , \"bait_set_name\" : \"string\" , \"bait_interval_list\" : \"string\" , \"target_interval_list\" : \"string\" , \"references\" : { \"calling_interval_list\" : \"string\" , \"contamination_sites_bed\" : \"string\" , \"contamination_sites_mu\" : \"string\" , \"contamination_sites_ud\" : \"string\" , \"dbsnp_vcf\" : \"string\" , \"dbsnp_vcf_index\" : \"string\" , \"evaluation_interval_list\" : \"string\" , \"haplotype_database_file\" : \"string\" , \"known_indels_sites_vcfs\" : [ \"string\" ], \"known_indels_sites_indices\" : [ \"string\" ], \"reference_fasta\" : { \"ref_pac\" : \"string\" , \"ref_bwt\" : \"string\" , \"ref_dict\" : \"string\" , \"ref_ann\" : \"string\" , \"ref_fasta_index\" : \"string\" , \"ref_alt\" : \"string\" , \"ref_fasta\" : \"string\" , \"ref_sa\" : \"string\" , \"ref_amb\" : \"string\" } }, \"scatter_settings\" : { \"haplotype_scatter_count\" : \"integer\" , \"break_bands_at_multiples_of\" : \"integer\" }, \"papi_settings\" : { \"agg_preemptible_tries\" : \"integer\" , \"preemptible_tries\" : \"integer\" }, \"fingerprint_genotypes_file\" : \"string\" , \"fingerprint_genotypes_index\" : \"string\" } }, \"items\" : [{ \"options\" : {}, // see work fl ow - op t io ns \"inputs\" : { // required - speci f y ei t her \"input_bam\" or \"input_cram\" \"input_bam\" : \"string\" , \"input_cram\" : \"string\" , // op t io nal i n pu ts \"sample_name\" : \"string\" , \"final_gvcf_base_name\" : \"string\" , \"unmapped_bam_suffix\" : \"string\" , \"cram_ref_fasta\" : \"string\" , \"cram_ref_fasta_index\" : \"string\" , \"bait_set_name\" : \"string\" , \"bait_interval_list\" : \"string\" , \"target_interval_list\" : \"string\" , \"references\" : { \"calling_interval_list\" : \"string\" , \"contamination_sites_bed\" : \"string\" , \"contamination_sites_mu\" : \"string\" , \"contamination_sites_ud\" : \"string\" , \"dbsnp_vcf\" : \"string\" , \"dbsnp_vcf_index\" : \"string\" , \"evaluation_interval_list\" : \"string\" , \"haplotype_database_file\" : \"string\" , \"known_indels_sites_vcfs\" : [ \"string\" ], \"known_indels_sites_indices\" : [ \"string\" ], \"reference_fasta\" : { \"ref_pac\" : \"string\" , \"ref_bwt\" : \"string\" , \"ref_dict\" : \"string\" , \"ref_ann\" : \"string\" , \"ref_fasta_index\" : \"string\" , \"ref_alt\" : \"string\" , \"ref_fasta\" : \"string\" , \"ref_sa\" : \"string\" , \"ref_amb\" : \"string\" } }, \"scatter_settings\" : { \"haplotype_scatter_count\" : \"integer\" , \"break_bands_at_multiples_of\" : \"integer\" }, \"papi_settings\" : { \"agg_preemptible_tries\" : \"integer\" , \"preemptible_tries\" : \"integer\" }, \"fingerprint_genotypes_file\" : \"string\" , \"fingerprint_genotypes_index\" : \"string\" , \"destination_cloud_path\" : \"string\" } }] }","title":"A1 External Exome Workload-Request JSON Spec"},{"location":"modules-general/","text":"Modules Design Principles and Assumptions \u2693\ufe0e WorkFlow Launcher is responsible for preparing the required workflow WDLs, inputs and options for Cromwell in a large scale. This work involves in inputs validation, pipeline WDL orchestration and Cromwell workflow management. Similar to other WFL modules, the aou-arrays module takes advantage of the workload concept in order to manage workflows efficiently. In general, WFL classify all workloads into 2 categories: continuous and fixed. For instance, aou-arrays module implements arrays workload as a continuous workload, which means all samples are coming in like a continuous stream, and WFL does not make any assumption of how many samples will be in the workload or how to group the samples together: it hands off the workload creation and starting process to its caller. wgs module implements External Whole Genome workloads as a discrete workload that WFL has full knowledge about the number and properties of the samples it's going to process, and the samples can be grouped into batches (workloads) by a set of properties. To learn more about the details of each module, please check their own sections in this documentation. Create a workload \u2693\ufe0e Defining a workload type usually requires these top-level parameters. Parameter Type Required executor URL output URL prefix pipeline pipeline project text common object input URL prefix items object The parameters are used this way. The executor URL specifies the Cromwell instance or other execution engine to service the workload . The output URL prefix specifies the path you'd like WFL to dump the results to. It usually is a gs bucket. The pipeline enumeration implicitly identifies a data schema for the inputs to and outputs from the workload. You can think of it as the kind of workflow specified for the workload. People sometimes refer to this as the tag in that it is a well-known name for a Cromwell pipeline defined in WDL. You might also think of pipeline as the external or official name of a WFL processing module. The project is just some text to identify a researcher, billing entity, or cost object responsible for the workload. The common is something common for all of the samples, such as the workflow options. For more details, check the docs for the specific type of workload you are trying to submit. The input URL prefix specifies the path you'd like WFL to read (a batch of) sample(s) from. It usually is a gs bucket. The items is used to configure individual units of a workload. You can use it to tell WFL to treat arbitrary parts of the workload sepcially. For more details, check the docs for the specific type of workload you are trying to submit.","title":"Overview"},{"location":"modules-general/#modules-design-principles-and-assumptions","text":"WorkFlow Launcher is responsible for preparing the required workflow WDLs, inputs and options for Cromwell in a large scale. This work involves in inputs validation, pipeline WDL orchestration and Cromwell workflow management. Similar to other WFL modules, the aou-arrays module takes advantage of the workload concept in order to manage workflows efficiently. In general, WFL classify all workloads into 2 categories: continuous and fixed. For instance, aou-arrays module implements arrays workload as a continuous workload, which means all samples are coming in like a continuous stream, and WFL does not make any assumption of how many samples will be in the workload or how to group the samples together: it hands off the workload creation and starting process to its caller. wgs module implements External Whole Genome workloads as a discrete workload that WFL has full knowledge about the number and properties of the samples it's going to process, and the samples can be grouped into batches (workloads) by a set of properties. To learn more about the details of each module, please check their own sections in this documentation.","title":"Modules Design Principles and Assumptions"},{"location":"modules-general/#create-a-workload","text":"Defining a workload type usually requires these top-level parameters. Parameter Type Required executor URL output URL prefix pipeline pipeline project text common object input URL prefix items object The parameters are used this way. The executor URL specifies the Cromwell instance or other execution engine to service the workload . The output URL prefix specifies the path you'd like WFL to dump the results to. It usually is a gs bucket. The pipeline enumeration implicitly identifies a data schema for the inputs to and outputs from the workload. You can think of it as the kind of workflow specified for the workload. People sometimes refer to this as the tag in that it is a well-known name for a Cromwell pipeline defined in WDL. You might also think of pipeline as the external or official name of a WFL processing module. The project is just some text to identify a researcher, billing entity, or cost object responsible for the workload. The common is something common for all of the samples, such as the workflow options. For more details, check the docs for the specific type of workload you are trying to submit. The input URL prefix specifies the path you'd like WFL to read (a batch of) sample(s) from. It usually is a gs bucket. The items is used to configure individual units of a workload. You can use it to tell WFL to treat arbitrary parts of the workload sepcially. For more details, check the docs for the specific type of workload you are trying to submit.","title":"Create a workload"},{"location":"modules-sg/","text":"GDCWholeGenomeSomaticSingleSample \u2693\ufe0e Inputs \u2693\ufe0e In addition to the standard workload request inputs: executor : URL of the Cromwell service output : GCS URL prefix for output files pipeline : literally \"GDCWholeGenomeSomaticSingleSample\" project : some tracking label you can choose a GDCWholeGenomeSomaticSingleSample workload requires the following inputs for each workflow. base_file_name contamination_vcf_index contamination_vcf cram_ref_fasta_index cram_ref_fasta dbsnp_vcf_index dbsnp_vcf input_cram Here is what those are. base_file_name \u2693\ufe0e The leaf name of a sample input or output path without the . suffix. The base_file_name is usually the same as the sample name and differs in every workflow. contamination_vcf_index and contamination_vcf \u2693\ufe0e These are GCS pathnames of the contamination detection data for the input samples. This commonly depends on the reference genome for the samples, and is shared across all the workflows. cram_ref_fasta_index and cram_ref_fasta \u2693\ufe0e These are GCS pathnames of the reference FASTA to which the input CRAM is aligned. This FASTA is used to expand CRAMs to BAMs and again is generally shared across all the workflows. dbsnp_vcf_index and dbsnp_vcf \u2693\ufe0e These are GCS pathnames of a VCF containing a database of known variants from the reference. As with the contamination and reference FASTA files, typically these are shared across all the workflows. input_cram \u2693\ufe0e This is a GCS pathname to the input CRAM. It's last component will typically be the base_file_name value with \".cram\" appended. The GDCWholeGenomeSomaticSingleSample.wdl workflow definition expects to find a base_file_name.cram.crai file for every base_file_name.cram file specified as an input_cram . Usage \u2693\ufe0e GDCWholeGenomeSomaticSingleSample workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Whole Genome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions. Create Workload: /api/v1/create \u2693\ufe0e Create a WFL workload running in production. Request curl -- loca t io n -- reques t POST \\ h tt ps : //go t c - prod - w fl .go t c - prod.broadi nst i tute .org/api/v 1 /crea te \\ -- header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -- header 'Co ntent - Type : applica t io n /jso n ' \\ -- da ta - raw ' { \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"items\" : [ { \"inputs\" : { \"base_file_name\" : \"27B-6\" , \"contamination_vcf\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz\" , \"contamination_vcf_index\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi\" , \"cram_ref_fasta\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\" , \"cram_ref_fasta_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai\" , \"dbsnp_vcf\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz\" , \"dbsnp_vcf_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz.tbi\" , \"input_cram\" : \"gs://broad-gotc-prod-storage/pipeline/PO-1234/27B-6/v1/27B-6.cram\" }, \"options\" : { \"monitoring_script\" : \"gs://broad-gotc-prod-storage/scripts/monitoring_script.sh\" } } ] } ' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } Note that the GDCWholeGenomeSomaticSingleSample pipeline supports Cromwell workflowOptions via the options map. See the reference page for more information. Start Workload: /api/v1/start \u2693\ufe0e Start all the workflows in the workload. Request curl --location --request POST \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/start \\ --header \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ --header 'Content-Type: application/json' \\ --data-raw '{\"uuid\": \"efb00901-378e-4365-86e7-edd0fbdaaab2\"}' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } Start Workload: /api/v1/start \u2693\ufe0e Included for compatibility with continuous workloads. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/stop' \\ -X \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -X 'Content-Type: application/json' \\ -d '{ \"uuid\": \"efb00901-378e-4365-86e7-edd0fbdaaab2\" }' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"stopped\" : \"2021-04-05T16:02:33Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } Exec Workload: /api/v1/exec \u2693\ufe0e Create a workload, then start every workflow in the workload. Except for the different WFL URI, the request and response are the same as for Create Workload above. curl --location --request POST \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/exec \\ ... and so on ... Query Workload: /api/v1/workload?uuid=<uuid> \u2693\ufe0e Query WFL for a workload by its UUID. Request curl --location --request GET \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?uuid = efb00901-378e-4365-86e7-edd0fbdaaab2 \\ --header 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response A successful response from /api/v1/workload is always an array of workload objects, but specifying a UUID returns only one. [ { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } ] Query Workload with project: /api/v1/workload?project=<project> \u2693\ufe0e Query WFL for all workloads with a specified project label. curl --location --request GET \\ /api/v1/workload?project = wgs-dev \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?project = PO-1234 \\ --header 'Authorization: Bearer ' $( gcloud auth print-access-token ) The response is the same as when specifying a UUID, except the array may contain multiple workload objects that share the same project value. Note A request to the /api/v1/workload endpoint without a project or uuid parameter returns all of the workloads that WFL knows about. That response might be large and take a while to process. List workflows managed by the workload GET /api/v1/workload/{uuid}/workflows \u2693\ufe0e Request curl -X GET '/api/v1/workload/efb00901-378e-4365-86e7-edd0fbdaaab2/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response A successful response from /api/v1/workload/{uuid}/workload is always an array of Cromwell workflows with their statuses. [{ \"status\" : \"Submitted\" , \"updated\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"8c1f586e-036b-4690-87c2-2af5d7e00450\" , \"inputs\" : { \"base_file_name\" : \"27B-6\" , \"contamination_vcf\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz\" , \"contamination_vcf_index\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi\" , \"cram_ref_fasta\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\" , \"cram_ref_fasta_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai\" , \"dbsnp_vcf\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz\" , \"dbsnp_vcf_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz.tbi\" , \"input_cram\" : \"gs://broad-gotc-prod-storage/pipeline/PO-1234/27B-6/v1/27B-6.cram\" }, \"options\" : { \"monitoring_script\" : \"gs://broad-gotc-prod-storage/scripts/monitoring_script.sh\" } }]","title":"Somatic Genomes"},{"location":"modules-sg/#gdcwholegenomesomaticsinglesample","text":"","title":"GDCWholeGenomeSomaticSingleSample"},{"location":"modules-sg/#inputs","text":"In addition to the standard workload request inputs: executor : URL of the Cromwell service output : GCS URL prefix for output files pipeline : literally \"GDCWholeGenomeSomaticSingleSample\" project : some tracking label you can choose a GDCWholeGenomeSomaticSingleSample workload requires the following inputs for each workflow. base_file_name contamination_vcf_index contamination_vcf cram_ref_fasta_index cram_ref_fasta dbsnp_vcf_index dbsnp_vcf input_cram Here is what those are.","title":"Inputs"},{"location":"modules-sg/#base_file_name","text":"The leaf name of a sample input or output path without the . suffix. The base_file_name is usually the same as the sample name and differs in every workflow.","title":"base_file_name"},{"location":"modules-sg/#contamination_vcf_index-and-contamination_vcf","text":"These are GCS pathnames of the contamination detection data for the input samples. This commonly depends on the reference genome for the samples, and is shared across all the workflows.","title":"contamination_vcf_index and contamination_vcf"},{"location":"modules-sg/#cram_ref_fasta_index-and-cram_ref_fasta","text":"These are GCS pathnames of the reference FASTA to which the input CRAM is aligned. This FASTA is used to expand CRAMs to BAMs and again is generally shared across all the workflows.","title":"cram_ref_fasta_index and cram_ref_fasta"},{"location":"modules-sg/#dbsnp_vcf_index-and-dbsnp_vcf","text":"These are GCS pathnames of a VCF containing a database of known variants from the reference. As with the contamination and reference FASTA files, typically these are shared across all the workflows.","title":"dbsnp_vcf_index and dbsnp_vcf"},{"location":"modules-sg/#input_cram","text":"This is a GCS pathname to the input CRAM. It's last component will typically be the base_file_name value with \".cram\" appended. The GDCWholeGenomeSomaticSingleSample.wdl workflow definition expects to find a base_file_name.cram.crai file for every base_file_name.cram file specified as an input_cram .","title":"input_cram"},{"location":"modules-sg/#usage","text":"GDCWholeGenomeSomaticSingleSample workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Whole Genome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions.","title":"Usage"},{"location":"modules-sg/#create-workload-apiv1create","text":"Create a WFL workload running in production. Request curl -- loca t io n -- reques t POST \\ h tt ps : //go t c - prod - w fl .go t c - prod.broadi nst i tute .org/api/v 1 /crea te \\ -- header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -- header 'Co ntent - Type : applica t io n /jso n ' \\ -- da ta - raw ' { \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"items\" : [ { \"inputs\" : { \"base_file_name\" : \"27B-6\" , \"contamination_vcf\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz\" , \"contamination_vcf_index\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi\" , \"cram_ref_fasta\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\" , \"cram_ref_fasta_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai\" , \"dbsnp_vcf\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz\" , \"dbsnp_vcf_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz.tbi\" , \"input_cram\" : \"gs://broad-gotc-prod-storage/pipeline/PO-1234/27B-6/v1/27B-6.cram\" }, \"options\" : { \"monitoring_script\" : \"gs://broad-gotc-prod-storage/scripts/monitoring_script.sh\" } } ] } ' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } Note that the GDCWholeGenomeSomaticSingleSample pipeline supports Cromwell workflowOptions via the options map. See the reference page for more information.","title":"Create Workload: /api/v1/create"},{"location":"modules-sg/#start-workload-apiv1start","text":"Start all the workflows in the workload. Request curl --location --request POST \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/start \\ --header \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ --header 'Content-Type: application/json' \\ --data-raw '{\"uuid\": \"efb00901-378e-4365-86e7-edd0fbdaaab2\"}' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" }","title":"Start Workload: /api/v1/start"},{"location":"modules-sg/#start-workload-apiv1start_1","text":"Included for compatibility with continuous workloads. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/stop' \\ -X \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -X 'Content-Type: application/json' \\ -d '{ \"uuid\": \"efb00901-378e-4365-86e7-edd0fbdaaab2\" }' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"stopped\" : \"2021-04-05T16:02:33Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" }","title":"Start Workload: /api/v1/start"},{"location":"modules-sg/#exec-workload-apiv1exec","text":"Create a workload, then start every workflow in the workload. Except for the different WFL URI, the request and response are the same as for Create Workload above. curl --location --request POST \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/exec \\ ... and so on ...","title":"Exec Workload: /api/v1/exec"},{"location":"modules-sg/#query-workload-apiv1workloaduuiduuid","text":"Query WFL for a workload by its UUID. Request curl --location --request GET \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?uuid = efb00901-378e-4365-86e7-edd0fbdaaab2 \\ --header 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response A successful response from /api/v1/workload is always an array of workload objects, but specifying a UUID returns only one. [ { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } ]","title":"Query Workload: /api/v1/workload?uuid=&lt;uuid&gt;"},{"location":"modules-sg/#query-workload-with-project-apiv1workloadprojectproject","text":"Query WFL for all workloads with a specified project label. curl --location --request GET \\ /api/v1/workload?project = wgs-dev \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?project = PO-1234 \\ --header 'Authorization: Bearer ' $( gcloud auth print-access-token ) The response is the same as when specifying a UUID, except the array may contain multiple workload objects that share the same project value. Note A request to the /api/v1/workload endpoint without a project or uuid parameter returns all of the workloads that WFL knows about. That response might be large and take a while to process.","title":"Query Workload with project: /api/v1/workload?project=&lt;project&gt;"},{"location":"modules-sg/#list-workflows-managed-by-the-workload-get-apiv1workloaduuidworkflows","text":"Request curl -X GET '/api/v1/workload/efb00901-378e-4365-86e7-edd0fbdaaab2/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response A successful response from /api/v1/workload/{uuid}/workload is always an array of Cromwell workflows with their statuses. [{ \"status\" : \"Submitted\" , \"updated\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"8c1f586e-036b-4690-87c2-2af5d7e00450\" , \"inputs\" : { \"base_file_name\" : \"27B-6\" , \"contamination_vcf\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz\" , \"contamination_vcf_index\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi\" , \"cram_ref_fasta\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\" , \"cram_ref_fasta_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai\" , \"dbsnp_vcf\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz\" , \"dbsnp_vcf_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz.tbi\" , \"input_cram\" : \"gs://broad-gotc-prod-storage/pipeline/PO-1234/27B-6/v1/27B-6.cram\" }, \"options\" : { \"monitoring_script\" : \"gs://broad-gotc-prod-storage/scripts/monitoring_script.sh\" } }]","title":"List workflows managed by the workload GET /api/v1/workload/{uuid}/workflows"},{"location":"modules-wgs/","text":"ExternalWholeGenomeReprocessing workload \u2693\ufe0e Inputs \u2693\ufe0e An ExternalWholeGenomeReprocessing workload specifies the following inputs for each workflow: input_cram or input_bam (required) base_file_name sample_name final_gvcf_base_name unmapped_bam_suffix reference_fasta_prefix input_cram or input_bam (required) \u2693\ufe0e Absolute GCS file path (like gs://... ) base_file_name \u2693\ufe0e Used for naming intermediate/output files Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension sample_name \u2693\ufe0e Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension final_gvcf_base_name \u2693\ufe0e Path to the final VCF ( .vcf will be added by the WDL) Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension unmapped_bam_suffix \u2693\ufe0e Defaults to .unmapped.bam reference_fasta_prefix \u2693\ufe0e Defaults to gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38 Note that this pipeline supports specifying arbitrary WDL inputs, either at the workload level through common or individually via items . Usage \u2693\ufe0e ExternalWholeGenomeReprocessing workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Whole Genome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions. Create Workload: POST /api/v1/create \u2693\ufe0e Creates a WFL workload. Before processing, confirm that the WFL and Cromwell service accounts have at least read access to the input files. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/create' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"project\": \"PO-1234\", \"items\": [{ \"inputs\": { \"input_cram\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", \"sample_name\": \"TestSample1234\" } }] }' Response { \"creator\" : \"sehsan@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T15:50:01Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" , \"version\" : \"0.7.0\" } Note that the ExternalWholeGenomeReprocessing pipeline supports specifying cromwell \"workflowOptions\" via the options map. See the reference page for more information. Start Workload: POST /api/v1/start \u2693\ufe0e Starts a Cromwell workflow for each item in the workload. If an output already exists in the output bucket for a particular input cram, WFL will not re-submit that workflow. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" }' Response { \"started\" : \"2020-10-05T15:50:51Z\" , \"creator\" : \"username@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T15:50:01Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" , \"version\" : \"0.7.0\" } Stop Workload: POST /api/v1/stop \u2693\ufe0e Included for compatibility with continuous workloads. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" }' Response json { \"started\": \"2020-10-05T15:50:51Z\", \"creator\": \"username@broadinstitute.org\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"release\": \"ExternalWholeGenomeReprocessing_v1.0\", \"created\": \"2020-10-05T15:50:01Z\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"project\": \"PO-1234\", \"commit\": \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\", \"wdl\": \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\", \"input\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\", \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\", \"version\": \"0.7.0\" } Exec Workload: POST /api/v1/exec \u2693\ufe0e Creates and then starts a Cromwell workflow for each item in the workload. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"project\": \"PO-1234\", \"items\": [{ \"inputs\": { \"input_cram\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", \"sample_name\": \"TestSample1234\" } }] }' Response { \"started\" : \"2020-10-05T16:15:32Z\" , \"creator\" : \"username@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T16:15:32Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"3a13f732-9743-47a9-ab83-c467b3bf0ca4\" , \"version\" : \"0.7.0\" } Query Workload: GET /api/v1/workload?uuid=<uuid> \u2693\ufe0e Queries the WFL database for workloads. Specify the uuid to query for a specific workload. Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload?uuid=813e3c38-9c11-4410-9888-435569d91d1d' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"creator\" : \"username\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org/\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-08-27T16:26:59Z\" , \"output\" : \"gs://broad-gotc-dev-zero-test/wgs-test-output\" , \"workflows\" : [ { \"updated\" : \"2020-10-05T16:15:32Z\" , \"uuid\" : \"2c543b29-2db9-4643-b81b-b16a0654c5cc\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } } ], \"project\" : \"wgs-dev\" , \"commit\" : \"d2fc38c61c62c44f4fd4d24bdee3121138e6c09e\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-test-storage/single_sample/plumbing/truth\" , \"uuid\" : \"813e3c38-9c11-4410-9888-435569d91d1d\" , \"version\" : \"0.7.0\" }] Query Workload with project: GET /api/v1/workload?project=<project> \u2693\ufe0e Queries the WFL database for workloads. Specify the project name to query for a list of specific workload(s). Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload?project=wgs-dev' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"creator\" : \"username\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org/\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-08-27T16:26:59Z\" , \"output\" : \"gs://broad-gotc-dev-zero-test/wgs-test-output\" , \"project\" : \"wgs-dev\" , \"commit\" : \"d2fc38c61c62c44f4fd4d24bdee3121138e6c09e\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-test-storage/single_sample/plumbing/truth\" , \"uuid\" : \"813e3c38-9c11-4410-9888-435569d91d1d\" , \"version\" : \"0.7.0\" }] The \"workflows\" field lists out each Cromwell workflow that was started, and includes their status information. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures. Note project and uuid are optional path parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together. List workflows managed by a workload GET /api/v1/workload/{uuid}/workflows \u2693\ufe0e Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload/813e3c38-9c11-4410-9888-435569d91d1d/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"updated\" : \"2020-10-05T16:15:32Z\" , \"uuid\" : \"2c543b29-2db9-4643-b81b-b16a0654c5cc\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } }] The \"workflows\" endpoint lists out each Cromwell workflow that was started, and includes their status information. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures.","title":"Whole Genome"},{"location":"modules-wgs/#externalwholegenomereprocessing-workload","text":"","title":"ExternalWholeGenomeReprocessing workload"},{"location":"modules-wgs/#inputs","text":"An ExternalWholeGenomeReprocessing workload specifies the following inputs for each workflow: input_cram or input_bam (required) base_file_name sample_name final_gvcf_base_name unmapped_bam_suffix reference_fasta_prefix","title":"Inputs"},{"location":"modules-wgs/#input_cram-or-input_bam-required","text":"Absolute GCS file path (like gs://... )","title":"input_cram or input_bam (required)"},{"location":"modules-wgs/#base_file_name","text":"Used for naming intermediate/output files Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension","title":"base_file_name"},{"location":"modules-wgs/#sample_name","text":"Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension","title":"sample_name"},{"location":"modules-wgs/#final_gvcf_base_name","text":"Path to the final VCF ( .vcf will be added by the WDL) Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension","title":"final_gvcf_base_name"},{"location":"modules-wgs/#unmapped_bam_suffix","text":"Defaults to .unmapped.bam","title":"unmapped_bam_suffix"},{"location":"modules-wgs/#reference_fasta_prefix","text":"Defaults to gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38 Note that this pipeline supports specifying arbitrary WDL inputs, either at the workload level through common or individually via items .","title":"reference_fasta_prefix"},{"location":"modules-wgs/#usage","text":"ExternalWholeGenomeReprocessing workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Whole Genome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions.","title":"Usage"},{"location":"modules-wgs/#create-workload-post-apiv1create","text":"Creates a WFL workload. Before processing, confirm that the WFL and Cromwell service accounts have at least read access to the input files. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/create' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"project\": \"PO-1234\", \"items\": [{ \"inputs\": { \"input_cram\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", \"sample_name\": \"TestSample1234\" } }] }' Response { \"creator\" : \"sehsan@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T15:50:01Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" , \"version\" : \"0.7.0\" } Note that the ExternalWholeGenomeReprocessing pipeline supports specifying cromwell \"workflowOptions\" via the options map. See the reference page for more information.","title":"Create Workload: POST /api/v1/create"},{"location":"modules-wgs/#start-workload-post-apiv1start","text":"Starts a Cromwell workflow for each item in the workload. If an output already exists in the output bucket for a particular input cram, WFL will not re-submit that workflow. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" }' Response { \"started\" : \"2020-10-05T15:50:51Z\" , \"creator\" : \"username@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T15:50:01Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" , \"version\" : \"0.7.0\" }","title":"Start Workload: POST /api/v1/start"},{"location":"modules-wgs/#stop-workload-post-apiv1stop","text":"Included for compatibility with continuous workloads. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" }' Response json { \"started\": \"2020-10-05T15:50:51Z\", \"creator\": \"username@broadinstitute.org\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"release\": \"ExternalWholeGenomeReprocessing_v1.0\", \"created\": \"2020-10-05T15:50:01Z\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"project\": \"PO-1234\", \"commit\": \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\", \"wdl\": \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\", \"input\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\", \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\", \"version\": \"0.7.0\" }","title":"Stop Workload: POST /api/v1/stop"},{"location":"modules-wgs/#exec-workload-post-apiv1exec","text":"Creates and then starts a Cromwell workflow for each item in the workload. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"project\": \"PO-1234\", \"items\": [{ \"inputs\": { \"input_cram\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", \"sample_name\": \"TestSample1234\" } }] }' Response { \"started\" : \"2020-10-05T16:15:32Z\" , \"creator\" : \"username@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T16:15:32Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"3a13f732-9743-47a9-ab83-c467b3bf0ca4\" , \"version\" : \"0.7.0\" }","title":"Exec Workload: POST /api/v1/exec"},{"location":"modules-wgs/#query-workload-get-apiv1workloaduuiduuid","text":"Queries the WFL database for workloads. Specify the uuid to query for a specific workload. Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload?uuid=813e3c38-9c11-4410-9888-435569d91d1d' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"creator\" : \"username\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org/\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-08-27T16:26:59Z\" , \"output\" : \"gs://broad-gotc-dev-zero-test/wgs-test-output\" , \"workflows\" : [ { \"updated\" : \"2020-10-05T16:15:32Z\" , \"uuid\" : \"2c543b29-2db9-4643-b81b-b16a0654c5cc\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } } ], \"project\" : \"wgs-dev\" , \"commit\" : \"d2fc38c61c62c44f4fd4d24bdee3121138e6c09e\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-test-storage/single_sample/plumbing/truth\" , \"uuid\" : \"813e3c38-9c11-4410-9888-435569d91d1d\" , \"version\" : \"0.7.0\" }]","title":"Query Workload: GET /api/v1/workload?uuid=&lt;uuid&gt;"},{"location":"modules-wgs/#query-workload-with-project-get-apiv1workloadprojectproject","text":"Queries the WFL database for workloads. Specify the project name to query for a list of specific workload(s). Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload?project=wgs-dev' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"creator\" : \"username\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org/\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-08-27T16:26:59Z\" , \"output\" : \"gs://broad-gotc-dev-zero-test/wgs-test-output\" , \"project\" : \"wgs-dev\" , \"commit\" : \"d2fc38c61c62c44f4fd4d24bdee3121138e6c09e\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-test-storage/single_sample/plumbing/truth\" , \"uuid\" : \"813e3c38-9c11-4410-9888-435569d91d1d\" , \"version\" : \"0.7.0\" }] The \"workflows\" field lists out each Cromwell workflow that was started, and includes their status information. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures. Note project and uuid are optional path parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together.","title":"Query Workload with project: GET /api/v1/workload?project=&lt;project&gt;"},{"location":"modules-wgs/#list-workflows-managed-by-a-workload-get-apiv1workloaduuidworkflows","text":"Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload/813e3c38-9c11-4410-9888-435569d91d1d/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"updated\" : \"2020-10-05T16:15:32Z\" , \"uuid\" : \"2c543b29-2db9-4643-b81b-b16a0654c5cc\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } }] The \"workflows\" endpoint lists out each Cromwell workflow that was started, and includes their status information. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures.","title":"List workflows managed by a workload GET /api/v1/workload/{uuid}/workflows"},{"location":"sink/","text":"Sink \u2693\ufe0e The workload Sink models the terminal stage of a processing pipeline. In a typical workload configuration, a Sink can be used to write workflow outputs to a desired location in the cloud. User Guide \u2693\ufe0e You can configure the type of Sink used in your workload by changing the sink attribute of your workload request. Terra Workspace Sink \u2693\ufe0e You can write workflow outputs to a Terra Workspace using the Terra Workspace sink. A typical Terra Workspace sink configuration in the workload request looks like: { \"name\" : \"Terra Workspace\" , \"workspace\" : \"{workspace-namespace}/{workspace-name}\" , \"entityType\" : \"{entity-type-name}\" , \"identifier\" : \"{workflow-identifier}\" , \"fromOutputs\" : { \"attribute0\" : \"output0\" , \"attribute1\" : [ \"output1\" , \"output2\" ], \"attribute3\" : \"$literal\" , ... } } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the Terra Workspace sink implementation. workspace The Terra Workspace to write pipeline outputs to. entityType The entity type in the workspace to write outputs to. identifier Selects the workflow attribute (output or input) to use as the entity name. fromOutputs Mapping from outputs to attribute names in the entityType . workspace \u2693\ufe0e The workspace is a \"{workspace-namespace}/{workspace-name}\" string as it appears in the URL path in the Terra UI. The workspace must exist prior to workload creation. You must ensure that workflow-launcher@firecloud.org is a workspace \"Writer\" in order to write entities to the workspace. entityType \u2693\ufe0e The entityType is the name of the entity type in the workspace that entities will be created as. The entity type must exist prior to workload creation and must be a table in the workspace. identifier \u2693\ufe0e WFL tries to find a workflow output whose name matches identifier , checking workflow input names as a fallback. The matching value will be the name of the newly created entity. Both workflow outputs and inputs are checked for matches since depending on use case, the logical unique identifier may be either. Warnings If an identifier has no matching workflow output or input, WFL will not be able to resolve a workflow to an entity name and will fail to write its outputs to the workspace data table. When two workflows share the same identifier value, the first set of outputs will be overwritten by the second in the workspace. Example: An eMerge Arrays workflow has an output called \"chip_well_barcode_output\" that uniquely identifies its inputs and outputs. By setting \"identifier\": \"chip_well_barcode_output\" in the sink configuration, entities will be created using the \"chip_well_barcode_output\" as the entity name. Below, the outputs for a successful workflow with a \"chip_well_barcode_output\" of \"204126290052_R01C01\" have been written to the destination data table. fromOutputs \u2693\ufe0e fromOutputs configures how to create new entities from pipeline outputs by mapping the output names to attributes in the entityType . Note that all attribute names must exist in the entityType before the workload creation. fromOutputs allows a small amount of flexibility in how to construct an entity and supports the following relations: \"attribute\": \"output\" Direct mapping from an output to an attribute \"attribute\": [\"output0\", \"output2\"] Make an attribute from a list of pipeline outputs. \"attribute\": \"$value\" Use the literal \"value\" for an attribute. Terra Data Repository Sink \u2693\ufe0e You can write workflow outputs to a Terra Data Repository dataset using the Terra DataRepo sink. A typical Terra DataRepo sink configuration in the workload request looks like: { \"name\" : \"Terra DataRepo\" , \"dataset\" : \"{dataset-id}\" , \"table\" : \"{table-name}\" , \"fromOutputs\" : { \"column0\" : \"output0\" , \"column1\" : [ \"output1\" , \"output2\" ], \"column3\" : \"$literal\" , ... } } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the Terra Workspace sink implementation. dataset The UUID of dataset to monitor and read from. table The name of the dataset table to monitor and read from. fromOutputs Mapping from outputs to columns in the table . dataset \u2693\ufe0e The dataset attribute is the UUID that uniquely identifies the TDR dataset you want workflow-launcher to write workflow outputs to. table \u2693\ufe0e The table is the name of the table in the dataset that you want workflow-launcher to write workflow outputs to. Once a workflow succeeds, its outputs will be ingested as new rows in that table (see note). You cannot write to more than one table per Terra DataRepo sink. Note workflow-launcher transforms outputs into a form conformant with the table in the dataset using the transformation described by fromOutputs . The columns in your table don't have to be an exact match for the output names. See below for more details. fromOutputs \u2693\ufe0e fromOutputs configures how to create new rows in the table from pipeline outputs by mapping the output names to columns in the table . fromOutputs allows a small amount of flexibility in how to construct an entity and supports the following relations: \"column\": \"output\" Direct mapping from an output to a column \"column\": [\"output0\", \"output2\"] Make a column from an array of pipeline outputs. \"column\": \"$value\" Use the literal \"value\" for a column. Note Any output not included in fromOutputs will not be ingested into the dataset Note Any column not included in fromOuputs will not have a value in the newly added row. Developer Guide \u2693\ufe0e A sink is one satisfying the Sink protocol as below: ( defprotocol Sink ( update-sink! ^ Workload [ ^ Workload workload ;; This sink instance ] \"Update the internal state of the `Workload`'s sink, consuming objects from the `Workload`'s executor queue, performing any external effects as required. Implementations should avoid maintaining in-memory state and making long- running external calls, favouring internal queues to manage such tasks asynchronously between invocations. Note that the `Workload`'s Sink and its Executor Queue are parameterised types and the Executor Queue's parameterisation must be convertible to the Sink's.\" )) Note The Sink protocol is implemented by the update-sink! multimethod. It's documented thus as a means of differentiating the in-memory data model from the metadata a user sees. To be used in a workload, a Sink implementation should satisfy Stage , the to-edn multimethod and the following multimethods specific to Sink s: ( defmulti create-sink \"Create a `Sink` instance using the database `transaction` and configuration in the sink `request` and return a `[type items]` pair to be written to a workload record as `sink_type` and `sink_items`. Notes: - This is a factory method registered for workload creation. - The `Sink` type string must match a value of the `sink` enum in the database schema. - This multimethod is type-dispatched on the `:name` association in the `request`.\" ( fn ^ [ ^ String ^ String ] [ ^ Connection transaction ;; JDBC Connection ^ long workload-id ;; ID of the workload being created ^ IPersistentHashMap request ;; Data forwarded to the handler ] ( :name request ))) ( defmulti load-sink! \"Return the `Sink` implementation associated with the `sink_type` and `sink_items` fields of the `workload` row in the database. Note that this multimethod is type-dispatched on the `:sink_type` association in the `workload`.\" ( fn ^ Sink [ ^ Connection transaction ;; JDBC Connection ^ IPersistentHashMap workload ;; Row from workload table ] ( :sink_type workload )))","title":"Sink"},{"location":"sink/#sink","text":"The workload Sink models the terminal stage of a processing pipeline. In a typical workload configuration, a Sink can be used to write workflow outputs to a desired location in the cloud.","title":"Sink"},{"location":"sink/#user-guide","text":"You can configure the type of Sink used in your workload by changing the sink attribute of your workload request.","title":"User Guide"},{"location":"sink/#terra-workspace-sink","text":"You can write workflow outputs to a Terra Workspace using the Terra Workspace sink. A typical Terra Workspace sink configuration in the workload request looks like: { \"name\" : \"Terra Workspace\" , \"workspace\" : \"{workspace-namespace}/{workspace-name}\" , \"entityType\" : \"{entity-type-name}\" , \"identifier\" : \"{workflow-identifier}\" , \"fromOutputs\" : { \"attribute0\" : \"output0\" , \"attribute1\" : [ \"output1\" , \"output2\" ], \"attribute3\" : \"$literal\" , ... } } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the Terra Workspace sink implementation. workspace The Terra Workspace to write pipeline outputs to. entityType The entity type in the workspace to write outputs to. identifier Selects the workflow attribute (output or input) to use as the entity name. fromOutputs Mapping from outputs to attribute names in the entityType .","title":"Terra Workspace Sink"},{"location":"sink/#workspace","text":"The workspace is a \"{workspace-namespace}/{workspace-name}\" string as it appears in the URL path in the Terra UI. The workspace must exist prior to workload creation. You must ensure that workflow-launcher@firecloud.org is a workspace \"Writer\" in order to write entities to the workspace.","title":"workspace"},{"location":"sink/#entitytype","text":"The entityType is the name of the entity type in the workspace that entities will be created as. The entity type must exist prior to workload creation and must be a table in the workspace.","title":"entityType"},{"location":"sink/#identifier","text":"WFL tries to find a workflow output whose name matches identifier , checking workflow input names as a fallback. The matching value will be the name of the newly created entity. Both workflow outputs and inputs are checked for matches since depending on use case, the logical unique identifier may be either. Warnings If an identifier has no matching workflow output or input, WFL will not be able to resolve a workflow to an entity name and will fail to write its outputs to the workspace data table. When two workflows share the same identifier value, the first set of outputs will be overwritten by the second in the workspace. Example: An eMerge Arrays workflow has an output called \"chip_well_barcode_output\" that uniquely identifies its inputs and outputs. By setting \"identifier\": \"chip_well_barcode_output\" in the sink configuration, entities will be created using the \"chip_well_barcode_output\" as the entity name. Below, the outputs for a successful workflow with a \"chip_well_barcode_output\" of \"204126290052_R01C01\" have been written to the destination data table.","title":"identifier"},{"location":"sink/#fromoutputs","text":"fromOutputs configures how to create new entities from pipeline outputs by mapping the output names to attributes in the entityType . Note that all attribute names must exist in the entityType before the workload creation. fromOutputs allows a small amount of flexibility in how to construct an entity and supports the following relations: \"attribute\": \"output\" Direct mapping from an output to an attribute \"attribute\": [\"output0\", \"output2\"] Make an attribute from a list of pipeline outputs. \"attribute\": \"$value\" Use the literal \"value\" for an attribute.","title":"fromOutputs"},{"location":"sink/#terra-data-repository-sink","text":"You can write workflow outputs to a Terra Data Repository dataset using the Terra DataRepo sink. A typical Terra DataRepo sink configuration in the workload request looks like: { \"name\" : \"Terra DataRepo\" , \"dataset\" : \"{dataset-id}\" , \"table\" : \"{table-name}\" , \"fromOutputs\" : { \"column0\" : \"output0\" , \"column1\" : [ \"output1\" , \"output2\" ], \"column3\" : \"$literal\" , ... } } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the Terra Workspace sink implementation. dataset The UUID of dataset to monitor and read from. table The name of the dataset table to monitor and read from. fromOutputs Mapping from outputs to columns in the table .","title":"Terra Data Repository Sink"},{"location":"sink/#dataset","text":"The dataset attribute is the UUID that uniquely identifies the TDR dataset you want workflow-launcher to write workflow outputs to.","title":"dataset"},{"location":"sink/#table","text":"The table is the name of the table in the dataset that you want workflow-launcher to write workflow outputs to. Once a workflow succeeds, its outputs will be ingested as new rows in that table (see note). You cannot write to more than one table per Terra DataRepo sink. Note workflow-launcher transforms outputs into a form conformant with the table in the dataset using the transformation described by fromOutputs . The columns in your table don't have to be an exact match for the output names. See below for more details.","title":"table"},{"location":"sink/#fromoutputs_1","text":"fromOutputs configures how to create new rows in the table from pipeline outputs by mapping the output names to columns in the table . fromOutputs allows a small amount of flexibility in how to construct an entity and supports the following relations: \"column\": \"output\" Direct mapping from an output to a column \"column\": [\"output0\", \"output2\"] Make a column from an array of pipeline outputs. \"column\": \"$value\" Use the literal \"value\" for a column. Note Any output not included in fromOutputs will not be ingested into the dataset Note Any column not included in fromOuputs will not have a value in the newly added row.","title":"fromOutputs"},{"location":"sink/#developer-guide","text":"A sink is one satisfying the Sink protocol as below: ( defprotocol Sink ( update-sink! ^ Workload [ ^ Workload workload ;; This sink instance ] \"Update the internal state of the `Workload`'s sink, consuming objects from the `Workload`'s executor queue, performing any external effects as required. Implementations should avoid maintaining in-memory state and making long- running external calls, favouring internal queues to manage such tasks asynchronously between invocations. Note that the `Workload`'s Sink and its Executor Queue are parameterised types and the Executor Queue's parameterisation must be convertible to the Sink's.\" )) Note The Sink protocol is implemented by the update-sink! multimethod. It's documented thus as a means of differentiating the in-memory data model from the metadata a user sees. To be used in a workload, a Sink implementation should satisfy Stage , the to-edn multimethod and the following multimethods specific to Sink s: ( defmulti create-sink \"Create a `Sink` instance using the database `transaction` and configuration in the sink `request` and return a `[type items]` pair to be written to a workload record as `sink_type` and `sink_items`. Notes: - This is a factory method registered for workload creation. - The `Sink` type string must match a value of the `sink` enum in the database schema. - This multimethod is type-dispatched on the `:name` association in the `request`.\" ( fn ^ [ ^ String ^ String ] [ ^ Connection transaction ;; JDBC Connection ^ long workload-id ;; ID of the workload being created ^ IPersistentHashMap request ;; Data forwarded to the handler ] ( :name request ))) ( defmulti load-sink! \"Return the `Sink` implementation associated with the `sink_type` and `sink_items` fields of the `workload` row in the database. Note that this multimethod is type-dispatched on the `:sink_type` association in the `workload`.\" ( fn ^ Sink [ ^ Connection transaction ;; JDBC Connection ^ IPersistentHashMap workload ;; Row from workload table ] ( :sink_type workload )))","title":"Developer Guide"},{"location":"source/","text":"Source \u2693\ufe0e The workload Source models the first stage of a processing pipeline. In a typical workload configuration, a Source can be used to read workflow inputs from a specified location or service in the cloud. User Guide \u2693\ufe0e You can configure the type of Source used in your workload by changing the source attribute of your workload request. Terra DataRepo Source \u2693\ufe0e You can configure workflow-launcher to fetch workflow inputs from a Terra Data Repository (TDR) dataset in real-time using the Terra DataRepo source. The Terra DataRepo source polls a specified table in your dataset for new and/or updated rows and snapshots the rows to be processed downstream by an Executor . The table in your dataset must include a DateTime or Timestamp column representing the load or last modification date of that row to be compatible with a Terra DataRepo source. The Terra DataRepo source can only read inputs from a single table. When you start the workload, the Terra DataRepo source will start looking for new/updated rows from that instant. When you stop the workload, the Terra DataRepo source will stop looking for new/updated rows from that instant. All pending snapshots may continue to be processed by a later workload stage. Note workflow-launcher creates snapshots of your data to be processed by a later stage of the workload. Therefore, you must ensure the account workflow-launcher@firecloud.org is a custodian of your dataset. A typical Terra DataRepo source configuration in the workload request looks like: { \"name\" : \"Terra DataRepo\" , \"dataset\" : \"{dataset-id}\" , \"table\" : \"{dataset-table-name}\" , \"column\" : \"{dataset-column-name-to-poll}\" , \"snapshotReaders\" : [ \"{user}@{domain}\" , ... ], \"pollingIntervalMinutes\" : 1 } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the Terra DataRepo source implementation. dataset The UUID of dataset to monitor and read from. table The name of the dataset table to monitor and read from. column The name of the UTC DateTime or Timestamp column in the table to poll. snapshotReaders A list of email addresses whom should be readers of all snapshots created by workflow-launcher in this workload. pollingIntervalMinutes Optional. Rate at which WFL will poll TDR for new rows to snapshot dataset \u2693\ufe0e The dataset attribute is the UUID that uniquely identifies the TDR dataset you want workflow-launcher to fetch workflow inputs form. table \u2693\ufe0e The table is the name of the table in the dataset that you want workflow-launcher to fetch inputs from. You should design this table such that each row contains all the inputs required to execute a workflow by the workload Executor downstream. column \u2693\ufe0e The column is the name of a column in the table specified above used to determine which rows are new or have been updated and therefore need reprocessing. It should be a Timestamp , but DateTime is accepted too. You must ensure that the Timestamp or DateTime column uses Universal Coordinated Time (UTC). Note Using a Timestamp will increase the likelihood of workflow-launcher detecting and scheduling new rows in real-time due to greater precision. Using DateTime may cause workflow-launcher to miss the row at first (though it will be picked up later). snapshotReaders \u2693\ufe0e The email addresses of those whom should be \"readers\" of all snapshots created by workflow-launcher in this workload. You can specify individual users and/or Terra/Firecloud groups. pollingIntervalMinutes \u2693\ufe0e Optional. The rate, in minutes, at which WFL will poll TDR for new rows to snapshot. If not provided, the default interval is 20 minutes. TDR Snapshots Source \u2693\ufe0e You can configure workflow-launcher to use a list of TDR snapshots directly. This may be useful if you don't want workflow-launcher to be a custodian of your dataset or if you already have snapshots you want to process. In this case you must ensure that workflow-launcher@firecloud.org is a reader of all snapshots you want it to process. A typical TDR Snapshots source configuration in the workload request looks like: { \"name\" : \"TDR Snapshots\" , \"snapshots\" : [ \"{snapshot-id}\" , ... ] } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the TDR Snapshots source implementation. snapshots A List of UUID s of snapshots to process. Note You must ensure that the snapshots you list are compatible with the downstream processing stage that consumes them. Developer Guide \u2693\ufe0e A source is a Queue that satisfies the Source protocol below: ( defprotocol Source ( start-source! ^ Unit [ ^ Connection transaction ;; JDBC Connection ^ Source source ;; This source instance ] \"Start enqueuing items onto the `source`'s queue to be consumed by a later processing stage. This operation should not perform any long-running external effects other than database operations via the `transaction`. This function is called at most once during a workload's operation.\" ) ( stop-source! ^ Unit [ ^ Connection transaction ;; JDBC Connection ^ Source source ;; This source instance ] \"Stop enqueuing inputs onto the `source`'s queue to be consumed by a later processing stage. This operation should not perform any long-running external effects other than database operations via the `transaction`. This function is called at most once during a workload's operation and will only be called after `start-source!`. Any outstanding items on the `source` queue may still be consumed by a later processing stage.\" ) ( update-source! ^ Workload [ ^ Workload workload ] \"Enqueue items onto the `workload`'s source queue to be consumed by a later processing stage unless stopped, performing any external effects as necessary. Implementations should avoid maintaining in-memory state and making long- running external calls, favouring internal queues to manage such tasks asynchronously between invocations. This function is called one or more times after `start-source!` and may be called after `stop-source!`\" )) Note The Source protocol is implemented by a set of multimethods of the same name. The use of a protocol is to illustrate the difference between the in-memory data model of a Source and the metadata seen by a user. To be used in a workload, a Source implementation should satisfy the processing Stage protocol and the to-edn multimethod in addition to the following multimethods specific to sinks: ( defmulti create-source \"Create a `Source` instance using the database `transaction` and configuration in the source `request` and return a `[type items]` pair to be written to a workload record as `source_type` and `source_items`. Notes: - This is a factory method registered for workload creation. - The `Source` type string must match a value of the `source` enum in the database schema. - This multimethod is type-dispatched on the `:name` association in the `request`.\" ( fn ^ [ ^ String ^ String ] [ ^ Connection transaction ;; JDBC Connection ^ long workload-id ;; ID of the workload being created ^ IPersistentHashMap request ;; Data forwarded to the handler ] ( :name request ))) ( defmulti load-source! \"Return the `Source` implementation associated with the `source_type` and `source_items` fields of the `workload` row in the database. Note that this multimethod is type-dispatched on the `:source_type` association in the `workload`.\" ( fn ^ Sink [ ^ Connection transaction ;; JDBC Connection ^ IPersistentHashMap workload ;; Row from workload table ] ( :source_type workload )))","title":"Source"},{"location":"source/#source","text":"The workload Source models the first stage of a processing pipeline. In a typical workload configuration, a Source can be used to read workflow inputs from a specified location or service in the cloud.","title":"Source"},{"location":"source/#user-guide","text":"You can configure the type of Source used in your workload by changing the source attribute of your workload request.","title":"User Guide"},{"location":"source/#terra-datarepo-source","text":"You can configure workflow-launcher to fetch workflow inputs from a Terra Data Repository (TDR) dataset in real-time using the Terra DataRepo source. The Terra DataRepo source polls a specified table in your dataset for new and/or updated rows and snapshots the rows to be processed downstream by an Executor . The table in your dataset must include a DateTime or Timestamp column representing the load or last modification date of that row to be compatible with a Terra DataRepo source. The Terra DataRepo source can only read inputs from a single table. When you start the workload, the Terra DataRepo source will start looking for new/updated rows from that instant. When you stop the workload, the Terra DataRepo source will stop looking for new/updated rows from that instant. All pending snapshots may continue to be processed by a later workload stage. Note workflow-launcher creates snapshots of your data to be processed by a later stage of the workload. Therefore, you must ensure the account workflow-launcher@firecloud.org is a custodian of your dataset. A typical Terra DataRepo source configuration in the workload request looks like: { \"name\" : \"Terra DataRepo\" , \"dataset\" : \"{dataset-id}\" , \"table\" : \"{dataset-table-name}\" , \"column\" : \"{dataset-column-name-to-poll}\" , \"snapshotReaders\" : [ \"{user}@{domain}\" , ... ], \"pollingIntervalMinutes\" : 1 } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the Terra DataRepo source implementation. dataset The UUID of dataset to monitor and read from. table The name of the dataset table to monitor and read from. column The name of the UTC DateTime or Timestamp column in the table to poll. snapshotReaders A list of email addresses whom should be readers of all snapshots created by workflow-launcher in this workload. pollingIntervalMinutes Optional. Rate at which WFL will poll TDR for new rows to snapshot","title":"Terra DataRepo Source"},{"location":"source/#dataset","text":"The dataset attribute is the UUID that uniquely identifies the TDR dataset you want workflow-launcher to fetch workflow inputs form.","title":"dataset"},{"location":"source/#table","text":"The table is the name of the table in the dataset that you want workflow-launcher to fetch inputs from. You should design this table such that each row contains all the inputs required to execute a workflow by the workload Executor downstream.","title":"table"},{"location":"source/#column","text":"The column is the name of a column in the table specified above used to determine which rows are new or have been updated and therefore need reprocessing. It should be a Timestamp , but DateTime is accepted too. You must ensure that the Timestamp or DateTime column uses Universal Coordinated Time (UTC). Note Using a Timestamp will increase the likelihood of workflow-launcher detecting and scheduling new rows in real-time due to greater precision. Using DateTime may cause workflow-launcher to miss the row at first (though it will be picked up later).","title":"column"},{"location":"source/#snapshotreaders","text":"The email addresses of those whom should be \"readers\" of all snapshots created by workflow-launcher in this workload. You can specify individual users and/or Terra/Firecloud groups.","title":"snapshotReaders"},{"location":"source/#pollingintervalminutes","text":"Optional. The rate, in minutes, at which WFL will poll TDR for new rows to snapshot. If not provided, the default interval is 20 minutes.","title":"pollingIntervalMinutes"},{"location":"source/#tdr-snapshots-source","text":"You can configure workflow-launcher to use a list of TDR snapshots directly. This may be useful if you don't want workflow-launcher to be a custodian of your dataset or if you already have snapshots you want to process. In this case you must ensure that workflow-launcher@firecloud.org is a reader of all snapshots you want it to process. A typical TDR Snapshots source configuration in the workload request looks like: { \"name\" : \"TDR Snapshots\" , \"snapshots\" : [ \"{snapshot-id}\" , ... ] } The table below summarises the purpose of each attribute in the above request. Attribute Description name Selects the TDR Snapshots source implementation. snapshots A List of UUID s of snapshots to process. Note You must ensure that the snapshots you list are compatible with the downstream processing stage that consumes them.","title":"TDR Snapshots Source"},{"location":"source/#developer-guide","text":"A source is a Queue that satisfies the Source protocol below: ( defprotocol Source ( start-source! ^ Unit [ ^ Connection transaction ;; JDBC Connection ^ Source source ;; This source instance ] \"Start enqueuing items onto the `source`'s queue to be consumed by a later processing stage. This operation should not perform any long-running external effects other than database operations via the `transaction`. This function is called at most once during a workload's operation.\" ) ( stop-source! ^ Unit [ ^ Connection transaction ;; JDBC Connection ^ Source source ;; This source instance ] \"Stop enqueuing inputs onto the `source`'s queue to be consumed by a later processing stage. This operation should not perform any long-running external effects other than database operations via the `transaction`. This function is called at most once during a workload's operation and will only be called after `start-source!`. Any outstanding items on the `source` queue may still be consumed by a later processing stage.\" ) ( update-source! ^ Workload [ ^ Workload workload ] \"Enqueue items onto the `workload`'s source queue to be consumed by a later processing stage unless stopped, performing any external effects as necessary. Implementations should avoid maintaining in-memory state and making long- running external calls, favouring internal queues to manage such tasks asynchronously between invocations. This function is called one or more times after `start-source!` and may be called after `stop-source!`\" )) Note The Source protocol is implemented by a set of multimethods of the same name. The use of a protocol is to illustrate the difference between the in-memory data model of a Source and the metadata seen by a user. To be used in a workload, a Source implementation should satisfy the processing Stage protocol and the to-edn multimethod in addition to the following multimethods specific to sinks: ( defmulti create-source \"Create a `Source` instance using the database `transaction` and configuration in the source `request` and return a `[type items]` pair to be written to a workload record as `source_type` and `source_items`. Notes: - This is a factory method registered for workload creation. - The `Source` type string must match a value of the `source` enum in the database schema. - This multimethod is type-dispatched on the `:name` association in the `request`.\" ( fn ^ [ ^ String ^ String ] [ ^ Connection transaction ;; JDBC Connection ^ long workload-id ;; ID of the workload being created ^ IPersistentHashMap request ;; Data forwarded to the handler ] ( :name request ))) ( defmulti load-source! \"Return the `Source` implementation associated with the `source_type` and `source_items` fields of the `workload` row in the database. Note that this multimethod is type-dispatched on the `:source_type` association in the `workload`.\" ( fn ^ Sink [ ^ Connection transaction ;; JDBC Connection ^ IPersistentHashMap workload ;; Row from workload table ] ( :source_type workload )))","title":"Developer Guide"},{"location":"staged-workload/","text":"Staged Workloads \u2693\ufe0e A staged workload is a discrete body of work, which takes data from a source, pushes it into a workflow executor for analysis, and then delivers the results of the analysis to an output location (also known as a sink). Staged Workload Components \u2693\ufe0e Source \u2693\ufe0e The workload Source models the first stage of a processing pipeline. In a typical workload configuration, a Source can be used to read workflow inputs from a specified location or service in the cloud. Executor \u2693\ufe0e The workload Executor models an intermediate stage of a processing pipeline. In a typical workload configuration, an Executor uses a supported service in the cloud to execute workflows. Sink \u2693\ufe0e The workload Sink models the terminal stage of a processing pipeline. In a typical workload configuration, a Sink can be used to write workflow outputs to a desired location in the cloud. Example Staged Workload \u2693\ufe0e The specific values below are from the COVID-19 Surveillance in Terra project. Workloads for other projects may leverage different implementations for source, executor or sink. watchers of a workload You may have noticed the optional watchers field in the requests. As of 2021/08 WFL supports registering Slack channels (Slack channel IDs that starts with a C ) as watchers of the workload. Your channel needs to live in the broadinstitute.slack.com Slack organization and you also have to /invite @WorkFlow Launcher Notifier to invite the WFL notifier to your channel before the channel can receive user facing messaged from WFL. { \"watchers\": [ [\"slack\", \"C000XXX0XXX\"], [\"email\", \"tester@broadinstitute.org\"] ], \"labels\": [ \"hornet:test\" ], \"project\": \"wfl-dev/CDC_Viral_Sequencing\", \"source\": { \"name\": \"Terra DataRepo\", \"dataset\": \"4bb51d98-b4aa-4c72-b76a-1a96a2ee3057\", \"table\": \"flowcells\", \"column\": \"last_modified_date\", \"snapshotReaders\": [ \"workflow-launcher-dev@firecloud.org\" ] }, \"executor\": { \"name\": \"Terra\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing\", \"methodConfiguration\": \"wfl-dev/sarscov2_illumina_full\", \"methodConfigurationVersion\": 1, \"fromSource\": \"importSnapshot\" }, \"sink\": { \"name\": \"Terra Workspace\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing\", \"entityType\": \"flowcell\", \"identifier\": \"run_id\", \"fromOutputs\": { \"submission_xml\" : \"submission_xml\", \"assembled_ids\" : \"assembled_ids\", \"num_failed_assembly\" : \"num_failed_assembly\", ... } } } Staged Workload Anatomy (High Level) \u2693\ufe0e Field Type Description watchers List An optional list of emails or Slack channels to notify labels List A list of user-defined labels.They must be a string of the form \"name\":\"value\u201d , where name must start with a letter followed by any combination of digits, letters, spaces, underscores and hyphens and value is any non-blank string project String The project is a non-null string required in the workload table. It's needed to support querying workloads by project source Object The data source executor Object The mechanism executing the analysis. (Most often this is Terra) sink Object The location where data will be placed after analysis is complete","title":"Overview"},{"location":"staged-workload/#staged-workloads","text":"A staged workload is a discrete body of work, which takes data from a source, pushes it into a workflow executor for analysis, and then delivers the results of the analysis to an output location (also known as a sink).","title":"Staged Workloads"},{"location":"staged-workload/#staged-workload-components","text":"","title":"Staged Workload Components"},{"location":"staged-workload/#source","text":"The workload Source models the first stage of a processing pipeline. In a typical workload configuration, a Source can be used to read workflow inputs from a specified location or service in the cloud.","title":"Source"},{"location":"staged-workload/#executor","text":"The workload Executor models an intermediate stage of a processing pipeline. In a typical workload configuration, an Executor uses a supported service in the cloud to execute workflows.","title":"Executor"},{"location":"staged-workload/#sink","text":"The workload Sink models the terminal stage of a processing pipeline. In a typical workload configuration, a Sink can be used to write workflow outputs to a desired location in the cloud.","title":"Sink"},{"location":"staged-workload/#example-staged-workload","text":"The specific values below are from the COVID-19 Surveillance in Terra project. Workloads for other projects may leverage different implementations for source, executor or sink. watchers of a workload You may have noticed the optional watchers field in the requests. As of 2021/08 WFL supports registering Slack channels (Slack channel IDs that starts with a C ) as watchers of the workload. Your channel needs to live in the broadinstitute.slack.com Slack organization and you also have to /invite @WorkFlow Launcher Notifier to invite the WFL notifier to your channel before the channel can receive user facing messaged from WFL. { \"watchers\": [ [\"slack\", \"C000XXX0XXX\"], [\"email\", \"tester@broadinstitute.org\"] ], \"labels\": [ \"hornet:test\" ], \"project\": \"wfl-dev/CDC_Viral_Sequencing\", \"source\": { \"name\": \"Terra DataRepo\", \"dataset\": \"4bb51d98-b4aa-4c72-b76a-1a96a2ee3057\", \"table\": \"flowcells\", \"column\": \"last_modified_date\", \"snapshotReaders\": [ \"workflow-launcher-dev@firecloud.org\" ] }, \"executor\": { \"name\": \"Terra\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing\", \"methodConfiguration\": \"wfl-dev/sarscov2_illumina_full\", \"methodConfigurationVersion\": 1, \"fromSource\": \"importSnapshot\" }, \"sink\": { \"name\": \"Terra Workspace\", \"workspace\": \"wfl-dev/CDC_Viral_Sequencing\", \"entityType\": \"flowcell\", \"identifier\": \"run_id\", \"fromOutputs\": { \"submission_xml\" : \"submission_xml\", \"assembled_ids\" : \"assembled_ids\", \"num_failed_assembly\" : \"num_failed_assembly\", ... } } }","title":"Example Staged Workload"},{"location":"staged-workload/#staged-workload-anatomy-high-level","text":"Field Type Description watchers List An optional list of emails or Slack channels to notify labels List A list of user-defined labels.They must be a string of the form \"name\":\"value\u201d , where name must start with a letter followed by any combination of digits, letters, spaces, underscores and hyphens and value is any non-blank string project String The project is a non-null string required in the workload table. It's needed to support querying workloads by project source Object The data source executor Object The mechanism executing the analysis. (Most often this is Terra) sink Object The location where data will be placed after analysis is complete","title":"Staged Workload Anatomy (High Level)"},{"location":"terra/","text":"WorkFlow Launcher's Role in Terra \u2693\ufe0e Summary \u2693\ufe0e The Data Sciences Platform (DSP) is building a new system (around Terra ) for storing and processing biological data. The system design includes a Data Repository where data is stored, and a Methods Repository that executably describes transformations on that data. In the new system, the DSP needs something to fulfill the role that Zamboni currently plays in DSP's current infrastructure to support the Genomics Platform (GP). Zamboni watches various queues for messages describing new data and how to process it. Zamboni interprets those messages to dispatch work to workflow engines (running on the premises or in the cloud) and monitors the progress of those workflows. The Zamboni web UI allows users to track the progress of workflows, and enables Ops engineers to debug problems and resume or restart failed workflows. Zamboni can run workflows on both a local Sun Grid Engine (SGE), and on Cromwell on premises and in the cloud. We think that WFL can fill the role of Zamboni in the new data storage and processing system that DSP is developing now. History \u2693\ufe0e WFL began as a project to replace a Zamboni starter , with the old name \"Zero\". A starter is a Zamboni component that brokers messages among the queues that Zamboni watches. It interprets messages queued from a Laboratory Information Management System (LIMS), such as the Mercury web service, and demultiplexes them to other Zamboni queues. Zero was later adapted to manage the reprocessing of the first batch of UK Biobank exomes. It has since been adapted to drive workflows for other projects at the Broad. Zero is unusual in that it usually runs as a stateless command line program without special system privilege, and interfaces with services running both on premises and in Google Cloud. It also manages a processing workload as a set of inputs mapped to outputs instead of tracking the progress of individual sample workflows. A Zero user need only specify a source of inputs, a workflow to run, an execution environment, and an output location. Then each time it is invoked, Zero ensures that workflows are started and retried as needed until an output exists for every input. Zero has recently been adapted again to deploy as a web service under Google App Engine (GAE) though most of the value of Zero is still not available to the server. And now it has the new name WFL. The role of WFL in Terra \u2693\ufe0e Diagrams of the new DSP processing system show a WFL service subscribed to event streams from the Data Repository (DR), with interfaces to both the Data and the Method Repositories. The implication is that something notifies WFL of new data in the Data Repository and WFL determines how to process it somehow. WFL then looks up whatever is required from the Method Repository, calls on other services as necessary to process the data and writes the results back to the DR. There is also, presumably, a web UI to track and debug the workflows managed by WFL. Many details are yet to be worked out. WFL Concepts \u2693\ufe0e WFL is designed around several novel concepts. Manage workloads instead of workflows. This is the biggest difference between Zamboni and Zero (WFL). Zamboni manages workflows whereas WFL manages workloads . Zamboni's unit of work is the workflow . Zamboni manages each workflow separately. A workflow is a transformation specified in WDL or Scala code that succeeds or fails to produce a result. The input to a workflow and its result may consist of multiple files, but they represent a single unit of work managed by a workflow engine such as Cromwell. Zamboni prepares a new workflow for each message it receives by packaging up the input and submitting it to a workflow engine. It then monitors that workflow and reports on its success or failure. WFL manages a workload , which indirectly comprises multiple workflows. Each workflow maps an input to some output, but WFL generally tracks only the inputs and outputs instead of the workflows themselves. Think of a workload as a set of inputs transformed via a workflow engine into a set of outputs. Call that set of outputs the result set . WFL generally does not care whether any individual workflow succeeds or fails. It merely considers all possible inputs specified by the workload, and looks for inputs whose outputs are missing from the result set. If some input lacks an output in the result set, WFL starts a new workflow to process that input. Note: This characterization is unfair to Zamboni. Zamboni also had to manage multiple workflows before the advent of Cromwell and still does when running workflows on SGE. But WFL can take advantage of Cromwell's job management to simplify its implementation. Specify inputs and outputs by general predicates. Each Zamboni message explicitly specifies an input to be processed. Zamboni then starts a workflow for that input and reports its status. Zamboni reports failure so a user can debug and manually succeed , reconsider, or restart the workflow. The output of a successful workflow is not Zamboni's concern. WFL finds inputs by applying a predicate specified by the user subject to some run-time constraint. Then WFL applies a function to each input to find how that input maps to the result set. Another predicate applied to the input, and its output in the result set, determines whether WFL will launch a workflow on that input. Those predicates and function can be anything expressed in a programming language. The run-time constraint is some strings passed on the command line. Minimize user input and decisions at run time. WFL gathers the predicates and mapping functions described above into a module that also knows how to generate everything a workflow engine needs to launch the workflow to process an input into a result output. That module name is one of a few run-time constraints specified by strings in a web form or on a command line. Further constraints are usually one or two of the following: - a processing environment ( `dev` `prod` `pharma5` ), - a file system directory ( `/seq/tng/tbl/` `file://home/tbl/` ), - a cloud object prefix ( `gs://bucket/folder/` `s3://bucket/` ), - a pathname suffix ( `.cram` `.vcf` ), - a spreadsheet ( or JSON , TSV , CSV , XML ) filename - or a count to limit the scope of a predicate . The module interprets the other constraints, determines which processing environments are allowed, and parses any files named accordingly. Maintain provenance. WFL runs out of a single JARfile built entirely from sources pulled from Git repositories. WFL records the Git commit hashes in the JARfile and adds them to every Cromwell workflow it starts. WFL can also preserve the Cromwell metadata alongside any result files generated by the workflow. Run with minimal privilege. Zamboni runs as a service with system account credentials such as picard . WFL is designed to run as whoever invokes it, such as tbl@broadinstitute.org . WFL fetches the users credentials from the environment when invoked from the command line. WFL requires authentication when running as a server, and constructs a JSON Web Token (JWT) to authorize other services as needed. Limit dependencies. WFL depends on a Java runtime, and Gnu make and the Clojure CLI to manage dependencies. Of course, it also pulls in numerous Clojure and Java libraries at build time, and sources WDL files from the warp repository. A programmer need only install Clojure, clone the wfl Git repository, and run make to bootstrap WFL from source. WFL server \u2693\ufe0e The WFL client is a command-line batch program that a person runs intermittently on a laptop or virtual machine (VM). We are working to port the client functions of WFL to a ubiquitous web service (WFL server) running in Google Cloud. That port requires we solve several problems. State The WFL client is a stateless program that relies on consistent command line arguments to provide the constraints needed to drive the input discovery predicates and so on. Each user runs a separate process that lasts only as long as necessary to complete some stage of a workload. The WFL server is shared among all its users and runs continually. Therefore it requires some kind of data store (a database) to maintain the state of each workload across successive connections from web browsers. We intend to use the hosted Postgres service available to GAE applications for this. This work is already underway (GH-573). Authorization The WFL client assumes it runs in an authenticated context. It can pull credentials from the environment on every invocation that requires authorization to a service. The WFL server will also need to authorize services to run as some authenticated user, but cannot assume the credentials are always available, nor that there is a user present to provide them. WFL can already use OAuth2.0 to authenticate users against an identity provider and use the resulting credentials to build a JWT. It can also derive the bearer token required by most of our authorized services from a JWT. But WFL also needs some secure JWT store, so tokens are available to authorize services even when there is no active user connection. It also needs some mechanism to refresh tokens as they expire to support long-running workloads. Workload specification The user of a WFL service needs some way to specify a workload. A workload may be some set of inputs and the kind of workflow to run on them. A WFL client user now specifies a workload with a module name and a constraint . For example, ukb pharma5 110000 gs://broad-ukb/in/ gs://broad-ukb/out/ means find up to 110000 cloud objects with names prefixed with gs://broad-ukb/in/ , process them in the Cromwell set up for pharma5 , and store their outputs under gs://broad-ukb/out/ somewhere. The ukb module knows how to find .aligned.cram files under the gs://broad-ukb/in/ cloud path and set up the WDL and Cromwell dependencies and options necessary to reprocess them into .cram output files. The ukb module also knows how to find the Cromwell deployed to support pharma5 workloads, how to authorize the user to that Cromwell, and how to read any supporting data from other services. And finally, the ukb module knows how to determine which inputs do not yet have outputs under the gs://broad-ukb/out/ cloud path, and do not have workflows running in the pharma5 Cromwell. In an ideal design, this workload specification would integrate conveniently with the Data Repository's subscription or eventing service. In any case though, WFL needs some interface through which a user can specify what needs to be done. Workload management Workloads need to be started, stopped, and monitored somehow. This implies that there is some way to find active or suspended workloads, and affordances for acting on them. Users need some way to monitor the progress of a workload, and to find and debug workloads encountering unacceptable workflow failures. Monitoring and diagnostic code already exists in various WFL modules, but there is no easy way to use them from a web browser. Service interface WFL should be useful to programs other than web browsers. It is easy to imagine Terra users wanting to query WFL for the status of workloads directly without buggy and tedious screen scraping. WFL should at least export a query endpoint for use by other reporting services as well as its own browser interface. It would be nice to provide a familiar JSON or GraphQL query syntax to other services. Browser interface A browser interface should require little in addition to WFL's service interface. Ideally, one should be able to adapt WFL to new workloads via a browser interface without requiring a redeployment.","title":"WorkFlow Launcher's Role in Terra"},{"location":"terra/#workflow-launchers-role-in-terra","text":"","title":"WorkFlow Launcher's Role in Terra"},{"location":"terra/#summary","text":"The Data Sciences Platform (DSP) is building a new system (around Terra ) for storing and processing biological data. The system design includes a Data Repository where data is stored, and a Methods Repository that executably describes transformations on that data. In the new system, the DSP needs something to fulfill the role that Zamboni currently plays in DSP's current infrastructure to support the Genomics Platform (GP). Zamboni watches various queues for messages describing new data and how to process it. Zamboni interprets those messages to dispatch work to workflow engines (running on the premises or in the cloud) and monitors the progress of those workflows. The Zamboni web UI allows users to track the progress of workflows, and enables Ops engineers to debug problems and resume or restart failed workflows. Zamboni can run workflows on both a local Sun Grid Engine (SGE), and on Cromwell on premises and in the cloud. We think that WFL can fill the role of Zamboni in the new data storage and processing system that DSP is developing now.","title":"Summary"},{"location":"terra/#history","text":"WFL began as a project to replace a Zamboni starter , with the old name \"Zero\". A starter is a Zamboni component that brokers messages among the queues that Zamboni watches. It interprets messages queued from a Laboratory Information Management System (LIMS), such as the Mercury web service, and demultiplexes them to other Zamboni queues. Zero was later adapted to manage the reprocessing of the first batch of UK Biobank exomes. It has since been adapted to drive workflows for other projects at the Broad. Zero is unusual in that it usually runs as a stateless command line program without special system privilege, and interfaces with services running both on premises and in Google Cloud. It also manages a processing workload as a set of inputs mapped to outputs instead of tracking the progress of individual sample workflows. A Zero user need only specify a source of inputs, a workflow to run, an execution environment, and an output location. Then each time it is invoked, Zero ensures that workflows are started and retried as needed until an output exists for every input. Zero has recently been adapted again to deploy as a web service under Google App Engine (GAE) though most of the value of Zero is still not available to the server. And now it has the new name WFL.","title":"History"},{"location":"terra/#the-role-of-wfl-in-terra","text":"Diagrams of the new DSP processing system show a WFL service subscribed to event streams from the Data Repository (DR), with interfaces to both the Data and the Method Repositories. The implication is that something notifies WFL of new data in the Data Repository and WFL determines how to process it somehow. WFL then looks up whatever is required from the Method Repository, calls on other services as necessary to process the data and writes the results back to the DR. There is also, presumably, a web UI to track and debug the workflows managed by WFL. Many details are yet to be worked out.","title":"The role of WFL in Terra"},{"location":"terra/#wfl-concepts","text":"WFL is designed around several novel concepts. Manage workloads instead of workflows. This is the biggest difference between Zamboni and Zero (WFL). Zamboni manages workflows whereas WFL manages workloads . Zamboni's unit of work is the workflow . Zamboni manages each workflow separately. A workflow is a transformation specified in WDL or Scala code that succeeds or fails to produce a result. The input to a workflow and its result may consist of multiple files, but they represent a single unit of work managed by a workflow engine such as Cromwell. Zamboni prepares a new workflow for each message it receives by packaging up the input and submitting it to a workflow engine. It then monitors that workflow and reports on its success or failure. WFL manages a workload , which indirectly comprises multiple workflows. Each workflow maps an input to some output, but WFL generally tracks only the inputs and outputs instead of the workflows themselves. Think of a workload as a set of inputs transformed via a workflow engine into a set of outputs. Call that set of outputs the result set . WFL generally does not care whether any individual workflow succeeds or fails. It merely considers all possible inputs specified by the workload, and looks for inputs whose outputs are missing from the result set. If some input lacks an output in the result set, WFL starts a new workflow to process that input. Note: This characterization is unfair to Zamboni. Zamboni also had to manage multiple workflows before the advent of Cromwell and still does when running workflows on SGE. But WFL can take advantage of Cromwell's job management to simplify its implementation. Specify inputs and outputs by general predicates. Each Zamboni message explicitly specifies an input to be processed. Zamboni then starts a workflow for that input and reports its status. Zamboni reports failure so a user can debug and manually succeed , reconsider, or restart the workflow. The output of a successful workflow is not Zamboni's concern. WFL finds inputs by applying a predicate specified by the user subject to some run-time constraint. Then WFL applies a function to each input to find how that input maps to the result set. Another predicate applied to the input, and its output in the result set, determines whether WFL will launch a workflow on that input. Those predicates and function can be anything expressed in a programming language. The run-time constraint is some strings passed on the command line. Minimize user input and decisions at run time. WFL gathers the predicates and mapping functions described above into a module that also knows how to generate everything a workflow engine needs to launch the workflow to process an input into a result output. That module name is one of a few run-time constraints specified by strings in a web form or on a command line. Further constraints are usually one or two of the following: - a processing environment ( `dev` `prod` `pharma5` ), - a file system directory ( `/seq/tng/tbl/` `file://home/tbl/` ), - a cloud object prefix ( `gs://bucket/folder/` `s3://bucket/` ), - a pathname suffix ( `.cram` `.vcf` ), - a spreadsheet ( or JSON , TSV , CSV , XML ) filename - or a count to limit the scope of a predicate . The module interprets the other constraints, determines which processing environments are allowed, and parses any files named accordingly. Maintain provenance. WFL runs out of a single JARfile built entirely from sources pulled from Git repositories. WFL records the Git commit hashes in the JARfile and adds them to every Cromwell workflow it starts. WFL can also preserve the Cromwell metadata alongside any result files generated by the workflow. Run with minimal privilege. Zamboni runs as a service with system account credentials such as picard . WFL is designed to run as whoever invokes it, such as tbl@broadinstitute.org . WFL fetches the users credentials from the environment when invoked from the command line. WFL requires authentication when running as a server, and constructs a JSON Web Token (JWT) to authorize other services as needed. Limit dependencies. WFL depends on a Java runtime, and Gnu make and the Clojure CLI to manage dependencies. Of course, it also pulls in numerous Clojure and Java libraries at build time, and sources WDL files from the warp repository. A programmer need only install Clojure, clone the wfl Git repository, and run make to bootstrap WFL from source.","title":"WFL Concepts"},{"location":"terra/#wfl-server","text":"The WFL client is a command-line batch program that a person runs intermittently on a laptop or virtual machine (VM). We are working to port the client functions of WFL to a ubiquitous web service (WFL server) running in Google Cloud. That port requires we solve several problems. State The WFL client is a stateless program that relies on consistent command line arguments to provide the constraints needed to drive the input discovery predicates and so on. Each user runs a separate process that lasts only as long as necessary to complete some stage of a workload. The WFL server is shared among all its users and runs continually. Therefore it requires some kind of data store (a database) to maintain the state of each workload across successive connections from web browsers. We intend to use the hosted Postgres service available to GAE applications for this. This work is already underway (GH-573). Authorization The WFL client assumes it runs in an authenticated context. It can pull credentials from the environment on every invocation that requires authorization to a service. The WFL server will also need to authorize services to run as some authenticated user, but cannot assume the credentials are always available, nor that there is a user present to provide them. WFL can already use OAuth2.0 to authenticate users against an identity provider and use the resulting credentials to build a JWT. It can also derive the bearer token required by most of our authorized services from a JWT. But WFL also needs some secure JWT store, so tokens are available to authorize services even when there is no active user connection. It also needs some mechanism to refresh tokens as they expire to support long-running workloads. Workload specification The user of a WFL service needs some way to specify a workload. A workload may be some set of inputs and the kind of workflow to run on them. A WFL client user now specifies a workload with a module name and a constraint . For example, ukb pharma5 110000 gs://broad-ukb/in/ gs://broad-ukb/out/ means find up to 110000 cloud objects with names prefixed with gs://broad-ukb/in/ , process them in the Cromwell set up for pharma5 , and store their outputs under gs://broad-ukb/out/ somewhere. The ukb module knows how to find .aligned.cram files under the gs://broad-ukb/in/ cloud path and set up the WDL and Cromwell dependencies and options necessary to reprocess them into .cram output files. The ukb module also knows how to find the Cromwell deployed to support pharma5 workloads, how to authorize the user to that Cromwell, and how to read any supporting data from other services. And finally, the ukb module knows how to determine which inputs do not yet have outputs under the gs://broad-ukb/out/ cloud path, and do not have workflows running in the pharma5 Cromwell. In an ideal design, this workload specification would integrate conveniently with the Data Repository's subscription or eventing service. In any case though, WFL needs some interface through which a user can specify what needs to be done. Workload management Workloads need to be started, stopped, and monitored somehow. This implies that there is some way to find active or suspended workloads, and affordances for acting on them. Users need some way to monitor the progress of a workload, and to find and debug workloads encountering unacceptable workflow failures. Monitoring and diagnostic code already exists in various WFL modules, but there is no easy way to use them from a web browser. Service interface WFL should be useful to programs other than web browsers. It is easy to imagine Terra users wanting to query WFL for the status of workloads directly without buggy and tedious screen scraping. WFL should at least export a query endpoint for use by other reporting services as well as its own browser interface. It would be nice to provide a familiar JSON or GraphQL query syntax to other services. Browser interface A browser interface should require little in addition to WFL's service interface. Ideally, one should be able to adapt WFL to new workloads via a browser interface without requiring a redeployment.","title":"WFL server"},{"location":"usage-abort/","text":"Aborting a WFL Workload \u2693\ufe0e Aborting a workload is done by aborting individual workflows directly with Cromwell. Tip This only works with Cromwell! Don't try this script for things running in Terra, it won't work. Here's a script that can help with that: # Usage: bash abort.sh QUERY [WFL_URL] [THREADS] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is optionally the WFL to abort workflows from # Default is the gotc-prod WFL # THREADS is optionally the number of threads to use to talk to Cromwell # Default is 2 # Usage: bash abort.sh QUERY [WFL_URL] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is the WFL instance to abort workflows from [default: gotc-prod] WFL_URL = \" ${ 2 :- https ://gotc-prod-wfl.gotc-prod.broadinstitute.org } \" AUTH_HEADER = \"Authorization: Bearer $( gcloud auth print-access-token ) \" getWorkloads () { # Query -> [Workload] curl -s -X GET \" ${ WFL_URL } /api/v1/workload? $1 \" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } getWorkflows () { # Workload -> [Workflow] uuid = $( jq -r .uuid <<< \" $1 \" ) curl -s -X GET \" ${ WFL_URL } /api/v1/workload/ ${ uuid } /workflows\" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } mapjq () { jq -c '.[]' <<< \" ${ 2 } \" \\ | while read elem ; do ${ 1 } \" ${ elem } \" ; done \\ | jq '[ .[] ]' } main () { # Query -> () workloads = $( getWorkloads \" ${ 1 } \" ) cromwell = $( jq -r 'map(.executor) | .[0]' <<< \" $WORKLOAD \" ) mapjq getWorkflows \" ${ workloads } \" | jq -s 'flatten | map(select(.status != \"Failed\" and .status != \"Succeeded\") | .uuid) | .[]' \\ | xargs -I % -n 1 -P ${ 3 :- 2 } curl -w \"\\n\" -s -X POST \" $CROMWELL /api/workflows/v1/%/abort\" \\ -H \" ${ AUTH_HEADER } \" \\ -H \"Content-Type: application/json\" } main \" $1 \" The 'QUERY' part is like you'd pass to retry.sh . You don't necessarily need to query WFL for the workload. As of this writing, the response from /start or /exec includes the workflow UUIDs, so if you stored that response in WORKLOAD then you could abort it without having to query WFL (and trigger WFL's potentially lengthy update process).","title":"Aborting a Workload"},{"location":"usage-abort/#aborting-a-wfl-workload","text":"Aborting a workload is done by aborting individual workflows directly with Cromwell. Tip This only works with Cromwell! Don't try this script for things running in Terra, it won't work. Here's a script that can help with that: # Usage: bash abort.sh QUERY [WFL_URL] [THREADS] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is optionally the WFL to abort workflows from # Default is the gotc-prod WFL # THREADS is optionally the number of threads to use to talk to Cromwell # Default is 2 # Usage: bash abort.sh QUERY [WFL_URL] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is the WFL instance to abort workflows from [default: gotc-prod] WFL_URL = \" ${ 2 :- https ://gotc-prod-wfl.gotc-prod.broadinstitute.org } \" AUTH_HEADER = \"Authorization: Bearer $( gcloud auth print-access-token ) \" getWorkloads () { # Query -> [Workload] curl -s -X GET \" ${ WFL_URL } /api/v1/workload? $1 \" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } getWorkflows () { # Workload -> [Workflow] uuid = $( jq -r .uuid <<< \" $1 \" ) curl -s -X GET \" ${ WFL_URL } /api/v1/workload/ ${ uuid } /workflows\" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } mapjq () { jq -c '.[]' <<< \" ${ 2 } \" \\ | while read elem ; do ${ 1 } \" ${ elem } \" ; done \\ | jq '[ .[] ]' } main () { # Query -> () workloads = $( getWorkloads \" ${ 1 } \" ) cromwell = $( jq -r 'map(.executor) | .[0]' <<< \" $WORKLOAD \" ) mapjq getWorkflows \" ${ workloads } \" | jq -s 'flatten | map(select(.status != \"Failed\" and .status != \"Succeeded\") | .uuid) | .[]' \\ | xargs -I % -n 1 -P ${ 3 :- 2 } curl -w \"\\n\" -s -X POST \" $CROMWELL /api/workflows/v1/%/abort\" \\ -H \" ${ AUTH_HEADER } \" \\ -H \"Content-Type: application/json\" } main \" $1 \" The 'QUERY' part is like you'd pass to retry.sh . You don't necessarily need to query WFL for the workload. As of this writing, the response from /start or /exec includes the workflow UUIDs, so if you stored that response in WORKLOAD then you could abort it without having to query WFL (and trigger WFL's potentially lengthy update process).","title":"Aborting a WFL Workload"},{"location":"usage-across-directory/","text":"Using WFL Across a Directory \u2693\ufe0e WFL supports starting workflows from a single file each--depending on the pipeline you specify, other inputs will be extrapolated (see WFL's docs for the specific pipeline for more information). If you have a set of files uploaded to a GCS bucket and you'd like to start a workflow for each one, you can do that via shell scripting. Suppose we have a set of CRAMs in a folder in some bucket, and we'd like to submit them all to WFL for ExternalExomeReprocessing (perhaps associated with some project or ticket, maybe PO-1234). We'll write a short bash script that will handle this for us. Tip Make sure you're able to list the files yourself! You'll need permissions and you may need to run gcloud auth login Step 1: List Files \u2693\ufe0e We need a list of all the files you intend to process. This'll depend on the file location, gs://broad-gotc-dev-wfl-ptc-test-inputs/ for example. We can use wildcards to list out the individual files we'd like. Make some scratch file like script.sh and store the list of CRAMs in a variable: # In script.sh CRAMS = $( gsutil ls 'gs://broad-gotc-dev-wfl-ptc-test-inputs/**.cram' ) Step 2: Format Items \u2693\ufe0e First, we need to turn that string output into an actual list of file paths. We can use jq to split into lines and select ones that are paths: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))' <<< \" $CRAMS \" ) Next, we need to format each of those file paths into inputs. WFL doesn't just accept a list of files because we allow configuration of many other inputs and options. ITEMS = $( jq 'map({ inputs: { input_cram: .} })' <<< \" $FILES \" ) Info If you want to process BAMs, you'll need to use input_bam instead of input_cram above. Step 3: Make Request \u2693\ufe0e Now, we can simply insert those items into a normal ExternalExomeReprocessing workload request: REQUEST = $( jq '{ cromwell: \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", output: \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output\", pipeline: \"ExternalExomeReprocessing\", project: \"PO-1234\", items: . }' <<< \" $ITEMS \" ) Info Remember to change the output bucket! And the project isn't used by WFL but we keep track of it to help you organize workloads based on tickets or anything else. Info You can make other customizations here too, like specifying some input or option across all the workflows by adding a common block. See the docs for your pipeline or the workflow options page for more info. Last, we can use curl to send off the request to WFL: curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \" $REQUEST \" Warning Curl will complain if the $REQUEST here contains more than thousand lines of data. Remember to dump the payload to a file such as payload.json and let Curl read from that file instead in that case. For example, the last step can be replaced by: echo \" $REQUEST \" >> \"payload.json\" curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \"@payload.json\" With this, the final result is something like the following: CRAMS = $( gsutil ls 'gs://broad-gotc-dev-wfl-ptc-test-inputs/**.cram' ) FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))' <<< \" $CRAMS \" ) ITEMS = $( jq 'map({ inputs: { input_cram: .} })' <<< \" $FILES \" ) REQUEST = $( jq '{ cromwell: \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", output: \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output\", pipeline: \"ExternalExomeReprocessing\", project: \"PO-1234\", items: . }' <<< \" $ITEMS \" ) curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \" $REQUEST \" Save that as script.sh and run with bash myscript.sh and you should be good to go! Other Notes \u2693\ufe0e Have a lot of workflows to submit? You can use array slicing to help split things up: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))[0:5000]' <<< \" $CRAMS \" ) Need to select files matching some other query too? You can chain the map - select commands and use other string filters on the file names: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\"))) | map(select(contains(\"foobar\")))' <<< \" $CRAMS \" ) If contains / startswith / endswith aren't enough, you can use test with PCRE regex: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\"))) | map(select(test(\"fo+bar\")))' <<< \" $CRAMS \" ) See this page for more jq info .","title":"Usage Across a Directory"},{"location":"usage-across-directory/#using-wfl-across-a-directory","text":"WFL supports starting workflows from a single file each--depending on the pipeline you specify, other inputs will be extrapolated (see WFL's docs for the specific pipeline for more information). If you have a set of files uploaded to a GCS bucket and you'd like to start a workflow for each one, you can do that via shell scripting. Suppose we have a set of CRAMs in a folder in some bucket, and we'd like to submit them all to WFL for ExternalExomeReprocessing (perhaps associated with some project or ticket, maybe PO-1234). We'll write a short bash script that will handle this for us. Tip Make sure you're able to list the files yourself! You'll need permissions and you may need to run gcloud auth login","title":"Using WFL Across a Directory"},{"location":"usage-across-directory/#step-1-list-files","text":"We need a list of all the files you intend to process. This'll depend on the file location, gs://broad-gotc-dev-wfl-ptc-test-inputs/ for example. We can use wildcards to list out the individual files we'd like. Make some scratch file like script.sh and store the list of CRAMs in a variable: # In script.sh CRAMS = $( gsutil ls 'gs://broad-gotc-dev-wfl-ptc-test-inputs/**.cram' )","title":"Step 1: List Files"},{"location":"usage-across-directory/#step-2-format-items","text":"First, we need to turn that string output into an actual list of file paths. We can use jq to split into lines and select ones that are paths: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))' <<< \" $CRAMS \" ) Next, we need to format each of those file paths into inputs. WFL doesn't just accept a list of files because we allow configuration of many other inputs and options. ITEMS = $( jq 'map({ inputs: { input_cram: .} })' <<< \" $FILES \" ) Info If you want to process BAMs, you'll need to use input_bam instead of input_cram above.","title":"Step 2: Format Items"},{"location":"usage-across-directory/#step-3-make-request","text":"Now, we can simply insert those items into a normal ExternalExomeReprocessing workload request: REQUEST = $( jq '{ cromwell: \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", output: \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output\", pipeline: \"ExternalExomeReprocessing\", project: \"PO-1234\", items: . }' <<< \" $ITEMS \" ) Info Remember to change the output bucket! And the project isn't used by WFL but we keep track of it to help you organize workloads based on tickets or anything else. Info You can make other customizations here too, like specifying some input or option across all the workflows by adding a common block. See the docs for your pipeline or the workflow options page for more info. Last, we can use curl to send off the request to WFL: curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \" $REQUEST \" Warning Curl will complain if the $REQUEST here contains more than thousand lines of data. Remember to dump the payload to a file such as payload.json and let Curl read from that file instead in that case. For example, the last step can be replaced by: echo \" $REQUEST \" >> \"payload.json\" curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \"@payload.json\" With this, the final result is something like the following: CRAMS = $( gsutil ls 'gs://broad-gotc-dev-wfl-ptc-test-inputs/**.cram' ) FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))' <<< \" $CRAMS \" ) ITEMS = $( jq 'map({ inputs: { input_cram: .} })' <<< \" $FILES \" ) REQUEST = $( jq '{ cromwell: \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", output: \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output\", pipeline: \"ExternalExomeReprocessing\", project: \"PO-1234\", items: . }' <<< \" $ITEMS \" ) curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \" $REQUEST \" Save that as script.sh and run with bash myscript.sh and you should be good to go!","title":"Step 3: Make Request"},{"location":"usage-across-directory/#other-notes","text":"Have a lot of workflows to submit? You can use array slicing to help split things up: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))[0:5000]' <<< \" $CRAMS \" ) Need to select files matching some other query too? You can chain the map - select commands and use other string filters on the file names: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\"))) | map(select(contains(\"foobar\")))' <<< \" $CRAMS \" ) If contains / startswith / endswith aren't enough, you can use test with PCRE regex: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\"))) | map(select(test(\"fo+bar\")))' <<< \" $CRAMS \" ) See this page for more jq info .","title":"Other Notes"},{"location":"usage-retry/","text":"Retrying Workflows \u2693\ufe0e Retrying Terra Workflows via WFL API \u2693\ufe0e WFL staged workloads with a Terra executor have a /retry endpoint that selects unretried workflows by their submission ID and re-submits them. The following curl shell command finds the unretried workflows launched by submission $SUBMISSION in workload $UUID and resubmits the underlying snapshot for processing. WFL = https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload AUTH = \"Authorization: Bearer $( gcloud auth print-access-token ) \" UUID = 0d307eb3-2b8e-419c-b687-8c08c84e2a0c # workload UUID SUBMISSION = 14bffc69-6ce7-4615-b318-7ef1c457c894 # Terra submission UUID curl -X POST -H \" $AUTH \" $WFL / $UUID /retry \\ --data '{\"submission\":\"$SUBMISSION\"}' \\ | jq A successful /retry request returns the workload specified by $UUID . A failed /retry request will return a description of the failure. For legacy (non-staged) workloads, the /retry endpoint is unimplemented and returns a 501 HTTP failure status. In such cases, retries may be facilitated by the runbook below. Request Body \u2693\ufe0e The request body filters must be valid: Mandatory submission - Terra submission ID (must be a valid UUID) Optional status - Workflow status (if specified, must be a retriable Cromwell workflow status) The only Cromwell statuses supported with the /retry API are the terminal workflow statuses: \"Aborted\" \"Failed\" \"Succeeded\" Why would you retry succeeded workflows? A workflow may have functionally succeeded, but be scientifically inaccurate and need to be rerun, e.g. if the initial run contained incorrect metadata. Attempting to retry workflows of any other status will return a 400 HTTP failure status, as will a valid combination of filters with no matching workflows in WFL's DB. Examples: A valid Terra submission ID for a different workload \"Failed\" workflow status when all unretried workflows had \"Succeeded\" Warnings and Caveats \u2693\ufe0e Submission of snapshot subsets not yet supported \u2693\ufe0e WFL is limited by Rawls functionality and cannot yet submit a subset of a snapshot. So retrying any workflow from a workload snapshot will resubmit all entities from that snapshot. (Because of this, the optional workflow status filter is purely decorative: all sibling workflows from the same submission will be resubmitted, regardless of their status.) Example - a running submission from a snapshot has 500 workflows: 1 failed 249 running 250 succeeded Retrying the failed workflow will create a new submission where all 500 original workflows are retried. Consider whether you should wait for all workflows in the submission to complete before initiating a retry to avoid multiple workflows running concurrently in competition for the same output files. Race condition when retrying the same workload concurrently \u2693\ufe0e A caller could hit this endpoint for the same workload multiple times in quick succession, making possible a race condition where each run retries the same set of workflows. Future improvements will make this operation threadsafe, but in the interim try to wait for a response from your retry request before resubmitting. Retrying Failures via WFL Runbook \u2693\ufe0e For legacy (non-staged) workloads, WFL remembers enough about submissions to let you quickly resubmit failed workflows with the same inputs/options as they were originally submitted. All you need is a query string like you'd pass to the /workflows endpoint, either: uuid=<UUID> where <UUID> is the identifier of the specific workload you'd like to retry failures from Ex: uuid=95d536c7-ce3e-4ffc-8c9c-2b9c710d625a project=<PROJECT> where <PROJECT> is the value of the project field of the workloads you'd like to retry Ex: project=PO-29619 With the below script, WFL will find matching workloads and resubmit any unique failures of individual workflows in a new workload (with the same parameters as the originals). Usage: bash retry.sh QUERY Ex: bash retry.sh project=PO-29619 # Usage: bash abort.sh QUERY [WFL_URL] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is the WFL instance to retry workflows from [default: gotc-prod] WFL_URL = \" ${ 2 :- https ://gotc-prod-wfl.gotc-prod.broadinstitute.org } \" AUTH_HEADER = \"Authorization: Bearer $( gcloud auth print-access-token ) \" getWorkloads () { # Query -> [Workload] curl -s -X GET \" ${ WFL_URL } /api/v1/workload? $1 \" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } getWorkflows () { # Workload -> [Workflow] uuid = $( jq -r .uuid <<< \" $1 \" ) curl -s -X GET \" ${ WFL_URL } /api/v1/workload/ ${ uuid } /workflows\" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } failedWorkflowsToSubmit () { # [[Workflow]] -> [Workflow] jq 'flatten | map ( select ( .status==\"Failed\" ) | {inputs: .inputs, options: .options} | del ( .[] | nulls ) ) ' <<< \" $1 \" } makeRetryRequest () { # [Workload], [Workflow] -> Request jq --argjson 'workflows' \" $2 \" \\ '.[0] | { executor: .executor , input: .input , output: .output , pipeline: .pipeline , project: .project , items: $workflows } | del(.[] | nulls) ' <<< \" $1 \" } mapjq () { jq -c '.[]' <<< \" ${ 2 } \" \\ | while read elem ; do ${ 1 } \" ${ elem } \" ; done \\ | jq -s '[ .[] ]' } main () { # Query -> () workloads = $( getWorkloads \" ${ 1 } \" ) workflows = $( mapjq getWorkflows \" ${ workloads } \" ) toSubmit = $( failedWorkflowsToSubmit \" ${ workflows } \" ) makeRetryRequest \" ${ workloads [0] } \" \" ${ toSubmit } \" > /tmp/retry.json curl -X POST \" ${ WFL_URL } /api/v1/exec\" \\ -H \" ${ AUTH_HEADER } \" \\ -H \"Content-Type: application/json\" \\ -d @/tmp/retry.json } main \" $1 \" Tips \u2693\ufe0e Customizing Inputs/Options \u2693\ufe0e If you want to inject a new input or option into all of the retried workflows, you can do that with a common block. For example, replace this: jq '{ executor: .executor, with this: jq '{ common: { inputs: { \"WholeGenomeReprocessing.WholeGenomeGermlineSingleSample.BamToCram.ValidateCram.memory_multiplier\": 2 } }, executor: .executor, That example uses WFL's arbitrary input feature to bump up the memory multiplier for a particular WGS task. Nested inputs will have periods in them, you'll need to use quotes around it You can't override inputs or options that the workflows originally had (the common block has lower precedence)","title":"Retrying Workflows"},{"location":"usage-retry/#retrying-workflows","text":"","title":"Retrying Workflows"},{"location":"usage-retry/#retrying-terra-workflows-via-wfl-api","text":"WFL staged workloads with a Terra executor have a /retry endpoint that selects unretried workflows by their submission ID and re-submits them. The following curl shell command finds the unretried workflows launched by submission $SUBMISSION in workload $UUID and resubmits the underlying snapshot for processing. WFL = https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload AUTH = \"Authorization: Bearer $( gcloud auth print-access-token ) \" UUID = 0d307eb3-2b8e-419c-b687-8c08c84e2a0c # workload UUID SUBMISSION = 14bffc69-6ce7-4615-b318-7ef1c457c894 # Terra submission UUID curl -X POST -H \" $AUTH \" $WFL / $UUID /retry \\ --data '{\"submission\":\"$SUBMISSION\"}' \\ | jq A successful /retry request returns the workload specified by $UUID . A failed /retry request will return a description of the failure. For legacy (non-staged) workloads, the /retry endpoint is unimplemented and returns a 501 HTTP failure status. In such cases, retries may be facilitated by the runbook below.","title":"Retrying Terra Workflows via WFL API"},{"location":"usage-retry/#request-body","text":"The request body filters must be valid: Mandatory submission - Terra submission ID (must be a valid UUID) Optional status - Workflow status (if specified, must be a retriable Cromwell workflow status) The only Cromwell statuses supported with the /retry API are the terminal workflow statuses: \"Aborted\" \"Failed\" \"Succeeded\" Why would you retry succeeded workflows? A workflow may have functionally succeeded, but be scientifically inaccurate and need to be rerun, e.g. if the initial run contained incorrect metadata. Attempting to retry workflows of any other status will return a 400 HTTP failure status, as will a valid combination of filters with no matching workflows in WFL's DB. Examples: A valid Terra submission ID for a different workload \"Failed\" workflow status when all unretried workflows had \"Succeeded\"","title":"Request Body"},{"location":"usage-retry/#warnings-and-caveats","text":"","title":"Warnings and Caveats"},{"location":"usage-retry/#submission-of-snapshot-subsets-not-yet-supported","text":"WFL is limited by Rawls functionality and cannot yet submit a subset of a snapshot. So retrying any workflow from a workload snapshot will resubmit all entities from that snapshot. (Because of this, the optional workflow status filter is purely decorative: all sibling workflows from the same submission will be resubmitted, regardless of their status.) Example - a running submission from a snapshot has 500 workflows: 1 failed 249 running 250 succeeded Retrying the failed workflow will create a new submission where all 500 original workflows are retried. Consider whether you should wait for all workflows in the submission to complete before initiating a retry to avoid multiple workflows running concurrently in competition for the same output files.","title":"Submission of snapshot subsets not yet supported"},{"location":"usage-retry/#race-condition-when-retrying-the-same-workload-concurrently","text":"A caller could hit this endpoint for the same workload multiple times in quick succession, making possible a race condition where each run retries the same set of workflows. Future improvements will make this operation threadsafe, but in the interim try to wait for a response from your retry request before resubmitting.","title":"Race condition when retrying the same workload concurrently"},{"location":"usage-retry/#retrying-failures-via-wfl-runbook","text":"For legacy (non-staged) workloads, WFL remembers enough about submissions to let you quickly resubmit failed workflows with the same inputs/options as they were originally submitted. All you need is a query string like you'd pass to the /workflows endpoint, either: uuid=<UUID> where <UUID> is the identifier of the specific workload you'd like to retry failures from Ex: uuid=95d536c7-ce3e-4ffc-8c9c-2b9c710d625a project=<PROJECT> where <PROJECT> is the value of the project field of the workloads you'd like to retry Ex: project=PO-29619 With the below script, WFL will find matching workloads and resubmit any unique failures of individual workflows in a new workload (with the same parameters as the originals). Usage: bash retry.sh QUERY Ex: bash retry.sh project=PO-29619 # Usage: bash abort.sh QUERY [WFL_URL] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is the WFL instance to retry workflows from [default: gotc-prod] WFL_URL = \" ${ 2 :- https ://gotc-prod-wfl.gotc-prod.broadinstitute.org } \" AUTH_HEADER = \"Authorization: Bearer $( gcloud auth print-access-token ) \" getWorkloads () { # Query -> [Workload] curl -s -X GET \" ${ WFL_URL } /api/v1/workload? $1 \" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } getWorkflows () { # Workload -> [Workflow] uuid = $( jq -r .uuid <<< \" $1 \" ) curl -s -X GET \" ${ WFL_URL } /api/v1/workload/ ${ uuid } /workflows\" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } failedWorkflowsToSubmit () { # [[Workflow]] -> [Workflow] jq 'flatten | map ( select ( .status==\"Failed\" ) | {inputs: .inputs, options: .options} | del ( .[] | nulls ) ) ' <<< \" $1 \" } makeRetryRequest () { # [Workload], [Workflow] -> Request jq --argjson 'workflows' \" $2 \" \\ '.[0] | { executor: .executor , input: .input , output: .output , pipeline: .pipeline , project: .project , items: $workflows } | del(.[] | nulls) ' <<< \" $1 \" } mapjq () { jq -c '.[]' <<< \" ${ 2 } \" \\ | while read elem ; do ${ 1 } \" ${ elem } \" ; done \\ | jq -s '[ .[] ]' } main () { # Query -> () workloads = $( getWorkloads \" ${ 1 } \" ) workflows = $( mapjq getWorkflows \" ${ workloads } \" ) toSubmit = $( failedWorkflowsToSubmit \" ${ workflows } \" ) makeRetryRequest \" ${ workloads [0] } \" \" ${ toSubmit } \" > /tmp/retry.json curl -X POST \" ${ WFL_URL } /api/v1/exec\" \\ -H \" ${ AUTH_HEADER } \" \\ -H \"Content-Type: application/json\" \\ -d @/tmp/retry.json } main \" $1 \"","title":"Retrying Failures via WFL Runbook"},{"location":"usage-retry/#tips","text":"","title":"Tips"},{"location":"usage-retry/#customizing-inputsoptions","text":"If you want to inject a new input or option into all of the retried workflows, you can do that with a common block. For example, replace this: jq '{ executor: .executor, with this: jq '{ common: { inputs: { \"WholeGenomeReprocessing.WholeGenomeGermlineSingleSample.BamToCram.ValidateCram.memory_multiplier\": 2 } }, executor: .executor, That example uses WFL's arbitrary input feature to bump up the memory multiplier for a particular WGS task. Nested inputs will have periods in them, you'll need to use quotes around it You can't override inputs or options that the workflows originally had (the common block has lower precedence)","title":"Customizing Inputs/Options"},{"location":"usage-workflow-options/","text":"Customizing Workflow Options \u2693\ufe0e Tip This page covers customizing workflow options , which are different from the inputs passed to the WDL. Workflow options are interpreted directly by Cromwell, though WDLs can customize them too. For more information see Cromwell's documentation . Another important piece of context for this page is the difference between a workflow that actually gets run on Cromwell versus a workload (a WFL-managed set of individual workflows). Usage \u2693\ufe0e Summary Workflow options are an arbitrary JSON object stored in a key of options Can be provided per-workflow, for an entire workload, or both Optional -- you only need to specify options if you'd like to override something Suppose the following valid workload request that you might POST to /create or /exec : { \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"project\" : \"PO-1234\" , \"items\" : [ { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" } } ] } You may optionally add arbitrary JSON objects as options either for individual workflows, for the entire workload, or both: { \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"project\" : \"PO-1234\" , \"common\" : { \"options\" : { \"write_to_cache\" : false , \"google_project\" : \"broad-google-project\" } }, \"items\" : [ { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-something-execution\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-different-execution\" , \"default_runtime_attributes\" : { \"maxRetries\" : 3 }, \"google_project\" : \"broad-google-project-2\" } } ] } Info This behavior isn't supported for All-of-Us-related processing. To recap, in the above example the following workflow options will be set: \"jes_gcs_root\" will have different values for the different samples \"default_runtime_attributes\" will override the \"maxRetries\" value to be 3 \"write_to_cache\" will be false for all samples \"google_project\" is broad-google-project for the entire workload but is overridden in the second sample to be broad-google-project-2 (providing an option with more granularity gives it higher precedence) In other words, WFL will recursively merge the options objects together to resolve the options for individual workflows. You can see this in WFL's response, which includes all workflow options calculated for each workflow: [{ \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-something-execution\" , \"write_to_cache\" : false , \"google_project\" : \"broad-google-project\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-different-execution\" , \"default_runtime_attributes\" : { \"maxRetries\" : 3 }, \"write_to_cache\" : false , \"google_project\" : \"broad-google-project-2\" } }] One note is that WFL already has some default values it passes for workflow options and you'll see those defaults when you look at the returned options for a given workflow. See below for more information. Behavior \u2693\ufe0e The diagram below lists the different sources of options for a particular workflow. Precedence is from the bottom up, so \"higher\" sources override lower ones. The green \"sources\" are where you may optionally provide configuration via options , the white \"sources\" are where WFL may create and supply options by default, and the gray \"sources\" are outside of WFL's visibility but can still affect the result. WFL supplies its own derived options usually on a per-module basis, meaning different pipelines that make use of different modules may have different options they derive and supply by default. Individual module documentation can help provide more info, as will simply looking at WFL's response from the /create or /exec endpoints, which includes those defaults.","title":"Workflow Options"},{"location":"usage-workflow-options/#customizing-workflow-options","text":"Tip This page covers customizing workflow options , which are different from the inputs passed to the WDL. Workflow options are interpreted directly by Cromwell, though WDLs can customize them too. For more information see Cromwell's documentation . Another important piece of context for this page is the difference between a workflow that actually gets run on Cromwell versus a workload (a WFL-managed set of individual workflows).","title":"Customizing Workflow Options"},{"location":"usage-workflow-options/#usage","text":"Summary Workflow options are an arbitrary JSON object stored in a key of options Can be provided per-workflow, for an entire workload, or both Optional -- you only need to specify options if you'd like to override something Suppose the following valid workload request that you might POST to /create or /exec : { \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"project\" : \"PO-1234\" , \"items\" : [ { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" } } ] } You may optionally add arbitrary JSON objects as options either for individual workflows, for the entire workload, or both: { \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"project\" : \"PO-1234\" , \"common\" : { \"options\" : { \"write_to_cache\" : false , \"google_project\" : \"broad-google-project\" } }, \"items\" : [ { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-something-execution\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-different-execution\" , \"default_runtime_attributes\" : { \"maxRetries\" : 3 }, \"google_project\" : \"broad-google-project-2\" } } ] } Info This behavior isn't supported for All-of-Us-related processing. To recap, in the above example the following workflow options will be set: \"jes_gcs_root\" will have different values for the different samples \"default_runtime_attributes\" will override the \"maxRetries\" value to be 3 \"write_to_cache\" will be false for all samples \"google_project\" is broad-google-project for the entire workload but is overridden in the second sample to be broad-google-project-2 (providing an option with more granularity gives it higher precedence) In other words, WFL will recursively merge the options objects together to resolve the options for individual workflows. You can see this in WFL's response, which includes all workflow options calculated for each workflow: [{ \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-something-execution\" , \"write_to_cache\" : false , \"google_project\" : \"broad-google-project\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-different-execution\" , \"default_runtime_attributes\" : { \"maxRetries\" : 3 }, \"write_to_cache\" : false , \"google_project\" : \"broad-google-project-2\" } }] One note is that WFL already has some default values it passes for workflow options and you'll see those defaults when you look at the returned options for a given workflow. See below for more information.","title":"Usage"},{"location":"usage-workflow-options/#behavior","text":"The diagram below lists the different sources of options for a particular workflow. Precedence is from the bottom up, so \"higher\" sources override lower ones. The green \"sources\" are where you may optionally provide configuration via options , the white \"sources\" are where WFL may create and supply options by default, and the gray \"sources\" are outside of WFL's visibility but can still affect the result. WFL supplies its own derived options usually on a per-module basis, meaning different pipelines that make use of different modules may have different options they derive and supply by default. Individual module documentation can help provide more info, as will simply looking at WFL's response from the /create or /exec endpoints, which includes those defaults.","title":"Behavior"}]}