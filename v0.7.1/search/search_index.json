{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to WorkFlow Launcher \u2693\ufe0e Overview \u2693\ufe0e WorkFlow Launcher (WFL) is a workload manager. For example, a workload could be a set of Whole Genome samples to be reprocessed in a given project/bucket, the workflow is the processing of an individual sample in that workload running WGS reprocessing; a workload could also be a queue of incoming notifications that describe all of the required inputs to launch Arrays scientific pipelines in Cromwell. WFL is designed to be deployed to run as a service in the cloud, primarily on Kubernetes clusters. For more on Workflow Launcher's role in the Terra infrastructure see Workflow Launcher's role in Terra . Quickstart \u2693\ufe0e Tip This is the Quickstart section, which should cover the most frequent uses cases that interact with WFL. For more detailed information, please check other sections such as the development guide or modules design principles . Build \u2693\ufe0e The easiest way to build WFL is via make , in addition, the following prerequisites are needed: The Docker daemon Clojure ( brew install clojure on macOS) Python3 ( brew install python@3.9 on macOS) NodeJS ( brew install node on macOS) Google Cloud SDK ( brew install --cask google-cloud-sdk on macOS) Arch Linux tips Install clojure from the official repository. Install google-cloud-sdk from the AUR. You could then invoke make at the project level to test and build all workflow-launcher modules: $ make -j8 where 8 can be replaced by any number that represents the concurrent jobs you wish to run. Info If the version of your make is above GNU Make 4.0 (you could check by running make --version ), it's highly recommended to use --output-sync along with -j so the standard outputs are sorted, i.e. $ make -j8 --output-sync make will build each module in workflow-launcher , run tests and generate Docker images. All generated files go into a derived directory under the project root. You can also invoke make on a module from the top level directory by $ make [ MODULE ] TARGET ={ prebuild | build | check | images | clean | distclean } where currently available MODULE s are {api functions/aou docs helm ui} For most of the time, you would want to run something like: $ make clean to clean up the built modules ( -j8 is also available for make clean ). and then run: $ make ui api TARGET = images -j8 to only build the WFL and its docker images without running tests. Info Note if you updated the second party repositories such as pipeline-config or gotc-deploy , you might have to run: $ make distclean to remove them. This is not always needed but can help completely purge the local derived files. Test \u2693\ufe0e If you only want to run tests on specific modules, you could run: $ make [ MODULE ] TARGET = check such as make api TARGET=check or make functions/aou TARGET=check . Note this automatically makes all of check 's prerequisites. Clojure Test \u2693\ufe0e When it comes to clojure tests, sometimes it's useful to only run a subset of tests to save time and filter out noise. You can do this by directly invoke clojure cli from within the api directory, for example, cd api and: $ clojure -M:test integration --focus wfl.integration.modules.copyfile-test In general, we implement Clojure tests under the test/ root directory and use the kaocha test runner. Test suites use a -test namespace suffix. You can pass extra command line arguments to kaocha , such as the above --focus flag. You can see the full list of options with the following: clojure -M:test --help At present, wfl api has three kinds of test, unit , integration , and system . These can be run via the deps.edn , optionally specifying the kind: clojure -M:test [ unit | integration | system ] Note that the integration tests currently require a little more configuration before they can be run, namely, they require a wfl server running locally: ./ops/server.sh Additionally, there is a custom parallel test runner that can be invoked to help speed up the system tests. Rather than clojure -M:test system you'd just specify the namespace(s) to try to parallelize. clojure -M:parallel-test wfl.system.v1-endpoint-test Info Note for system tests, no matter it's kicked off through clojure -M:test system or clojure -M:parallel-test wfl.system.v1-endpoint-test , you can use an environment variable WFL_CROMWELL_URL to override the default Cromwell instance that's used in the test. For example: WFL_CROMWELL_URL = https://cromwell-gotc-auth.gotc-prod.broadinstitute.org/ clojure -M:parallel-test wfl.system.v1-endpoint-test will tell the test to submit workflows to the \"gotc-prod\" Cromwell instance no matter what the default instance was defined in the test. However, you need to make sure the validity of the Cromwell URL you passed in; certain IAM permissions will also be required in order for Cromwell to execute the testing workflows smoothly. Deploy \u2693\ufe0e Currently, we mainly deploy WFL to broad-gotc-dev and broad-gotc-prod projects. When it's time to deploy WFL, for most of the time developers need to release a new version following the steps in Release Guide After which, the developers who have broad VPN connected can go to the Jenkins Page to deploy applicable versions of WFL to various available cloud projects. Implementation \u2693\ufe0e For frontend details, check Frontend Section Top-level files \u2693\ufe0e After cloning a new WFL repo, the top-level files are: . \u251c\u2500\u2500 api/ - `workflow-launcher` backend \u251c\u2500\u2500 functions/ - cloud functions deployed separately \u251c\u2500\u2500 database/ - database scheme migration changelog and changeset \u251c\u2500\u2500 derived/ - generated artifacts \u251c\u2500\u2500 docs/ - ancillary documentation \u251c\u2500\u2500 helm/ - helm-managed k8s configuration \u251c\u2500\u2500 LICENSE.txt \u251c\u2500\u2500 Makefile - project level` Makefile` \u251c\u2500\u2500 makerules/ - common `Makefile` functionality \u251c\u2500\u2500 ops/ - scripts to support Operations \u251c\u2500\u2500 README.md - symbolic link to docs/md/README.md \u251c\u2500\u2500 ui/ - `workflow-launcher` frontend \u2514\u2500\u2500 version - holds the current semantic version Tip: Run make at least once after cloning the repo to make sure all the necessary files are in place. api Module \u2693\ufe0e Source code \u2693\ufe0e The Clojure source code is in the api/src/ directory. The entry point for the WFL executable is the -main function in main.clj . It takes the command line arguments as strings, validates the arguments, then launches the appropriate process. The server.clj file implements the WFL server. The server_debug.clj file adds some tools to aid in debugging the server. Some hacks specific to WFL are in wfl.clj . The build.clj file includes build and deployment code. The debug.clj file defines some macros useful when debugging or logging. The util.clj file contains a few functions and macros used in WFL that are not specific to its function. The environments.clj file defines configuration parameters for different execution contexts. It's a placeholder in this repo but will be loaded in build/deploy time from a private repo. The module/xx.clj file implements a command-line starter for reprocessing eXternal eXomes . The module/wgs.clj file helps implements a command-line starter for reprocessing Whole GenomeS . The module/sg.clj file implements Somatic Genomes support. The module/all.clj file hosts some utilities shared across modules. The metadata.clj file implements a tool to extract metadata from Cromwell that can be archived with the outputs generated by a workflow. The dx.clj file implements miscellaneous pipeline debugging tools. The once.clj file defines some initialization functions mostly supporting authentication. The api/handlers.clj file defines the handler functions used by server. The api/routes.clj file defines the routing strategy for server. Each of the other source files implement an interface to one of the services WFL talks to, and are named accordingly. File Service cromwell.clj Cromwell workflow runner datarepo.clj DSP DataRepo db.clj On-prem and Cloud SQL databases gcs.clj Google Cloud Storage jms.clj Java Message Service queues postgres.clj Cloud SQL postgres databases server.clj the WFL server itself Exomes in the Cloud Resources \u2693\ufe0e From Hybrid Selection in the Cloud V1 Clients Google Cloud Storage Client Library (Java) Google Cloud Client Library for Java Diagrams Zamboni Overview Sources /Users/tbl/Broad/zamboni/Client/src/scala/org/broadinstitute/zamboni/client/lightning/clp/Lightning.scala /Users/tbl/Broad/picard-private/src/java/edu/mit/broad/picard/lightning /Users/tbl/Broad/gppipeline-devtools/release client /Users/tbl/Broad/gppipeline-devtools/starter control /picard02:/seq/pipeline/gppipeline-devtools/current/defs/prod.defs","title":"Get Started"},{"location":"index.html#welcome-to-workflow-launcher","text":"","title":"Welcome to WorkFlow Launcher"},{"location":"index.html#overview","text":"WorkFlow Launcher (WFL) is a workload manager. For example, a workload could be a set of Whole Genome samples to be reprocessed in a given project/bucket, the workflow is the processing of an individual sample in that workload running WGS reprocessing; a workload could also be a queue of incoming notifications that describe all of the required inputs to launch Arrays scientific pipelines in Cromwell. WFL is designed to be deployed to run as a service in the cloud, primarily on Kubernetes clusters. For more on Workflow Launcher's role in the Terra infrastructure see Workflow Launcher's role in Terra .","title":"Overview"},{"location":"index.html#quickstart","text":"Tip This is the Quickstart section, which should cover the most frequent uses cases that interact with WFL. For more detailed information, please check other sections such as the development guide or modules design principles .","title":"Quickstart"},{"location":"index.html#build","text":"The easiest way to build WFL is via make , in addition, the following prerequisites are needed: The Docker daemon Clojure ( brew install clojure on macOS) Python3 ( brew install python@3.9 on macOS) NodeJS ( brew install node on macOS) Google Cloud SDK ( brew install --cask google-cloud-sdk on macOS) Arch Linux tips Install clojure from the official repository. Install google-cloud-sdk from the AUR. You could then invoke make at the project level to test and build all workflow-launcher modules: $ make -j8 where 8 can be replaced by any number that represents the concurrent jobs you wish to run. Info If the version of your make is above GNU Make 4.0 (you could check by running make --version ), it's highly recommended to use --output-sync along with -j so the standard outputs are sorted, i.e. $ make -j8 --output-sync make will build each module in workflow-launcher , run tests and generate Docker images. All generated files go into a derived directory under the project root. You can also invoke make on a module from the top level directory by $ make [ MODULE ] TARGET ={ prebuild | build | check | images | clean | distclean } where currently available MODULE s are {api functions/aou docs helm ui} For most of the time, you would want to run something like: $ make clean to clean up the built modules ( -j8 is also available for make clean ). and then run: $ make ui api TARGET = images -j8 to only build the WFL and its docker images without running tests. Info Note if you updated the second party repositories such as pipeline-config or gotc-deploy , you might have to run: $ make distclean to remove them. This is not always needed but can help completely purge the local derived files.","title":"Build"},{"location":"index.html#test","text":"If you only want to run tests on specific modules, you could run: $ make [ MODULE ] TARGET = check such as make api TARGET=check or make functions/aou TARGET=check . Note this automatically makes all of check 's prerequisites.","title":"Test"},{"location":"index.html#clojure-test","text":"When it comes to clojure tests, sometimes it's useful to only run a subset of tests to save time and filter out noise. You can do this by directly invoke clojure cli from within the api directory, for example, cd api and: $ clojure -M:test integration --focus wfl.integration.modules.copyfile-test In general, we implement Clojure tests under the test/ root directory and use the kaocha test runner. Test suites use a -test namespace suffix. You can pass extra command line arguments to kaocha , such as the above --focus flag. You can see the full list of options with the following: clojure -M:test --help At present, wfl api has three kinds of test, unit , integration , and system . These can be run via the deps.edn , optionally specifying the kind: clojure -M:test [ unit | integration | system ] Note that the integration tests currently require a little more configuration before they can be run, namely, they require a wfl server running locally: ./ops/server.sh Additionally, there is a custom parallel test runner that can be invoked to help speed up the system tests. Rather than clojure -M:test system you'd just specify the namespace(s) to try to parallelize. clojure -M:parallel-test wfl.system.v1-endpoint-test Info Note for system tests, no matter it's kicked off through clojure -M:test system or clojure -M:parallel-test wfl.system.v1-endpoint-test , you can use an environment variable WFL_CROMWELL_URL to override the default Cromwell instance that's used in the test. For example: WFL_CROMWELL_URL = https://cromwell-gotc-auth.gotc-prod.broadinstitute.org/ clojure -M:parallel-test wfl.system.v1-endpoint-test will tell the test to submit workflows to the \"gotc-prod\" Cromwell instance no matter what the default instance was defined in the test. However, you need to make sure the validity of the Cromwell URL you passed in; certain IAM permissions will also be required in order for Cromwell to execute the testing workflows smoothly.","title":"Clojure Test"},{"location":"index.html#deploy","text":"Currently, we mainly deploy WFL to broad-gotc-dev and broad-gotc-prod projects. When it's time to deploy WFL, for most of the time developers need to release a new version following the steps in Release Guide After which, the developers who have broad VPN connected can go to the Jenkins Page to deploy applicable versions of WFL to various available cloud projects.","title":"Deploy"},{"location":"index.html#implementation","text":"For frontend details, check Frontend Section","title":"Implementation"},{"location":"index.html#top-level-files","text":"After cloning a new WFL repo, the top-level files are: . \u251c\u2500\u2500 api/ - `workflow-launcher` backend \u251c\u2500\u2500 functions/ - cloud functions deployed separately \u251c\u2500\u2500 database/ - database scheme migration changelog and changeset \u251c\u2500\u2500 derived/ - generated artifacts \u251c\u2500\u2500 docs/ - ancillary documentation \u251c\u2500\u2500 helm/ - helm-managed k8s configuration \u251c\u2500\u2500 LICENSE.txt \u251c\u2500\u2500 Makefile - project level` Makefile` \u251c\u2500\u2500 makerules/ - common `Makefile` functionality \u251c\u2500\u2500 ops/ - scripts to support Operations \u251c\u2500\u2500 README.md - symbolic link to docs/md/README.md \u251c\u2500\u2500 ui/ - `workflow-launcher` frontend \u2514\u2500\u2500 version - holds the current semantic version Tip: Run make at least once after cloning the repo to make sure all the necessary files are in place.","title":"Top-level files"},{"location":"index.html#api-module","text":"","title":"api Module"},{"location":"index.html#source-code","text":"The Clojure source code is in the api/src/ directory. The entry point for the WFL executable is the -main function in main.clj . It takes the command line arguments as strings, validates the arguments, then launches the appropriate process. The server.clj file implements the WFL server. The server_debug.clj file adds some tools to aid in debugging the server. Some hacks specific to WFL are in wfl.clj . The build.clj file includes build and deployment code. The debug.clj file defines some macros useful when debugging or logging. The util.clj file contains a few functions and macros used in WFL that are not specific to its function. The environments.clj file defines configuration parameters for different execution contexts. It's a placeholder in this repo but will be loaded in build/deploy time from a private repo. The module/xx.clj file implements a command-line starter for reprocessing eXternal eXomes . The module/wgs.clj file helps implements a command-line starter for reprocessing Whole GenomeS . The module/sg.clj file implements Somatic Genomes support. The module/all.clj file hosts some utilities shared across modules. The metadata.clj file implements a tool to extract metadata from Cromwell that can be archived with the outputs generated by a workflow. The dx.clj file implements miscellaneous pipeline debugging tools. The once.clj file defines some initialization functions mostly supporting authentication. The api/handlers.clj file defines the handler functions used by server. The api/routes.clj file defines the routing strategy for server. Each of the other source files implement an interface to one of the services WFL talks to, and are named accordingly. File Service cromwell.clj Cromwell workflow runner datarepo.clj DSP DataRepo db.clj On-prem and Cloud SQL databases gcs.clj Google Cloud Storage jms.clj Java Message Service queues postgres.clj Cloud SQL postgres databases server.clj the WFL server itself","title":"Source code"},{"location":"index.html#exomes-in-the-cloud-resources","text":"From Hybrid Selection in the Cloud V1 Clients Google Cloud Storage Client Library (Java) Google Cloud Client Library for Java Diagrams Zamboni Overview Sources /Users/tbl/Broad/zamboni/Client/src/scala/org/broadinstitute/zamboni/client/lightning/clp/Lightning.scala /Users/tbl/Broad/picard-private/src/java/edu/mit/broad/picard/lightning /Users/tbl/Broad/gppipeline-devtools/release client /Users/tbl/Broad/gppipeline-devtools/starter control /picard02:/seq/pipeline/gppipeline-devtools/current/defs/prod.defs","title":"Exomes in the Cloud Resources"},{"location":"dev-frontend.html","text":"Workflow Launcher UI \u2693\ufe0e This is the front-end interface of the Workflow Launcher. It is a VueJS based SPA (Single-Page Application) that works as an ordinary client of the Workflow Launcher Server. You could find its position in the following Diagram: Structure \u2693\ufe0e ui \u251c\u2500\u2500 README.md \u251c\u2500\u2500 babel.config.js \u251c\u2500\u2500 package-lock.json \u251c\u2500\u2500 package.json \u251c\u2500\u2500 public/ \u251c\u2500\u2500 src/ \u2502 \u251c\u2500\u2500 App.vue \u2502 \u251c\u2500\u2500 assets/ \u2502 \u251c\u2500\u2500 components/ \u2502 \u251c\u2500\u2500 main.js \u2502 \u251c\u2500\u2500 plugins/ \u2502 \u251c\u2500\u2500 router/ \u2502 \u251c\u2500\u2500 store/ \u2502 \u2514\u2500\u2500 views/ \u2514\u2500\u2500 vue.config.js In the above structure: public/ hosts the template static index HTML file that will be injected. package-*.json files hold various metadata relevant to the project. This file is used to give information to npm that allows it to identify the project as well as handle the project's dependencies. src/ folder hosts the source code of the UI application: App.vue is the main Vue component and it glues all other components together. components/ hosts all reusable Vue components. main.js helps inject some project-wide tools and plugins such as vue-router or vuetify and make them available to all sub components. plugins/ holds plugin components' settgins files. router contains files that register the internal routing table for UI. store/ hosts state files and functions that used by vuex . views/ holds different views or \"pages\" for the single-page application. The views consume the re-usable components here. vue.config.js contains settings for the Vue applicationm, such as the proxy table for local development. Project setup \u2693\ufe0e Quick Start \u2693\ufe0e Run the following command from the workflow-launcher root directory: $ make ui To build the module. You can then execute $ npm serve --prefix = derived/ui to host the page. Notes: 1. For any of the following commands that uses npm , if you prefer to run from the root directory of the WFL repo instead of running from within wfl/ui , please be sure to append --prefix=ui to the npm command you run. 2. When using the environment as configured by make , append --prefix=derived/ui to your npm commands. Install dependencies \u2693\ufe0e After cloning workflow-launcher , run the following command to install the necessary dependencies: $ npm install Compiles and hot-reloads for development \u2693\ufe0e $ npm run serve Compiles and minifies for production \u2693\ufe0e $ npm run build Lints and fixes files \u2693\ufe0e $ npm run lint Development \u2693\ufe0e It makes your life easier if you start the local server while developing on the ui, since you could preview the live changes in your browser. Styles \u2693\ufe0e This project follows and uses Material Design, especilly the Vue implementation of Material Design framework: Vuetify. Please check their docs before adding anything to the front-end. Add new components or views \u2693\ufe0e The development process is pretty straightforward as the above structure diagram shows. Usually you just need to create a new re-usable component under ui/src/components , which follows the Vue file format: <template> <!-- your HTML and template code --> </template> <script> // your JavaScript code following Vue- // component standards </script> <style> /* your CSS styles */ </style> You could either put the component you created in the App.vue directly, or use it in the views under views/ . Note the views files are also components, except they are designed to be specific not reusable. UI states \u2693\ufe0e Sometimes it's inevitable to store some states for components of UI to better control their behaviors, the state files should be added to store/modules/ and get registered in store/index.js . Single Page Routing \u2693\ufe0e The SPA application is achieved by an internal routing in UI. This is controlled by the routing tables in router/ . More refernces \u2693\ufe0e VueJS: https://vuejs.org/v2/guide/ Vuetify: https://vuetifyjs.com/en/ Vue-router: https://router.vuejs.org/","title":"Frontend"},{"location":"dev-frontend.html#workflow-launcher-ui","text":"This is the front-end interface of the Workflow Launcher. It is a VueJS based SPA (Single-Page Application) that works as an ordinary client of the Workflow Launcher Server. You could find its position in the following Diagram:","title":"Workflow Launcher UI"},{"location":"dev-frontend.html#structure","text":"ui \u251c\u2500\u2500 README.md \u251c\u2500\u2500 babel.config.js \u251c\u2500\u2500 package-lock.json \u251c\u2500\u2500 package.json \u251c\u2500\u2500 public/ \u251c\u2500\u2500 src/ \u2502 \u251c\u2500\u2500 App.vue \u2502 \u251c\u2500\u2500 assets/ \u2502 \u251c\u2500\u2500 components/ \u2502 \u251c\u2500\u2500 main.js \u2502 \u251c\u2500\u2500 plugins/ \u2502 \u251c\u2500\u2500 router/ \u2502 \u251c\u2500\u2500 store/ \u2502 \u2514\u2500\u2500 views/ \u2514\u2500\u2500 vue.config.js In the above structure: public/ hosts the template static index HTML file that will be injected. package-*.json files hold various metadata relevant to the project. This file is used to give information to npm that allows it to identify the project as well as handle the project's dependencies. src/ folder hosts the source code of the UI application: App.vue is the main Vue component and it glues all other components together. components/ hosts all reusable Vue components. main.js helps inject some project-wide tools and plugins such as vue-router or vuetify and make them available to all sub components. plugins/ holds plugin components' settgins files. router contains files that register the internal routing table for UI. store/ hosts state files and functions that used by vuex . views/ holds different views or \"pages\" for the single-page application. The views consume the re-usable components here. vue.config.js contains settings for the Vue applicationm, such as the proxy table for local development.","title":"Structure"},{"location":"dev-frontend.html#project-setup","text":"","title":"Project setup"},{"location":"dev-frontend.html#quick-start","text":"Run the following command from the workflow-launcher root directory: $ make ui To build the module. You can then execute $ npm serve --prefix = derived/ui to host the page. Notes: 1. For any of the following commands that uses npm , if you prefer to run from the root directory of the WFL repo instead of running from within wfl/ui , please be sure to append --prefix=ui to the npm command you run. 2. When using the environment as configured by make , append --prefix=derived/ui to your npm commands.","title":"Quick Start"},{"location":"dev-frontend.html#install-dependencies","text":"After cloning workflow-launcher , run the following command to install the necessary dependencies: $ npm install","title":"Install dependencies"},{"location":"dev-frontend.html#compiles-and-hot-reloads-for-development","text":"$ npm run serve","title":"Compiles and hot-reloads for development"},{"location":"dev-frontend.html#compiles-and-minifies-for-production","text":"$ npm run build","title":"Compiles and minifies for production"},{"location":"dev-frontend.html#lints-and-fixes-files","text":"$ npm run lint","title":"Lints and fixes files"},{"location":"dev-frontend.html#development","text":"It makes your life easier if you start the local server while developing on the ui, since you could preview the live changes in your browser.","title":"Development"},{"location":"dev-frontend.html#styles","text":"This project follows and uses Material Design, especilly the Vue implementation of Material Design framework: Vuetify. Please check their docs before adding anything to the front-end.","title":"Styles"},{"location":"dev-frontend.html#add-new-components-or-views","text":"The development process is pretty straightforward as the above structure diagram shows. Usually you just need to create a new re-usable component under ui/src/components , which follows the Vue file format: <template> <!-- your HTML and template code --> </template> <script> // your JavaScript code following Vue- // component standards </script> <style> /* your CSS styles */ </style> You could either put the component you created in the App.vue directly, or use it in the views under views/ . Note the views files are also components, except they are designed to be specific not reusable.","title":"Add new components or views"},{"location":"dev-frontend.html#ui-states","text":"Sometimes it's inevitable to store some states for components of UI to better control their behaviors, the state files should be added to store/modules/ and get registered in store/index.js .","title":"UI states"},{"location":"dev-frontend.html#single-page-routing","text":"The SPA application is achieved by an internal routing in UI. This is controlled by the routing tables in router/ .","title":"Single Page Routing"},{"location":"dev-frontend.html#more-refernces","text":"VueJS: https://vuejs.org/v2/guide/ Vuetify: https://vuetifyjs.com/en/ Vue-router: https://router.vuejs.org/","title":"More refernces"},{"location":"dev-logging.html","text":"WFL Logging \u2693\ufe0e TL;DR \u2693\ufe0e Import clojure.tools.logging :as log and use log/error / log/info etc. clojure.tools.logging uses SLF4J under the hood which in turn uses Log4j2 as its implementation. Below is more detailed information for those interested. Usage \u2693\ufe0e We use clojure.tools.logging aliased to log . Require it like any other dependency: ( ns \"...\" ( :require ... [ clojure.tools.logging :as log ] ... )) ( log/info \"Hello!\" ) Full documentation is available here . Behavior \u2693\ufe0e Currently, all error-level messages are routed to STDERR, and everything else is routed to STDOUT. Thus, to have WFL log everything to a file you'd want to use something like my-command >output.log 2 > & 1 That'll capture both STDOUT and STDERR to the same file. Note that this specific syntax is more universal than just &>output.log . Testing \u2693\ufe0e clojure.tools.logging provides a test namespace . An example of usage is in test/wfl/unit/logging_test.clj , which exists to test that the service loaders are correctly resolving our dependencies. Under the Hood \u2693\ufe0e This section might be a bit verbose but hopefully it won't be too out-of-date since logging setup doesn't change all that much. The key takeaway here is that JVM logging libraries use service loaders and other runtime configuration to find each other. WFL's logging works as follows: clojure.tools.logging is imported and used directly Why clojure.tools.logging? It is Clojure-native so it has intuitive syntax Why not wrap or delegate to it? It already works just as a wrapper to any other logging implementation so wrapping it would duplicate its purpose clojure.tools.logging delegates to SLF4J Why SLF4J? Jetty already uses it, so configuring it ourselves helps keep it quiet SLF4J delegates to Log4j 2 Why delegate? SLF4J is a facade that still needs an implementation to actually log things Why Log4j 2? It is a fair default implementation: highly configurable, well-tested, well-supported Even without making our own wrapper around clojure.tools.logging, we have a lot of flexibility. Suppose Jetty removes their dependency on SLF4J: we could remove our own dependency on SLF4J and clojure.tools.logging would immediately begin interacting directly with Log4j 2.","title":"Logging"},{"location":"dev-logging.html#wfl-logging","text":"","title":"WFL Logging"},{"location":"dev-logging.html#tldr","text":"Import clojure.tools.logging :as log and use log/error / log/info etc. clojure.tools.logging uses SLF4J under the hood which in turn uses Log4j2 as its implementation. Below is more detailed information for those interested.","title":"TL;DR"},{"location":"dev-logging.html#usage","text":"We use clojure.tools.logging aliased to log . Require it like any other dependency: ( ns \"...\" ( :require ... [ clojure.tools.logging :as log ] ... )) ( log/info \"Hello!\" ) Full documentation is available here .","title":"Usage"},{"location":"dev-logging.html#behavior","text":"Currently, all error-level messages are routed to STDERR, and everything else is routed to STDOUT. Thus, to have WFL log everything to a file you'd want to use something like my-command >output.log 2 > & 1 That'll capture both STDOUT and STDERR to the same file. Note that this specific syntax is more universal than just &>output.log .","title":"Behavior"},{"location":"dev-logging.html#testing","text":"clojure.tools.logging provides a test namespace . An example of usage is in test/wfl/unit/logging_test.clj , which exists to test that the service loaders are correctly resolving our dependencies.","title":"Testing"},{"location":"dev-logging.html#under-the-hood","text":"This section might be a bit verbose but hopefully it won't be too out-of-date since logging setup doesn't change all that much. The key takeaway here is that JVM logging libraries use service loaders and other runtime configuration to find each other. WFL's logging works as follows: clojure.tools.logging is imported and used directly Why clojure.tools.logging? It is Clojure-native so it has intuitive syntax Why not wrap or delegate to it? It already works just as a wrapper to any other logging implementation so wrapping it would duplicate its purpose clojure.tools.logging delegates to SLF4J Why SLF4J? Jetty already uses it, so configuring it ourselves helps keep it quiet SLF4J delegates to Log4j 2 Why delegate? SLF4J is a facade that still needs an implementation to actually log things Why Log4j 2? It is a fair default implementation: highly configurable, well-tested, well-supported Even without making our own wrapper around clojure.tools.logging, we have a lot of flexibility. Suppose Jetty removes their dependency on SLF4J: we could remove our own dependency on SLF4J and clojure.tools.logging would immediately begin interacting directly with Log4j 2.","title":"Under the Hood"},{"location":"dev-process.html","text":"Development Process \u2693\ufe0e This is a development process we are tying to standardize within the team and encourage ourselves to follow in most cases. The Swagger page \u2693\ufe0e WFL ships with a Swagger UI that documents all available endpoints. It's available at path /swagger . At present, we cannot hit it directly without logging in first because it is bundled with the UI and not the API. Log into WFL UI, e.g. https://dev-wfl.gotc-dev.broadinstitute.org/login Navigate to /swagger via Swagger API button in top right Tip To access the swagger page locally, you'll need to start a development server and access via the UI. See the development tips below for more information. Development Setup \u2693\ufe0e Clojure development feels very different from Scala and Java development. It even differs markedly from development in other dynamic languages such as Python or Ruby. Get a demonstration from someone familiar with Clojure development before you spend too much time trying to figure things out on your own. Find a local Cursive user for guidance if you like IntelliJ. Rex Wang knows how to use it. Cursive licences are available here . If none are available, free non-commercial licenses are suitable for open-source development. The steps for getting this project set up with very recent versions of IntelliJ differ from Cursive's docs: Tip Run make prebuild before launching IntelliJ as it sets up all libraries and derived resources and sources: make TARGET = prebuild -jN Outside of IntelliJ , clone the repo. Now inside of IntelliJ , import the project. Use the Project Structure window (Help -> Find Action -> Project Structure) to set a JDK as the Project SDK There is also a Calva plugin for Visual Studio Code . I hack Clojure in Emacs using CIDER and nREPL . CIDER is not trivial to set up, but not especially difficult if you are used to Emacs. (I can help if CIDER gives you trouble.) Process \u2693\ufe0e We base feature branches off develop , make pull requests, ask for reviews and merge back to develop on Github. For the release process, please refer to the release guide . Clone the repo git@github.com:broadinstitute/wfl.git Start from the latest copy of the remote develop git checkout develop git pull origin develop Create a feature branch It is highly recommended that you follow the naming convention shown below so JIRA could pick up the branch and link it to our JIRA board. git checkout -b tbl/GH-666-feature-branch-something Start your work, add and commit your changes git add \"README.md\" git commit -m \"Update the readme file.\" [Optional] Rebase onto latest develop if you want to get updates git checkout develop git pull origin develop --ff git checkout tbl/GH-666-feature-branch-something git rebase develop alternatively, you could use the following commands without switching branches: git checkout tbl/GH-666-feature-branch-something git fetch origin develop git merge develop Push branch to Github in the early stage of your development (recommended): git push --set-upstream origin tbl/GH-666-feature-branch-something Create the pull request on Github UI. Be sure to fill out the PR description following the PR template instructions. If the PR is still in development, make sure use the dropdown menu and choose Create draft pull request If the PR is ready for review, click Create pull request . Look for reviewer(s) in the team. Address reviewer comments with more commits. Receive approval from reviewers. Merge the PR. Development Tips \u2693\ufe0e Here are some tips for WFL development. Some of this advice might help when testing Liquibase migration or other changes that affect WFL's Postgres database. setting up a local Postgres \u2693\ufe0e You can test against a local Postgres before running Liquibase or SQL against a shared database in gotc-dev or gasp production. Install Postgres locally. You need version 11 because that is what Google's hosted service supports, and there are differences in the SQL syntax. brew install postgresql@11 Start Postgres. pg_ctl -D /usr/local/var/postgresql@11 start Tip It might be useful to set up some an alias for postgres if you are using zsh, for example: alias pq=\"pg_ctl -D /usr/local/var/postgresql@11\" thus you could use pq start or pq stop to easily spin up and turn down the db. [Optional] Create wfl DB. If you see errors like this when launching a local WFL server or applying liquibase updates: FATAL: database \"wfl\" does not exist You should do as instructed within your terminal: createdb wfl Or to recreate an existing wfl DB: dropdb wfl createdb wfl You are now free to launch a local WFL server pointing to your local DB. Assuming that WFL_POSTGRES_URL in (wfl.environment/defaults) is set to point at a running local Postgres (e.g. jdbc:postgresql:wfl ), running ./ops/server.sh (or however you launch a local WFL server) will connect the server to that running local Postgres. Now any changes to WFL state will affect only your local database. That includes running Liquibase, so don't forget to reset :debug to env before deploying your changes after merging a PR. migrating a database \u2693\ufe0e To change WFL's Postgres database schema, add a changeset XML file in the database/changesets directory. Name the file for a recent or the current date followed by something describing the change. That will ensure that the changesets list in the order in which they apply. Note that the id and logicalFilePath attributes are derived from the changeset's file name. Then add the changeset file to the database/changlog.xml file. Test the changes against a local scratch database . See the next section for suggestions. debugging JDBC SQL \u2693\ufe0e Something seems to swallow SQL exceptions raised by Postgres and the JDBC library. Wrap suspect clojure.java.jdbc calls in wfl.util/do-or-nil to ensure that any exceptions show up in the server logs. debugging API specs \u2693\ufe0e If an API references an undefined spec, HTTP requests and responses might silently fail or the Swagger page will fail to render. Check the clojure.spec.alpha/def s in wfl.api.routes for typos before tearing your hair out. debugging Liquibase locally \u2693\ufe0e Running liquibase update : liquibase --classpath = $( clojure -Spath ) \\ --url = jdbc:postgresql:wfl \\ --changeLogFile = database/changelog.xml \\ --username = $USER update For the above, the username and password need to be correct for the target environment. If you're running a local server with the postgres command above, you don't need a password and can omit it. Otherwise, you may be able to find this data in the Vault entry for the environment's server -- resources/wfl/environments.clj has some environments if you've built locally. You can use --password=$ENV_SOMETHING to supply it. Tip It is more convenient to use the following alias to migrate the database schema from within the api directory: clojure -M:liquibase if you are working with a local database. Override ENVIRONMENT variables for local development \u2693\ufe0e WFL uses src/wfl/api/environment.clj to read and process environment variables. Most of the variables have their default values, which can be overwritten for development purposes. For example, if we want to run system tests in parallel against a local WFL instance, use below under api/ directory: WFL_WFL_URL = http://localhost:3000 clojure -M:parallel-test wfl.system.v1-endpoint-test REPL testing with fixtures. \u2693\ufe0e Now that we're using fixtures, and so on, in our tests, it is no longer good enough to run deftest vars as functions. Running a test like this (test-something) does not set up the necessary fixtures. However, clojure.test/test-vars can run a test with all the surrounding clojure.test mechanism in place. It takes a vector of var s like this. ( comment ( test-vars [ # 'test-something ]))","title":"Development Process and Tips"},{"location":"dev-process.html#development-process","text":"This is a development process we are tying to standardize within the team and encourage ourselves to follow in most cases.","title":"Development Process"},{"location":"dev-process.html#the-swagger-page","text":"WFL ships with a Swagger UI that documents all available endpoints. It's available at path /swagger . At present, we cannot hit it directly without logging in first because it is bundled with the UI and not the API. Log into WFL UI, e.g. https://dev-wfl.gotc-dev.broadinstitute.org/login Navigate to /swagger via Swagger API button in top right Tip To access the swagger page locally, you'll need to start a development server and access via the UI. See the development tips below for more information.","title":"The Swagger page"},{"location":"dev-process.html#development-setup","text":"Clojure development feels very different from Scala and Java development. It even differs markedly from development in other dynamic languages such as Python or Ruby. Get a demonstration from someone familiar with Clojure development before you spend too much time trying to figure things out on your own. Find a local Cursive user for guidance if you like IntelliJ. Rex Wang knows how to use it. Cursive licences are available here . If none are available, free non-commercial licenses are suitable for open-source development. The steps for getting this project set up with very recent versions of IntelliJ differ from Cursive's docs: Tip Run make prebuild before launching IntelliJ as it sets up all libraries and derived resources and sources: make TARGET = prebuild -jN Outside of IntelliJ , clone the repo. Now inside of IntelliJ , import the project. Use the Project Structure window (Help -> Find Action -> Project Structure) to set a JDK as the Project SDK There is also a Calva plugin for Visual Studio Code . I hack Clojure in Emacs using CIDER and nREPL . CIDER is not trivial to set up, but not especially difficult if you are used to Emacs. (I can help if CIDER gives you trouble.)","title":"Development Setup"},{"location":"dev-process.html#process","text":"We base feature branches off develop , make pull requests, ask for reviews and merge back to develop on Github. For the release process, please refer to the release guide . Clone the repo git@github.com:broadinstitute/wfl.git Start from the latest copy of the remote develop git checkout develop git pull origin develop Create a feature branch It is highly recommended that you follow the naming convention shown below so JIRA could pick up the branch and link it to our JIRA board. git checkout -b tbl/GH-666-feature-branch-something Start your work, add and commit your changes git add \"README.md\" git commit -m \"Update the readme file.\" [Optional] Rebase onto latest develop if you want to get updates git checkout develop git pull origin develop --ff git checkout tbl/GH-666-feature-branch-something git rebase develop alternatively, you could use the following commands without switching branches: git checkout tbl/GH-666-feature-branch-something git fetch origin develop git merge develop Push branch to Github in the early stage of your development (recommended): git push --set-upstream origin tbl/GH-666-feature-branch-something Create the pull request on Github UI. Be sure to fill out the PR description following the PR template instructions. If the PR is still in development, make sure use the dropdown menu and choose Create draft pull request If the PR is ready for review, click Create pull request . Look for reviewer(s) in the team. Address reviewer comments with more commits. Receive approval from reviewers. Merge the PR.","title":"Process"},{"location":"dev-process.html#development-tips","text":"Here are some tips for WFL development. Some of this advice might help when testing Liquibase migration or other changes that affect WFL's Postgres database.","title":"Development Tips"},{"location":"dev-process.html#setting-up-a-local-postgres","text":"You can test against a local Postgres before running Liquibase or SQL against a shared database in gotc-dev or gasp production. Install Postgres locally. You need version 11 because that is what Google's hosted service supports, and there are differences in the SQL syntax. brew install postgresql@11 Start Postgres. pg_ctl -D /usr/local/var/postgresql@11 start Tip It might be useful to set up some an alias for postgres if you are using zsh, for example: alias pq=\"pg_ctl -D /usr/local/var/postgresql@11\" thus you could use pq start or pq stop to easily spin up and turn down the db. [Optional] Create wfl DB. If you see errors like this when launching a local WFL server or applying liquibase updates: FATAL: database \"wfl\" does not exist You should do as instructed within your terminal: createdb wfl Or to recreate an existing wfl DB: dropdb wfl createdb wfl You are now free to launch a local WFL server pointing to your local DB. Assuming that WFL_POSTGRES_URL in (wfl.environment/defaults) is set to point at a running local Postgres (e.g. jdbc:postgresql:wfl ), running ./ops/server.sh (or however you launch a local WFL server) will connect the server to that running local Postgres. Now any changes to WFL state will affect only your local database. That includes running Liquibase, so don't forget to reset :debug to env before deploying your changes after merging a PR.","title":"setting up a local Postgres"},{"location":"dev-process.html#migrating-a-database","text":"To change WFL's Postgres database schema, add a changeset XML file in the database/changesets directory. Name the file for a recent or the current date followed by something describing the change. That will ensure that the changesets list in the order in which they apply. Note that the id and logicalFilePath attributes are derived from the changeset's file name. Then add the changeset file to the database/changlog.xml file. Test the changes against a local scratch database . See the next section for suggestions.","title":"migrating a database"},{"location":"dev-process.html#debugging-jdbc-sql","text":"Something seems to swallow SQL exceptions raised by Postgres and the JDBC library. Wrap suspect clojure.java.jdbc calls in wfl.util/do-or-nil to ensure that any exceptions show up in the server logs.","title":"debugging JDBC SQL"},{"location":"dev-process.html#debugging-api-specs","text":"If an API references an undefined spec, HTTP requests and responses might silently fail or the Swagger page will fail to render. Check the clojure.spec.alpha/def s in wfl.api.routes for typos before tearing your hair out.","title":"debugging API specs"},{"location":"dev-process.html#debugging-liquibase-locally","text":"Running liquibase update : liquibase --classpath = $( clojure -Spath ) \\ --url = jdbc:postgresql:wfl \\ --changeLogFile = database/changelog.xml \\ --username = $USER update For the above, the username and password need to be correct for the target environment. If you're running a local server with the postgres command above, you don't need a password and can omit it. Otherwise, you may be able to find this data in the Vault entry for the environment's server -- resources/wfl/environments.clj has some environments if you've built locally. You can use --password=$ENV_SOMETHING to supply it. Tip It is more convenient to use the following alias to migrate the database schema from within the api directory: clojure -M:liquibase if you are working with a local database.","title":"debugging Liquibase locally"},{"location":"dev-process.html#override-environment-variables-for-local-development","text":"WFL uses src/wfl/api/environment.clj to read and process environment variables. Most of the variables have their default values, which can be overwritten for development purposes. For example, if we want to run system tests in parallel against a local WFL instance, use below under api/ directory: WFL_WFL_URL = http://localhost:3000 clojure -M:parallel-test wfl.system.v1-endpoint-test","title":"Override ENVIRONMENT variables for local development"},{"location":"dev-process.html#repl-testing-with-fixtures","text":"Now that we're using fixtures, and so on, in our tests, it is no longer good enough to run deftest vars as functions. Running a test like this (test-something) does not set up the necessary fixtures. However, clojure.test/test-vars can run a test with all the surrounding clojure.test mechanism in place. It takes a vector of var s like this. ( comment ( test-vars [ # 'test-something ]))","title":"REPL testing with fixtures."},{"location":"dev-release.html","text":"Release Process \u2693\ufe0e The main branch contains tagged release commits. We follow a simple process in order to release a new version of WFL: Create a release branch based off develop release branch names follow the convention release/X.Y.Z-rc the version string should match that specified in version Identify and cherry-pick additional commits from develop that you want to release (e.g. late features and bug fixes). Create a release candidate and deploy to a testing environment. See instructions bellow. Bash the release candidate. Add/cherry-pick any bug fixes that result. Create a pull request into main . You will need to run ./ops/cli.py release to generate the changelog for this release (the -d flag can be used to do a dry run without writing to the CHANGELOG.md file). When the PR is approved, merge it into main . The release action will run automatically to build, test and build and push the tagged docker images of WFL to DockerHub . Please merge PRs that have passed all automated tests only. Tip It can take up to 30 minutes for the Github Action to finish! Please be patient! Tip Remember to create a PR to bump the version string in version in develop for the next release, including changes to CHANGELOG.md from the release. Creating a Release Candidate \u2693\ufe0e In this example, we will create a release candidate for vX.Y.Z. We will assume the existence of a release branch release/X.Y.Z-rc . From wfl 's root directory: Ensure your local repository clone is clean $ make distclean Prepare sources $ git checkout release/X.Y.Z-rc $ git pull origin release/X.Y.Z-rc --ff Build the docker images locally $ make TARGET = images Tag the commit and release the images to dockerhub with the release candidate tag. Let us assume that this is the Mth release candidate. $ ./ops/cli.py tag-and-push-images --version = X.Y.Z-rcN Tip You can run make in parallel by adding -jN to the end of your make command, where N is the number of concurrent jobs to run.","title":"Release Process"},{"location":"dev-release.html#release-process","text":"The main branch contains tagged release commits. We follow a simple process in order to release a new version of WFL: Create a release branch based off develop release branch names follow the convention release/X.Y.Z-rc the version string should match that specified in version Identify and cherry-pick additional commits from develop that you want to release (e.g. late features and bug fixes). Create a release candidate and deploy to a testing environment. See instructions bellow. Bash the release candidate. Add/cherry-pick any bug fixes that result. Create a pull request into main . You will need to run ./ops/cli.py release to generate the changelog for this release (the -d flag can be used to do a dry run without writing to the CHANGELOG.md file). When the PR is approved, merge it into main . The release action will run automatically to build, test and build and push the tagged docker images of WFL to DockerHub . Please merge PRs that have passed all automated tests only. Tip It can take up to 30 minutes for the Github Action to finish! Please be patient! Tip Remember to create a PR to bump the version string in version in develop for the next release, including changes to CHANGELOG.md from the release.","title":"Release Process"},{"location":"dev-release.html#creating-a-release-candidate","text":"In this example, we will create a release candidate for vX.Y.Z. We will assume the existence of a release branch release/X.Y.Z-rc . From wfl 's root directory: Ensure your local repository clone is clean $ make distclean Prepare sources $ git checkout release/X.Y.Z-rc $ git pull origin release/X.Y.Z-rc --ff Build the docker images locally $ make TARGET = images Tag the commit and release the images to dockerhub with the release candidate tag. Let us assume that this is the Mth release candidate. $ ./ops/cli.py tag-and-push-images --version = X.Y.Z-rcN Tip You can run make in parallel by adding -jN to the end of your make command, where N is the number of concurrent jobs to run.","title":"Creating a Release Candidate"},{"location":"modules-arrays.html","text":"Arrays module \u2693\ufe0e WorkFlow Launcher (WFL) implements aou-arrays module to support secure and efficient processing of the AllOfUs Arrays samples. This page documents the design principles and assumptions of the module as well as summarizes the general process of module development. aou-arrays module implements arrays workload as a continuous workload , which means all samples are coming in like a continuous stream, and WFL does not make any assumption of how many samples will be in the workload or how to group the samples together: it hands off the workload creation and starting process to its caller. API \u2693\ufe0e aou-arrays module, like others, implements the following multimethod dispatchers : start-workload! add-workload! It supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload POST /api/v1/append_to_aou Append one or more sample(s) to an existing AOU workload, unless stopped Different from the fixed workload types that caller only needs to create a workload with a series of sample inputs and then simply start the workload, aou-arrays module requires the caller to manage the life cycle of a workload on their own in a multi-stage manner: The caller needs to create a workload and specify the type to be AllOfUsArrays , the caller will receive the information of the created workload if everything goes well, one of which is the uuid of the workload. Once the workload information is being reviewed, the caller needs to \"start\" the newly created workload to tell WFL that \"this workload is ready to accept incoming samples\". Without this \"start\" signal WFL will refuse to append any sample to this workload. The caller can append new individual samples to an existing started workload, and these new samples will be analyzed, processed and submitted to Cromwell as long as it has valid information. To give more information, here are some example inputs to the above endpoints: GET /api/v1/workload Request curl 'http://localhost:8080/api/v1/workload' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' GET /api/v1/workload?uuid={uuid} Request curl 'http://localhost:8080/api/v1/workload?uuid=00000000-0000-0000-0000-000000000000' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' GET /api/v1/workload?project={project} Request curl 'http://localhost:8080/api/v1/workload?project=(Test)%20WFL%20Local%20Testing' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' Note project and uuid are optional path parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together. GET /api/v1/workload/{uuid}/workflows Request curl 'http://localhost:8080/api/v1/workload/00000000-0000-0000-0000-000000000000/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) POST /api/v1/create Request curl -X POST 'http://localhost:8080/api/v1/create' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/aou-test-output/\", \"project\": \"Example Project\", \"pipeline\": \"AllOfUsArrays\" }' POST /api/v1/start Request curl -X POST 'http://localhost:8080/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\" }' POST /api/v1/stop Stops the workload from accepting new samples. See also: /api/v1/append_to_aou . Request curl -X POST 'http://localhost:8080/api/v1/stop' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\" }' POST /api/v1/workload/append_to_aou Request curl -X POST 'http://localhost:8080/api/v1/append_to_aou' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\", \"notifications\": [ { \"zcall_thresholds_file\": \"foo\", \"sample_lsid\": \"foo\", \"bead_pool_manifest_file\": \"foo\", \"chip_well_barcode\": \"foo\", \"sample_alias\": \"foo\", \"green_idat_cloud_path\": \"foo\", \"red_idat_cloud_path\": \"foo\", \"cluster_file\": \"foo\", \"reported_gender\": \"foo\", \"gender_cluster_file\": \"foo\", \"params_file\": \"foo\", \"extended_chip_manifest_file\": \"foo\", \"analysis_version_number\": 1 }, { \"zcall_thresholds_file\": \"foo\", \"sample_lsid\": \"foo\", \"bead_pool_manifest_file\": \"foo\", \"chip_well_barcode\": \"foo\", \"sample_alias\": \"foo\", \"green_idat_cloud_path\": \"foo\", \"red_idat_cloud_path\": \"foo\", \"cluster_file\": \"foo\", \"reported_gender\": \"foo\", \"gender_cluster_file\": \"foo\", \"params_file\": \"foo\", \"extended_chip_manifest_file\": \"foo\", \"analysis_version_number\": 5 } ] }' Workload Model \u2693\ufe0e WFL designed the following workload model in order to support the above API and workload submission mechanism. Initially, it has the following schema: List of relations Schema | Name | Type | Owner | Size | Description --------+--------------------------------+----------+----------+------------+------------- public | databasechangelog | table | foo | 16 kB | public | databasechangeloglock | table | foo | 8192 bytes | public | workload | table | foo | 16 kB | public | workload_id_seq | sequence | foo | 8192 bytes | the workload table looks like: id | commit | created | creator | cromwell | finished | input | items | output | pipeline | project | release | started | uuid | version | wdl ----+--------+---------+---------+----------+----------+-------+-------+--------+----------+---------+---------+---------+------+---------+----- (0 rows) Note that different from the fixed workload types, input , output and items are not useful to aou-arrays workload since these fields vary from sample to sample. Any information the caller provided to these fields will stored as placeholders. More importantly, even though id is the primary key here, (pipeline, project, release) works as the unique identifier for arrays workloads, for instance, if there's already a workload with values: (AllOfUsArrays, gotc-dev, Arrays_v1.9) , any further attempts to create a new workload with exact the same values will return the information of this existing workload rather than create a new row. Once the caller successfully creates a new sample, there will be a new row added to the above workload table, and a new table will be created accordingly: List of relations Schema | Name | Type | Owner | Size | Description --------+--------------------------------+----------+----------+------------+------------- public | allofusarrays_000000001 | table | foo | 16 kB | public | allofusarrays_000000001_id_seq | sequence | foo | 8192 bytes | public | databasechangelog | table | foo | 16 kB | public | databasechangeloglock | table | foo | 8192 bytes | public | workload | table | foo | 16 kB | public | workload_id_seq | sequence | foo | 8192 bytes | The allofusarrays_00000000X table has the following fields: id | analysis_version_number | chip_well_barcode | status | updated | uuid ----+-------------------------+-------------------+-----------+-------------------------------+-------------------------------------- 1 | 1 | 0000000000_R01C01 | Succeeded | 2020-07-21 00:00:00.241218-04 | 00000000-0000-0000-0000-000000000000 2 | 5 | 0000000000_R01C01 | Failed | 2020-07-21 00:00:00.028976-04 | 00000000-0000-0000-0000-000000000000 Among which (analysis_version_number, chip_well_barcode) works as the primary key , any new samples that collide with the existing primary-keys will be omitted.","title":"Arrays"},{"location":"modules-arrays.html#arrays-module","text":"WorkFlow Launcher (WFL) implements aou-arrays module to support secure and efficient processing of the AllOfUs Arrays samples. This page documents the design principles and assumptions of the module as well as summarizes the general process of module development. aou-arrays module implements arrays workload as a continuous workload , which means all samples are coming in like a continuous stream, and WFL does not make any assumption of how many samples will be in the workload or how to group the samples together: it hands off the workload creation and starting process to its caller.","title":"Arrays module"},{"location":"modules-arrays.html#api","text":"aou-arrays module, like others, implements the following multimethod dispatchers : start-workload! add-workload! It supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload POST /api/v1/append_to_aou Append one or more sample(s) to an existing AOU workload, unless stopped Different from the fixed workload types that caller only needs to create a workload with a series of sample inputs and then simply start the workload, aou-arrays module requires the caller to manage the life cycle of a workload on their own in a multi-stage manner: The caller needs to create a workload and specify the type to be AllOfUsArrays , the caller will receive the information of the created workload if everything goes well, one of which is the uuid of the workload. Once the workload information is being reviewed, the caller needs to \"start\" the newly created workload to tell WFL that \"this workload is ready to accept incoming samples\". Without this \"start\" signal WFL will refuse to append any sample to this workload. The caller can append new individual samples to an existing started workload, and these new samples will be analyzed, processed and submitted to Cromwell as long as it has valid information. To give more information, here are some example inputs to the above endpoints: GET /api/v1/workload Request curl 'http://localhost:8080/api/v1/workload' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' GET /api/v1/workload?uuid={uuid} Request curl 'http://localhost:8080/api/v1/workload?uuid=00000000-0000-0000-0000-000000000000' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' GET /api/v1/workload?project={project} Request curl 'http://localhost:8080/api/v1/workload?project=(Test)%20WFL%20Local%20Testing' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' Note project and uuid are optional path parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together. GET /api/v1/workload/{uuid}/workflows Request curl 'http://localhost:8080/api/v1/workload/00000000-0000-0000-0000-000000000000/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) POST /api/v1/create Request curl -X POST 'http://localhost:8080/api/v1/create' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/aou-test-output/\", \"project\": \"Example Project\", \"pipeline\": \"AllOfUsArrays\" }' POST /api/v1/start Request curl -X POST 'http://localhost:8080/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\" }' POST /api/v1/stop Stops the workload from accepting new samples. See also: /api/v1/append_to_aou . Request curl -X POST 'http://localhost:8080/api/v1/stop' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\" }' POST /api/v1/workload/append_to_aou Request curl -X POST 'http://localhost:8080/api/v1/append_to_aou' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d $'{ \"uuid\": \"00000000-0000-0000-0000-000000000000\", \"notifications\": [ { \"zcall_thresholds_file\": \"foo\", \"sample_lsid\": \"foo\", \"bead_pool_manifest_file\": \"foo\", \"chip_well_barcode\": \"foo\", \"sample_alias\": \"foo\", \"green_idat_cloud_path\": \"foo\", \"red_idat_cloud_path\": \"foo\", \"cluster_file\": \"foo\", \"reported_gender\": \"foo\", \"gender_cluster_file\": \"foo\", \"params_file\": \"foo\", \"extended_chip_manifest_file\": \"foo\", \"analysis_version_number\": 1 }, { \"zcall_thresholds_file\": \"foo\", \"sample_lsid\": \"foo\", \"bead_pool_manifest_file\": \"foo\", \"chip_well_barcode\": \"foo\", \"sample_alias\": \"foo\", \"green_idat_cloud_path\": \"foo\", \"red_idat_cloud_path\": \"foo\", \"cluster_file\": \"foo\", \"reported_gender\": \"foo\", \"gender_cluster_file\": \"foo\", \"params_file\": \"foo\", \"extended_chip_manifest_file\": \"foo\", \"analysis_version_number\": 5 } ] }'","title":"API"},{"location":"modules-arrays.html#workload-model","text":"WFL designed the following workload model in order to support the above API and workload submission mechanism. Initially, it has the following schema: List of relations Schema | Name | Type | Owner | Size | Description --------+--------------------------------+----------+----------+------------+------------- public | databasechangelog | table | foo | 16 kB | public | databasechangeloglock | table | foo | 8192 bytes | public | workload | table | foo | 16 kB | public | workload_id_seq | sequence | foo | 8192 bytes | the workload table looks like: id | commit | created | creator | cromwell | finished | input | items | output | pipeline | project | release | started | uuid | version | wdl ----+--------+---------+---------+----------+----------+-------+-------+--------+----------+---------+---------+---------+------+---------+----- (0 rows) Note that different from the fixed workload types, input , output and items are not useful to aou-arrays workload since these fields vary from sample to sample. Any information the caller provided to these fields will stored as placeholders. More importantly, even though id is the primary key here, (pipeline, project, release) works as the unique identifier for arrays workloads, for instance, if there's already a workload with values: (AllOfUsArrays, gotc-dev, Arrays_v1.9) , any further attempts to create a new workload with exact the same values will return the information of this existing workload rather than create a new row. Once the caller successfully creates a new sample, there will be a new row added to the above workload table, and a new table will be created accordingly: List of relations Schema | Name | Type | Owner | Size | Description --------+--------------------------------+----------+----------+------------+------------- public | allofusarrays_000000001 | table | foo | 16 kB | public | allofusarrays_000000001_id_seq | sequence | foo | 8192 bytes | public | databasechangelog | table | foo | 16 kB | public | databasechangeloglock | table | foo | 8192 bytes | public | workload | table | foo | 16 kB | public | workload_id_seq | sequence | foo | 8192 bytes | The allofusarrays_00000000X table has the following fields: id | analysis_version_number | chip_well_barcode | status | updated | uuid ----+-------------------------+-------------------+-----------+-------------------------------+-------------------------------------- 1 | 1 | 0000000000_R01C01 | Succeeded | 2020-07-21 00:00:00.241218-04 | 00000000-0000-0000-0000-000000000000 2 | 5 | 0000000000_R01C01 | Failed | 2020-07-21 00:00:00.028976-04 | 00000000-0000-0000-0000-000000000000 Among which (analysis_version_number, chip_well_barcode) works as the primary key , any new samples that collide with the existing primary-keys will be omitted.","title":"Workload Model"},{"location":"modules-external-exome-reprocessing.html","text":"External Exome Reprocessing workload \u2693\ufe0e Inputs \u2693\ufe0e An ExternalExomeReprocessing workload requires the specification of exactly one the following inputs for each workflow: input_bam , OR input_cram Where input_bam and input_cram are GS URLs of the file to reprocess. Note that the input_bam and input_cram inputs should only be used with CRAM and BAM files, respectively. All other WDL inputs are optional - see the output below for all options. Usage \u2693\ufe0e External Exome Reprocessing workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Exome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions. Create Workload: POST /api/v1/create \u2693\ufe0e Create a new workload. Ensure that workflow-launcher and cromwell 's service accounts have at least read access to the input files. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/create' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\", \"pipeline\": \"ExternalExomeReprocessing\", \"project\": \"Example Project\", \"items\": [{ \"inputs\": { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" } }] }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Note that the ExternalExomeReprocessing pipeline supports specifying cromwell \"workflowOptions\" via the options map. See the reference page for more information. Start Workload: POST /api/v1/start \u2693\ufe0e Starts a Cromwell workflow for each item in the workload. If an output already exists in the output bucket for a particular input cram, WFL will not re-submit that workflow. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/start' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{\"uuid\": \"1337254e-f7d8-438d-a2b3-a74b199fee3c\"}' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Stop Workload: POST /api/v1/stop \u2693\ufe0e Included for compatibility with continuous workloads. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/stop' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"started\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"stopped\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Exec Workload: POST /api/v1/exec \u2693\ufe0e Creates and then starts a Cromwell workflow for each item in the workload. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\", \"pipeline\": \"ExternalExomeReprocessing\", \"project\": \"Example Project\", \"items\": [{ \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", } }] }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Query Workload: GET /api/v1/workload?uuid=<uuid> \u2693\ufe0e Queries the WFL database for workloads. Specify the uuid to query for a specific workload. Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?uuid=1337254e-f7d8-438d-a2b3-a74b199fee3c' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }] Query Workload with project: GET /api/v1/workload?project=<project> \u2693\ufe0e Queries the WFL database for workloads. Specify the project name to query for a list of specific workload(s). Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?project=PO-1234' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }] Note project and uuid are optional query parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together. List Workflows in a Workload: GET /api/v1/workload/{uuid}/workflows \u2693\ufe0e Returns the workflows created and managed by the workload with uuid . Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload/1337254e-f7d8-438d-a2b3-a74b199fee3c/workflows' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"status\" : \"Submitted\" , \"updated\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"uuid\" : \"bb0d93e3-1a6a-4816-82d9-713fa58fb235\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"destination_cloud_path\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/8600be1a-48df-4a51-bdba-0044e0af8d33/single_sample/plumbing/truth/develop/20k\" , \"sample_name\" : \"NA12878_PLUMBING\" , \"base_file_name\" : \"NA12878_PLUMBING.cram\" , \"final_gvcf_base_name\" : \"NA12878_PLUMBING.cram\" } }] \"workflows\" lists out each workflow managed by this workload, including their status. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures. A1 External Exome Workload-Request JSON Spec \u2693\ufe0e { \"pipeline\" : \"string\" , \"executor\" : \"string\" , \"output\" : \"string\" , \"project\" : \"string\" , \"common\" : { \"options\" : {}, // see work fl ow - op t io ns \"inputs\" : { \"unmapped_bam_suffix\" : \"string\" , \"cram_ref_fasta\" : \"string\" , \"cram_ref_fasta_index\" : \"string\" , \"bait_set_name\" : \"string\" , \"bait_interval_list\" : \"string\" , \"target_interval_list\" : \"string\" , \"references\" : { \"calling_interval_list\" : \"string\" , \"contamination_sites_bed\" : \"string\" , \"contamination_sites_mu\" : \"string\" , \"contamination_sites_ud\" : \"string\" , \"dbsnp_vcf\" : \"string\" , \"dbsnp_vcf_index\" : \"string\" , \"evaluation_interval_list\" : \"string\" , \"haplotype_database_file\" : \"string\" , \"known_indels_sites_vcfs\" : [ \"string\" ], \"known_indels_sites_indices\" : [ \"string\" ], \"reference_fasta\" : { \"ref_pac\" : \"string\" , \"ref_bwt\" : \"string\" , \"ref_dict\" : \"string\" , \"ref_ann\" : \"string\" , \"ref_fasta_index\" : \"string\" , \"ref_alt\" : \"string\" , \"ref_fasta\" : \"string\" , \"ref_sa\" : \"string\" , \"ref_amb\" : \"string\" } }, \"scatter_settings\" : { \"haplotype_scatter_count\" : \"integer\" , \"break_bands_at_multiples_of\" : \"integer\" }, \"papi_settings\" : { \"agg_preemptible_tries\" : \"integer\" , \"preemptible_tries\" : \"integer\" }, \"fingerprint_genotypes_file\" : \"string\" , \"fingerprint_genotypes_index\" : \"string\" } }, \"items\" : [{ \"options\" : {}, // see work fl ow - op t io ns \"inputs\" : { // required - speci f y ei t her \"input_bam\" or \"input_cram\" \"input_bam\" : \"string\" , \"input_cram\" : \"string\" , // op t io nal i n pu ts \"sample_name\" : \"string\" , \"final_gvcf_base_name\" : \"string\" , \"unmapped_bam_suffix\" : \"string\" , \"cram_ref_fasta\" : \"string\" , \"cram_ref_fasta_index\" : \"string\" , \"bait_set_name\" : \"string\" , \"bait_interval_list\" : \"string\" , \"target_interval_list\" : \"string\" , \"references\" : { \"calling_interval_list\" : \"string\" , \"contamination_sites_bed\" : \"string\" , \"contamination_sites_mu\" : \"string\" , \"contamination_sites_ud\" : \"string\" , \"dbsnp_vcf\" : \"string\" , \"dbsnp_vcf_index\" : \"string\" , \"evaluation_interval_list\" : \"string\" , \"haplotype_database_file\" : \"string\" , \"known_indels_sites_vcfs\" : [ \"string\" ], \"known_indels_sites_indices\" : [ \"string\" ], \"reference_fasta\" : { \"ref_pac\" : \"string\" , \"ref_bwt\" : \"string\" , \"ref_dict\" : \"string\" , \"ref_ann\" : \"string\" , \"ref_fasta_index\" : \"string\" , \"ref_alt\" : \"string\" , \"ref_fasta\" : \"string\" , \"ref_sa\" : \"string\" , \"ref_amb\" : \"string\" } }, \"scatter_settings\" : { \"haplotype_scatter_count\" : \"integer\" , \"break_bands_at_multiples_of\" : \"integer\" }, \"papi_settings\" : { \"agg_preemptible_tries\" : \"integer\" , \"preemptible_tries\" : \"integer\" }, \"fingerprint_genotypes_file\" : \"string\" , \"fingerprint_genotypes_index\" : \"string\" , \"destination_cloud_path\" : \"string\" } }] }","title":"External Exome"},{"location":"modules-external-exome-reprocessing.html#external-exome-reprocessing-workload","text":"","title":"External Exome Reprocessing workload"},{"location":"modules-external-exome-reprocessing.html#inputs","text":"An ExternalExomeReprocessing workload requires the specification of exactly one the following inputs for each workflow: input_bam , OR input_cram Where input_bam and input_cram are GS URLs of the file to reprocess. Note that the input_bam and input_cram inputs should only be used with CRAM and BAM files, respectively. All other WDL inputs are optional - see the output below for all options.","title":"Inputs"},{"location":"modules-external-exome-reprocessing.html#usage","text":"External Exome Reprocessing workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Exome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions.","title":"Usage"},{"location":"modules-external-exome-reprocessing.html#create-workload-post-apiv1create","text":"Create a new workload. Ensure that workflow-launcher and cromwell 's service accounts have at least read access to the input files. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/create' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\", \"pipeline\": \"ExternalExomeReprocessing\", \"project\": \"Example Project\", \"items\": [{ \"inputs\": { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" } }] }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" } Note that the ExternalExomeReprocessing pipeline supports specifying cromwell \"workflowOptions\" via the options map. See the reference page for more information.","title":"Create Workload: POST /api/v1/create"},{"location":"modules-external-exome-reprocessing.html#start-workload-post-apiv1start","text":"Starts a Cromwell workflow for each item in the workload. If an output already exists in the output bucket for a particular input cram, WFL will not re-submit that workflow. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/start' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{\"uuid\": \"1337254e-f7d8-438d-a2b3-a74b199fee3c\"}' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }","title":"Start Workload: POST /api/v1/start"},{"location":"modules-external-exome-reprocessing.html#stop-workload-post-apiv1stop","text":"Included for compatibility with continuous workloads. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/stop' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"started\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"stopped\" : \"YYYY-MM-ddTHH:mm:ssZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }","title":"Stop Workload: POST /api/v1/stop"},{"location":"modules-external-exome-reprocessing.html#exec-workload-post-apiv1exec","text":"Creates and then starts a Cromwell workflow for each item in the workload. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\", \"pipeline\": \"ExternalExomeReprocessing\", \"project\": \"Example Project\", \"items\": [{ \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", } }] }' Response { \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }","title":"Exec Workload: POST /api/v1/exec"},{"location":"modules-external-exome-reprocessing.html#query-workload-get-apiv1workloaduuiduuid","text":"Queries the WFL database for workloads. Specify the uuid to query for a specific workload. Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?uuid=1337254e-f7d8-438d-a2b3-a74b199fee3c' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }]","title":"Query Workload: GET /api/v1/workload?uuid=&lt;uuid&gt;"},{"location":"modules-external-exome-reprocessing.html#query-workload-with-project-get-apiv1workloadprojectproject","text":"Queries the WFL database for workloads. Specify the project name to query for a list of specific workload(s). Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?project=PO-1234' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"creator\" : \"user@domain\" , \"pipeline\" : \"ExternalExomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"release\" : \"ExternalExomeReprocessing_vX.Y.Z\" , \"created\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"started\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/\" , \"commit\" : \"commit-ish\" , \"project\" : \"Example Project\" , \"uuid\" : \"1337254e-f7d8-438d-a2b3-a74b199fee3c\" , \"wdl\" : \"pipelines/broad/reprocessing/external/exome/ExternalExomeReprocessing.wdl\" , \"version\" : \"X.Y.Z\" }] Note project and uuid are optional query parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together.","title":"Query Workload with project: GET /api/v1/workload?project=&lt;project&gt;"},{"location":"modules-external-exome-reprocessing.html#list-workflows-in-a-workload-get-apiv1workloaduuidworkflows","text":"Returns the workflows created and managed by the workload with uuid . Request curl -X GET 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload/1337254e-f7d8-438d-a2b3-a74b199fee3c/workflows' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" Response [{ \"status\" : \"Submitted\" , \"updated\" : \"YYYY-MM-DDTHH:MM:SSZ\" , \"uuid\" : \"bb0d93e3-1a6a-4816-82d9-713fa58fb235\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"destination_cloud_path\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output/8600be1a-48df-4a51-bdba-0044e0af8d33/single_sample/plumbing/truth/develop/20k\" , \"sample_name\" : \"NA12878_PLUMBING\" , \"base_file_name\" : \"NA12878_PLUMBING.cram\" , \"final_gvcf_base_name\" : \"NA12878_PLUMBING.cram\" } }] \"workflows\" lists out each workflow managed by this workload, including their status. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures.","title":"List Workflows in a Workload: GET /api/v1/workload/{uuid}/workflows"},{"location":"modules-external-exome-reprocessing.html#a1-external-exome-workload-request-json-spec","text":"{ \"pipeline\" : \"string\" , \"executor\" : \"string\" , \"output\" : \"string\" , \"project\" : \"string\" , \"common\" : { \"options\" : {}, // see work fl ow - op t io ns \"inputs\" : { \"unmapped_bam_suffix\" : \"string\" , \"cram_ref_fasta\" : \"string\" , \"cram_ref_fasta_index\" : \"string\" , \"bait_set_name\" : \"string\" , \"bait_interval_list\" : \"string\" , \"target_interval_list\" : \"string\" , \"references\" : { \"calling_interval_list\" : \"string\" , \"contamination_sites_bed\" : \"string\" , \"contamination_sites_mu\" : \"string\" , \"contamination_sites_ud\" : \"string\" , \"dbsnp_vcf\" : \"string\" , \"dbsnp_vcf_index\" : \"string\" , \"evaluation_interval_list\" : \"string\" , \"haplotype_database_file\" : \"string\" , \"known_indels_sites_vcfs\" : [ \"string\" ], \"known_indels_sites_indices\" : [ \"string\" ], \"reference_fasta\" : { \"ref_pac\" : \"string\" , \"ref_bwt\" : \"string\" , \"ref_dict\" : \"string\" , \"ref_ann\" : \"string\" , \"ref_fasta_index\" : \"string\" , \"ref_alt\" : \"string\" , \"ref_fasta\" : \"string\" , \"ref_sa\" : \"string\" , \"ref_amb\" : \"string\" } }, \"scatter_settings\" : { \"haplotype_scatter_count\" : \"integer\" , \"break_bands_at_multiples_of\" : \"integer\" }, \"papi_settings\" : { \"agg_preemptible_tries\" : \"integer\" , \"preemptible_tries\" : \"integer\" }, \"fingerprint_genotypes_file\" : \"string\" , \"fingerprint_genotypes_index\" : \"string\" } }, \"items\" : [{ \"options\" : {}, // see work fl ow - op t io ns \"inputs\" : { // required - speci f y ei t her \"input_bam\" or \"input_cram\" \"input_bam\" : \"string\" , \"input_cram\" : \"string\" , // op t io nal i n pu ts \"sample_name\" : \"string\" , \"final_gvcf_base_name\" : \"string\" , \"unmapped_bam_suffix\" : \"string\" , \"cram_ref_fasta\" : \"string\" , \"cram_ref_fasta_index\" : \"string\" , \"bait_set_name\" : \"string\" , \"bait_interval_list\" : \"string\" , \"target_interval_list\" : \"string\" , \"references\" : { \"calling_interval_list\" : \"string\" , \"contamination_sites_bed\" : \"string\" , \"contamination_sites_mu\" : \"string\" , \"contamination_sites_ud\" : \"string\" , \"dbsnp_vcf\" : \"string\" , \"dbsnp_vcf_index\" : \"string\" , \"evaluation_interval_list\" : \"string\" , \"haplotype_database_file\" : \"string\" , \"known_indels_sites_vcfs\" : [ \"string\" ], \"known_indels_sites_indices\" : [ \"string\" ], \"reference_fasta\" : { \"ref_pac\" : \"string\" , \"ref_bwt\" : \"string\" , \"ref_dict\" : \"string\" , \"ref_ann\" : \"string\" , \"ref_fasta_index\" : \"string\" , \"ref_alt\" : \"string\" , \"ref_fasta\" : \"string\" , \"ref_sa\" : \"string\" , \"ref_amb\" : \"string\" } }, \"scatter_settings\" : { \"haplotype_scatter_count\" : \"integer\" , \"break_bands_at_multiples_of\" : \"integer\" }, \"papi_settings\" : { \"agg_preemptible_tries\" : \"integer\" , \"preemptible_tries\" : \"integer\" }, \"fingerprint_genotypes_file\" : \"string\" , \"fingerprint_genotypes_index\" : \"string\" , \"destination_cloud_path\" : \"string\" } }] }","title":"A1 External Exome Workload-Request JSON Spec"},{"location":"modules-general.html","text":"Modules Design Principles and Assumptions \u2693\ufe0e WorkFlow Launcher is responsible for preparing the required workflow WDLs, inputs and options for Cromwell in a large scale. This work involves in inputs validation, pipeline WDL orchestration and Cromwell workflow management. Similar to other WFL modules, the aou-arrays module takes advantage of the workload concept in order to manage workflows efficiently. In general, WFL classify all workloads into 2 categories: continuous and fixed. For instance, aou-arrays module implements arrays workload as a continuous workload, which means all samples are coming in like a continuous stream, and WFL does not make any assumption of how many samples will be in the workload or how to group the samples together: it hands off the workload creation and starting process to its caller. wgs module implements External Whole Genome workloads as a discrete workload that WFL has full knowledge about the number and properties of the samples it's going to process, and the samples can be grouped into batches (workloads) by a set of properties. To learn more about the details of each module, please check their own sections in this documentation. Create a workload \u2693\ufe0e Defining a workload type usually requires these top-level parameters. Parameter Type Required executor URL output URL prefix pipeline pipeline project text common object input URL prefix items object The parameters are used this way. The executor URL specifies the Cromwell instance or other execution engine to service the workload . The output URL prefix specifies the path you'd like WFL to dump the results to. It usually is a gs bucket. The pipeline enumeration implicitly identifies a data schema for the inputs to and outputs from the workload. You can think of it as the kind of workflow specified for the workload. People sometimes refer to this as the tag in that it is a well-known name for a Cromwell pipeline defined in WDL. You might also think of pipeline as the external or official name of a WFL processing module. The project is just some text to identify a researcher, billing entity, or cost object responsible for the workload. The common is something common for all of the samples, such as the workflow options. For more details, check the docs for the specific type of workload you are trying to submit. The input URL prefix specifies the path you'd like WFL to read (a batch of) sample(s) from. It usually is a gs bucket. The items is used to configure individual units of a workload. You can use it to tell WFL to treat arbitrary parts of the workload sepcially. For more details, check the docs for the specific type of workload you are trying to submit.","title":"Overview"},{"location":"modules-general.html#modules-design-principles-and-assumptions","text":"WorkFlow Launcher is responsible for preparing the required workflow WDLs, inputs and options for Cromwell in a large scale. This work involves in inputs validation, pipeline WDL orchestration and Cromwell workflow management. Similar to other WFL modules, the aou-arrays module takes advantage of the workload concept in order to manage workflows efficiently. In general, WFL classify all workloads into 2 categories: continuous and fixed. For instance, aou-arrays module implements arrays workload as a continuous workload, which means all samples are coming in like a continuous stream, and WFL does not make any assumption of how many samples will be in the workload or how to group the samples together: it hands off the workload creation and starting process to its caller. wgs module implements External Whole Genome workloads as a discrete workload that WFL has full knowledge about the number and properties of the samples it's going to process, and the samples can be grouped into batches (workloads) by a set of properties. To learn more about the details of each module, please check their own sections in this documentation.","title":"Modules Design Principles and Assumptions"},{"location":"modules-general.html#create-a-workload","text":"Defining a workload type usually requires these top-level parameters. Parameter Type Required executor URL output URL prefix pipeline pipeline project text common object input URL prefix items object The parameters are used this way. The executor URL specifies the Cromwell instance or other execution engine to service the workload . The output URL prefix specifies the path you'd like WFL to dump the results to. It usually is a gs bucket. The pipeline enumeration implicitly identifies a data schema for the inputs to and outputs from the workload. You can think of it as the kind of workflow specified for the workload. People sometimes refer to this as the tag in that it is a well-known name for a Cromwell pipeline defined in WDL. You might also think of pipeline as the external or official name of a WFL processing module. The project is just some text to identify a researcher, billing entity, or cost object responsible for the workload. The common is something common for all of the samples, such as the workflow options. For more details, check the docs for the specific type of workload you are trying to submit. The input URL prefix specifies the path you'd like WFL to read (a batch of) sample(s) from. It usually is a gs bucket. The items is used to configure individual units of a workload. You can use it to tell WFL to treat arbitrary parts of the workload sepcially. For more details, check the docs for the specific type of workload you are trying to submit.","title":"Create a workload"},{"location":"modules-sg.html","text":"GDCWholeGenomeSomaticSingleSample \u2693\ufe0e Inputs \u2693\ufe0e In addition to the standard workload request inputs: executor : URL of the Cromwell service output : GCS URL prefix for output files pipeline : literally \"GDCWholeGenomeSomaticSingleSample\" project : some tracking label you can choose a GDCWholeGenomeSomaticSingleSample workload requires the following inputs for each workflow. base_file_name contamination_vcf_index contamination_vcf cram_ref_fasta_index cram_ref_fasta dbsnp_vcf_index dbsnp_vcf input_cram Here is what those are. base_file_name \u2693\ufe0e The leaf name of a sample input or output path without the . suffix. The base_file_name is usually the same as the sample name and differs in every workflow. contamination_vcf_index and contamination_vcf \u2693\ufe0e These are GCS pathnames of the contamination detection data for the input samples. This commonly depends on the reference genome for the samples, and is shared across all the workflows. cram_ref_fasta_index and cram_ref_fasta \u2693\ufe0e These are GCS pathnames of the reference FASTA to which the input CRAM is aligned. This FASTA is used to expand CRAMs to BAMs and again is generally shared across all the workflows. dbsnp_vcf_index and dbsnp_vcf \u2693\ufe0e These are GCS pathnames of a VCF containing a database of known variants from the reference. As with the contamination and reference FASTA files, typically these are shared across all the workflows. input_cram \u2693\ufe0e This is a GCS pathname to the input CRAM. It's last component will typically be the base_file_name value with \".cram\" appended. The GDCWholeGenomeSomaticSingleSample.wdl workflow definition expects to find a base_file_name.cram.crai file for every base_file_name.cram file specified as an input_cram . Usage \u2693\ufe0e GDCWholeGenomeSomaticSingleSample workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Whole Genome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions. Create Workload: /api/v1/create \u2693\ufe0e Create a WFL workload running in production. Request curl -- loca t io n -- reques t POST \\ h tt ps : //go t c - prod - w fl .go t c - prod.broadi nst i tute .org/api/v 1 /crea te \\ -- header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -- header 'Co ntent - Type : applica t io n /jso n ' \\ -- da ta - raw ' { \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"items\" : [ { \"inputs\" : { \"base_file_name\" : \"27B-6\" , \"contamination_vcf\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz\" , \"contamination_vcf_index\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi\" , \"cram_ref_fasta\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\" , \"cram_ref_fasta_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai\" , \"dbsnp_vcf\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz\" , \"dbsnp_vcf_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz.tbi\" , \"input_cram\" : \"gs://broad-gotc-prod-storage/pipeline/PO-1234/27B-6/v1/27B-6.cram\" }, \"options\" : { \"monitoring_script\" : \"gs://broad-gotc-prod-storage/scripts/monitoring_script.sh\" } } ] } ' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } Note that the GDCWholeGenomeSomaticSingleSample pipeline supports Cromwell workflowOptions via the options map. See the reference page for more information. Start Workload: /api/v1/start \u2693\ufe0e Start all the workflows in the workload. Request curl --location --request POST \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/start \\ --header \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ --header 'Content-Type: application/json' \\ --data-raw '{\"uuid\": \"efb00901-378e-4365-86e7-edd0fbdaaab2\"}' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } Start Workload: /api/v1/start \u2693\ufe0e Included for compatibility with continuous workloads. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/stop' \\ -X \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -X 'Content-Type: application/json' \\ -d '{ \"uuid\": \"efb00901-378e-4365-86e7-edd0fbdaaab2\" }' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"stopped\" : \"2021-04-05T16:02:33Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } Exec Workload: /api/v1/exec \u2693\ufe0e Create a workload, then start every workflow in the workload. Except for the different WFL URI, the request and response are the same as for Create Workload above. curl --location --request POST \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/exec \\ ... and so on ... Query Workload: /api/v1/workload?uuid=<uuid> \u2693\ufe0e Query WFL for a workload by its UUID. Request curl --location --request GET \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?uuid = efb00901-378e-4365-86e7-edd0fbdaaab2 \\ --header 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response A successful response from /api/v1/workload is always an array of workload objects, but specifying a UUID returns only one. [ { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } ] Query Workload with project: /api/v1/workload?project=<project> \u2693\ufe0e Query WFL for all workloads with a specified project label. curl --location --request GET \\ /api/v1/workload?project = wgs-dev \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?project = PO-1234 \\ --header 'Authorization: Bearer ' $( gcloud auth print-access-token ) The response is the same as when specifying a UUID, except the array may contain multiple workload objects that share the same project value. Note A request to the /api/v1/workload endpoint without a project or uuid parameter returns all of the workloads that WFL knows about. That response might be large and take a while to process. List workflows managed by the workload GET /api/v1/workload/{uuid}/workflows \u2693\ufe0e Request curl -X GET '/api/v1/workload/efb00901-378e-4365-86e7-edd0fbdaaab2/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response A successful response from /api/v1/workload/{uuid}/workload is always an array of Cromwell workflows with their statuses. [{ \"status\" : \"Submitted\" , \"updated\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"8c1f586e-036b-4690-87c2-2af5d7e00450\" , \"inputs\" : { \"base_file_name\" : \"27B-6\" , \"contamination_vcf\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz\" , \"contamination_vcf_index\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi\" , \"cram_ref_fasta\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\" , \"cram_ref_fasta_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai\" , \"dbsnp_vcf\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz\" , \"dbsnp_vcf_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz.tbi\" , \"input_cram\" : \"gs://broad-gotc-prod-storage/pipeline/PO-1234/27B-6/v1/27B-6.cram\" }, \"options\" : { \"monitoring_script\" : \"gs://broad-gotc-prod-storage/scripts/monitoring_script.sh\" } }]","title":"Somatic Genomes"},{"location":"modules-sg.html#gdcwholegenomesomaticsinglesample","text":"","title":"GDCWholeGenomeSomaticSingleSample"},{"location":"modules-sg.html#inputs","text":"In addition to the standard workload request inputs: executor : URL of the Cromwell service output : GCS URL prefix for output files pipeline : literally \"GDCWholeGenomeSomaticSingleSample\" project : some tracking label you can choose a GDCWholeGenomeSomaticSingleSample workload requires the following inputs for each workflow. base_file_name contamination_vcf_index contamination_vcf cram_ref_fasta_index cram_ref_fasta dbsnp_vcf_index dbsnp_vcf input_cram Here is what those are.","title":"Inputs"},{"location":"modules-sg.html#base_file_name","text":"The leaf name of a sample input or output path without the . suffix. The base_file_name is usually the same as the sample name and differs in every workflow.","title":"base_file_name"},{"location":"modules-sg.html#contamination_vcf_index-and-contamination_vcf","text":"These are GCS pathnames of the contamination detection data for the input samples. This commonly depends on the reference genome for the samples, and is shared across all the workflows.","title":"contamination_vcf_index and contamination_vcf"},{"location":"modules-sg.html#cram_ref_fasta_index-and-cram_ref_fasta","text":"These are GCS pathnames of the reference FASTA to which the input CRAM is aligned. This FASTA is used to expand CRAMs to BAMs and again is generally shared across all the workflows.","title":"cram_ref_fasta_index and cram_ref_fasta"},{"location":"modules-sg.html#dbsnp_vcf_index-and-dbsnp_vcf","text":"These are GCS pathnames of a VCF containing a database of known variants from the reference. As with the contamination and reference FASTA files, typically these are shared across all the workflows.","title":"dbsnp_vcf_index and dbsnp_vcf"},{"location":"modules-sg.html#input_cram","text":"This is a GCS pathname to the input CRAM. It's last component will typically be the base_file_name value with \".cram\" appended. The GDCWholeGenomeSomaticSingleSample.wdl workflow definition expects to find a base_file_name.cram.crai file for every base_file_name.cram file specified as an input_cram .","title":"input_cram"},{"location":"modules-sg.html#usage","text":"GDCWholeGenomeSomaticSingleSample workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Whole Genome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions.","title":"Usage"},{"location":"modules-sg.html#create-workload-apiv1create","text":"Create a WFL workload running in production. Request curl -- loca t io n -- reques t POST \\ h tt ps : //go t c - prod - w fl .go t c - prod.broadi nst i tute .org/api/v 1 /crea te \\ -- header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -- header 'Co ntent - Type : applica t io n /jso n ' \\ -- da ta - raw ' { \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"items\" : [ { \"inputs\" : { \"base_file_name\" : \"27B-6\" , \"contamination_vcf\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz\" , \"contamination_vcf_index\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi\" , \"cram_ref_fasta\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\" , \"cram_ref_fasta_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai\" , \"dbsnp_vcf\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz\" , \"dbsnp_vcf_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz.tbi\" , \"input_cram\" : \"gs://broad-gotc-prod-storage/pipeline/PO-1234/27B-6/v1/27B-6.cram\" }, \"options\" : { \"monitoring_script\" : \"gs://broad-gotc-prod-storage/scripts/monitoring_script.sh\" } } ] } ' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } Note that the GDCWholeGenomeSomaticSingleSample pipeline supports Cromwell workflowOptions via the options map. See the reference page for more information.","title":"Create Workload: /api/v1/create"},{"location":"modules-sg.html#start-workload-apiv1start","text":"Start all the workflows in the workload. Request curl --location --request POST \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/start \\ --header \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ --header 'Content-Type: application/json' \\ --data-raw '{\"uuid\": \"efb00901-378e-4365-86e7-edd0fbdaaab2\"}' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" }","title":"Start Workload: /api/v1/start"},{"location":"modules-sg.html#start-workload-apiv1start_1","text":"Included for compatibility with continuous workloads. Request curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/stop' \\ -X \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -X 'Content-Type: application/json' \\ -d '{ \"uuid\": \"efb00901-378e-4365-86e7-edd0fbdaaab2\" }' Response { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"stopped\" : \"2021-04-05T16:02:33Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" }","title":"Start Workload: /api/v1/start"},{"location":"modules-sg.html#exec-workload-apiv1exec","text":"Create a workload, then start every workflow in the workload. Except for the different WFL URI, the request and response are the same as for Create Workload above. curl --location --request POST \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/exec \\ ... and so on ...","title":"Exec Workload: /api/v1/exec"},{"location":"modules-sg.html#query-workload-apiv1workloaduuiduuid","text":"Query WFL for a workload by its UUID. Request curl --location --request GET \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?uuid = efb00901-378e-4365-86e7-edd0fbdaaab2 \\ --header 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response A successful response from /api/v1/workload is always an array of workload objects, but specifying a UUID returns only one. [ { \"commit\" : \"477bb195c40cc5f5afb81ca1b57e97c9cc18fa2c\" , \"created\" : \"2021-04-05T16:02:31Z\" , \"creator\" : \"tbl@broadinstitute.org\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\" , \"output\" : \"gs://broad-prod-somatic-genomes-output\" , \"pipeline\" : \"GDCWholeGenomeSomaticSingleSample\" , \"project\" : \"PO-1234\" , \"release\" : \"GDCWholeGenomeSomaticSingleSample_v1.1.0\" , \"started\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"efb00901-378e-4365-86e7-edd0fbdaaab2\" , \"version\" : \"0.7.0\" , \"wdl\" : \"pipelines/broad/dna_seq/somatic/single_sample/wgs/gdc_genome/GDCWholeGenomeSomaticSingleSample.wdl\" } ]","title":"Query Workload: /api/v1/workload?uuid=&lt;uuid&gt;"},{"location":"modules-sg.html#query-workload-with-project-apiv1workloadprojectproject","text":"Query WFL for all workloads with a specified project label. curl --location --request GET \\ /api/v1/workload?project = wgs-dev \\ https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/workload?project = PO-1234 \\ --header 'Authorization: Bearer ' $( gcloud auth print-access-token ) The response is the same as when specifying a UUID, except the array may contain multiple workload objects that share the same project value. Note A request to the /api/v1/workload endpoint without a project or uuid parameter returns all of the workloads that WFL knows about. That response might be large and take a while to process.","title":"Query Workload with project: /api/v1/workload?project=&lt;project&gt;"},{"location":"modules-sg.html#list-workflows-managed-by-the-workload-get-apiv1workloaduuidworkflows","text":"Request curl -X GET '/api/v1/workload/efb00901-378e-4365-86e7-edd0fbdaaab2/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response A successful response from /api/v1/workload/{uuid}/workload is always an array of Cromwell workflows with their statuses. [{ \"status\" : \"Submitted\" , \"updated\" : \"2021-04-05T16:02:32Z\" , \"uuid\" : \"8c1f586e-036b-4690-87c2-2af5d7e00450\" , \"inputs\" : { \"base_file_name\" : \"27B-6\" , \"contamination_vcf\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz\" , \"contamination_vcf_index\" : \"gs://gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi\" , \"cram_ref_fasta\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\" , \"cram_ref_fasta_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai\" , \"dbsnp_vcf\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz\" , \"dbsnp_vcf_index\" : \"gs://gcp-public-data--broad-references/hg38/v0/gdc/dbsnp_144.hg38.vcf.gz.tbi\" , \"input_cram\" : \"gs://broad-gotc-prod-storage/pipeline/PO-1234/27B-6/v1/27B-6.cram\" }, \"options\" : { \"monitoring_script\" : \"gs://broad-gotc-prod-storage/scripts/monitoring_script.sh\" } }]","title":"List workflows managed by the workload GET /api/v1/workload/{uuid}/workflows"},{"location":"modules-wgs.html","text":"ExternalWholeGenomeReprocessing workload \u2693\ufe0e Inputs \u2693\ufe0e An ExternalWholeGenomeReprocessing workload specifies the following inputs for each workflow: input_cram or input_bam (required) base_file_name sample_name final_gvcf_base_name unmapped_bam_suffix reference_fasta_prefix input_cram or input_bam (required) \u2693\ufe0e Absolute GCS file path (like gs://... ) base_file_name \u2693\ufe0e Used for naming intermediate/output files Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension sample_name \u2693\ufe0e Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension final_gvcf_base_name \u2693\ufe0e Path to the final VCF ( .vcf will be added by the WDL) Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension unmapped_bam_suffix \u2693\ufe0e Defaults to .unmapped.bam reference_fasta_prefix \u2693\ufe0e Defaults to gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38 Note that this pipeline supports specifying arbitrary WDL inputs, either at the workload level through common or individually via items . Usage \u2693\ufe0e ExternalWholeGenomeReprocessing workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Whole Genome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions. Create Workload: POST /api/v1/create \u2693\ufe0e Creates a WFL workload. Before processing, confirm that the WFL and Cromwell service accounts have at least read access to the input files. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/create' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"project\": \"PO-1234\", \"items\": [{ \"inputs\": { \"input_cram\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", \"sample_name\": \"TestSample1234\" } }] }' Response { \"creator\" : \"sehsan@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T15:50:01Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" , \"version\" : \"0.7.0\" } Note that the ExternalWholeGenomeReprocessing pipeline supports specifying cromwell \"workflowOptions\" via the options map. See the reference page for more information. Start Workload: POST /api/v1/start \u2693\ufe0e Starts a Cromwell workflow for each item in the workload. If an output already exists in the output bucket for a particular input cram, WFL will not re-submit that workflow. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" }' Response { \"started\" : \"2020-10-05T15:50:51Z\" , \"creator\" : \"username@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T15:50:01Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" , \"version\" : \"0.7.0\" } Stop Workload: POST /api/v1/stop \u2693\ufe0e Included for compatibility with continuous workloads. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" }' Response json { \"started\": \"2020-10-05T15:50:51Z\", \"creator\": \"username@broadinstitute.org\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"release\": \"ExternalWholeGenomeReprocessing_v1.0\", \"created\": \"2020-10-05T15:50:01Z\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"project\": \"PO-1234\", \"commit\": \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\", \"wdl\": \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\", \"input\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\", \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\", \"version\": \"0.7.0\" } Exec Workload: POST /api/v1/exec \u2693\ufe0e Creates and then starts a Cromwell workflow for each item in the workload. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"project\": \"PO-1234\", \"items\": [{ \"inputs\": { \"input_cram\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", \"sample_name\": \"TestSample1234\" } }] }' Response { \"started\" : \"2020-10-05T16:15:32Z\" , \"creator\" : \"username@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T16:15:32Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"3a13f732-9743-47a9-ab83-c467b3bf0ca4\" , \"version\" : \"0.7.0\" } Query Workload: GET /api/v1/workload?uuid=<uuid> \u2693\ufe0e Queries the WFL database for workloads. Specify the uuid to query for a specific workload. Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload?uuid=813e3c38-9c11-4410-9888-435569d91d1d' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"creator\" : \"username\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org/\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-08-27T16:26:59Z\" , \"output\" : \"gs://broad-gotc-dev-zero-test/wgs-test-output\" , \"workflows\" : [ { \"updated\" : \"2020-10-05T16:15:32Z\" , \"uuid\" : \"2c543b29-2db9-4643-b81b-b16a0654c5cc\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } } ], \"project\" : \"wgs-dev\" , \"commit\" : \"d2fc38c61c62c44f4fd4d24bdee3121138e6c09e\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-test-storage/single_sample/plumbing/truth\" , \"uuid\" : \"813e3c38-9c11-4410-9888-435569d91d1d\" , \"version\" : \"0.7.0\" }] Query Workload with project: GET /api/v1/workload?project=<project> \u2693\ufe0e Queries the WFL database for workloads. Specify the project name to query for a list of specific workload(s). Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload?project=wgs-dev' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"creator\" : \"username\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org/\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-08-27T16:26:59Z\" , \"output\" : \"gs://broad-gotc-dev-zero-test/wgs-test-output\" , \"project\" : \"wgs-dev\" , \"commit\" : \"d2fc38c61c62c44f4fd4d24bdee3121138e6c09e\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-test-storage/single_sample/plumbing/truth\" , \"uuid\" : \"813e3c38-9c11-4410-9888-435569d91d1d\" , \"version\" : \"0.7.0\" }] The \"workflows\" field lists out each Cromwell workflow that was started, and includes their status information. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures. Note project and uuid are optional path parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together. List workflows managed by a workload GET /api/v1/workload/{uuid}/workflows \u2693\ufe0e Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload/813e3c38-9c11-4410-9888-435569d91d1d/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"updated\" : \"2020-10-05T16:15:32Z\" , \"uuid\" : \"2c543b29-2db9-4643-b81b-b16a0654c5cc\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } }] The \"workflows\" endpoint lists out each Cromwell workflow that was started, and includes their status information. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures.","title":"Whole Genome"},{"location":"modules-wgs.html#externalwholegenomereprocessing-workload","text":"","title":"ExternalWholeGenomeReprocessing workload"},{"location":"modules-wgs.html#inputs","text":"An ExternalWholeGenomeReprocessing workload specifies the following inputs for each workflow: input_cram or input_bam (required) base_file_name sample_name final_gvcf_base_name unmapped_bam_suffix reference_fasta_prefix","title":"Inputs"},{"location":"modules-wgs.html#input_cram-or-input_bam-required","text":"Absolute GCS file path (like gs://... )","title":"input_cram or input_bam (required)"},{"location":"modules-wgs.html#base_file_name","text":"Used for naming intermediate/output files Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension","title":"base_file_name"},{"location":"modules-wgs.html#sample_name","text":"Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension","title":"sample_name"},{"location":"modules-wgs.html#final_gvcf_base_name","text":"Path to the final VCF ( .vcf will be added by the WDL) Defaults to the filename of the input_cram or input_bam without the .cram or .bam extension","title":"final_gvcf_base_name"},{"location":"modules-wgs.html#unmapped_bam_suffix","text":"Defaults to .unmapped.bam","title":"unmapped_bam_suffix"},{"location":"modules-wgs.html#reference_fasta_prefix","text":"Defaults to gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38 Note that this pipeline supports specifying arbitrary WDL inputs, either at the workload level through common or individually via items .","title":"reference_fasta_prefix"},{"location":"modules-wgs.html#usage","text":"ExternalWholeGenomeReprocessing workload supports the following API endpoints: Verb Endpoint Description GET /api/v1/workload List all workloads, optionally filtering by uuid or project GET /api/v1/workload/{uuid}/workflows List all workflows for a specified workload uuid POST /api/v1/create Create a new workload POST /api/v1/start Start a workload POST /api/v1/stop Stop a running workload POST /api/v1/exec Create and start (execute) a workload Permissions in production External Whole Genome Reprocessing in gotc-prod uses a set of execution projects, please refer to this page when you have questions about permissions.","title":"Usage"},{"location":"modules-wgs.html#create-workload-post-apiv1create","text":"Creates a WFL workload. Before processing, confirm that the WFL and Cromwell service accounts have at least read access to the input files. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/create' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"project\": \"PO-1234\", \"items\": [{ \"inputs\": { \"input_cram\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", \"sample_name\": \"TestSample1234\" } }] }' Response { \"creator\" : \"sehsan@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T15:50:01Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" , \"version\" : \"0.7.0\" } Note that the ExternalWholeGenomeReprocessing pipeline supports specifying cromwell \"workflowOptions\" via the options map. See the reference page for more information.","title":"Create Workload: POST /api/v1/create"},{"location":"modules-wgs.html#start-workload-post-apiv1start","text":"Starts a Cromwell workflow for each item in the workload. If an output already exists in the output bucket for a particular input cram, WFL will not re-submit that workflow. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" }' Response { \"started\" : \"2020-10-05T15:50:51Z\" , \"creator\" : \"username@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T15:50:01Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" , \"version\" : \"0.7.0\" }","title":"Start Workload: POST /api/v1/start"},{"location":"modules-wgs.html#stop-workload-post-apiv1stop","text":"Included for compatibility with continuous workloads. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/start' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\" }' Response json { \"started\": \"2020-10-05T15:50:51Z\", \"creator\": \"username@broadinstitute.org\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"release\": \"ExternalWholeGenomeReprocessing_v1.0\", \"created\": \"2020-10-05T15:50:01Z\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"project\": \"PO-1234\", \"commit\": \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\", \"wdl\": \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\", \"input\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\", \"uuid\": \"74d96a04-fea7-4270-a02b-a319dae2dd5e\", \"version\": \"0.7.0\" }","title":"Stop Workload: POST /api/v1/stop"},{"location":"modules-wgs.html#exec-workload-post-apiv1exec","text":"Creates and then starts a Cromwell workflow for each item in the workload. Request curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) \\ -H 'Content-Type: application/json' \\ -d '{ \"executor\": \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\", \"output\": \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\", \"pipeline\": \"ExternalWholeGenomeReprocessing\", \"project\": \"PO-1234\", \"items\": [{ \"inputs\": { \"input_cram\": \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\", \"sample_name\": \"TestSample1234\" } }] }' Response { \"started\" : \"2020-10-05T16:15:32Z\" , \"creator\" : \"username@broadinstitute.org\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-10-05T16:15:32Z\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"project\" : \"PO-1234\" , \"commit\" : \"d65371ca983b4f0d4fa06868e2946a8e3cab291b\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"uuid\" : \"3a13f732-9743-47a9-ab83-c467b3bf0ca4\" , \"version\" : \"0.7.0\" }","title":"Exec Workload: POST /api/v1/exec"},{"location":"modules-wgs.html#query-workload-get-apiv1workloaduuiduuid","text":"Queries the WFL database for workloads. Specify the uuid to query for a specific workload. Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload?uuid=813e3c38-9c11-4410-9888-435569d91d1d' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"creator\" : \"username\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org/\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-08-27T16:26:59Z\" , \"output\" : \"gs://broad-gotc-dev-zero-test/wgs-test-output\" , \"workflows\" : [ { \"updated\" : \"2020-10-05T16:15:32Z\" , \"uuid\" : \"2c543b29-2db9-4643-b81b-b16a0654c5cc\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } } ], \"project\" : \"wgs-dev\" , \"commit\" : \"d2fc38c61c62c44f4fd4d24bdee3121138e6c09e\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-test-storage/single_sample/plumbing/truth\" , \"uuid\" : \"813e3c38-9c11-4410-9888-435569d91d1d\" , \"version\" : \"0.7.0\" }]","title":"Query Workload: GET /api/v1/workload?uuid=&lt;uuid&gt;"},{"location":"modules-wgs.html#query-workload-with-project-get-apiv1workloadprojectproject","text":"Queries the WFL database for workloads. Specify the project name to query for a list of specific workload(s). Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload?project=wgs-dev' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"creator\" : \"username\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org/\" , \"release\" : \"ExternalWholeGenomeReprocessing_v1.0\" , \"created\" : \"2020-08-27T16:26:59Z\" , \"output\" : \"gs://broad-gotc-dev-zero-test/wgs-test-output\" , \"project\" : \"wgs-dev\" , \"commit\" : \"d2fc38c61c62c44f4fd4d24bdee3121138e6c09e\" , \"wdl\" : \"pipelines/reprocessing/external/wgs/ExternalWholeGenomeReprocessing.wdl\" , \"input\" : \"gs://broad-gotc-test-storage/single_sample/plumbing/truth\" , \"uuid\" : \"813e3c38-9c11-4410-9888-435569d91d1d\" , \"version\" : \"0.7.0\" }] The \"workflows\" field lists out each Cromwell workflow that was started, and includes their status information. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures. Note project and uuid are optional path parameters to the /api/v1/workload endpoint, hitting this endpoint without them will return all workloads. However, they cannot be specified together.","title":"Query Workload with project: GET /api/v1/workload?project=&lt;project&gt;"},{"location":"modules-wgs.html#list-workflows-managed-by-a-workload-get-apiv1workloaduuidworkflows","text":"Request curl -X GET 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/workload/813e3c38-9c11-4410-9888-435569d91d1d/workflows' \\ -H 'Authorization: Bearer ' $( gcloud auth print-access-token ) Response [{ \"updated\" : \"2020-10-05T16:15:32Z\" , \"uuid\" : \"2c543b29-2db9-4643-b81b-b16a0654c5cc\" , \"inputs\" : { \"input_cram\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth/develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } }] The \"workflows\" endpoint lists out each Cromwell workflow that was started, and includes their status information. It is also possible to use the Job Manager to check workflow progress and easily see information about any workflow failures.","title":"List workflows managed by a workload GET /api/v1/workload/{uuid}/workflows"},{"location":"terra.html","text":"WorkFlow Launcher's Role in Terra \u2693\ufe0e Summary \u2693\ufe0e The Data Sciences Platform (DSP) is building a new system (around Terra ) for storing and processing biological data. The system design includes a Data Repository where data is stored, and a Methods Repository that executably describes transformations on that data. In the new system, the DSP needs something to fulfill the role that Zamboni currently plays in DSP's current infrastructure to support the Genomics Platform (GP). Zamboni watches various queues for messages describing new data and how to process it. Zamboni interprets those messages to dispatch work to workflow engines (running on the premises or in the cloud) and monitors the progress of those workflows. The Zamboni web UI allows users to track the progress of workflows, and enables Ops engineers to debug problems and resume or restart failed workflows. Zamboni can run workflows on both a local Sun Grid Engine (SGE), and on Cromwell on premises and in the cloud. We think that WFL can fill the role of Zamboni in the new data storage and processing system that DSP is developing now. History \u2693\ufe0e WFL began as a project to replace a Zamboni starter , with the old name \"Zero\". A starter is a Zamboni component that brokers messages among the queues that Zamboni watches. It interprets messages queued from a Laboratory Information Management System (LIMS), such as the Mercury web service, and demultiplexes them to other Zamboni queues. Zero was later adapted to manage the reprocessing of the first batch of UK Biobank exomes. It has since been adapted to drive workflows for other projects at the Broad. Zero is unusual in that it usually runs as a stateless command line program without special system privilege, and interfaces with services running both on premises and in Google Cloud. It also manages a processing workload as a set of inputs mapped to outputs instead of tracking the progress of individual sample workflows. A Zero user need only specify a source of inputs, a workflow to run, an execution environment, and an output location. Then each time it is invoked, Zero ensures that workflows are started and retried as needed until an output exists for every input. Zero has recently been adapted again to deploy as a web service under Google App Engine (GAE) though most of the value of Zero is still not available to the server. And now it has the new name WFL. The role of WFL in Terra \u2693\ufe0e Diagrams of the new DSP processing system show a WFL service subscribed to event streams from the Data Repository (DR), with interfaces to both the Data and the Method Repositories. The implication is that something notifies WFL of new data in the Data Repository and WFL determines how to process it somehow. WFL then looks up whatever is required from the Method Repository, calls on other services as necessary to process the data and writes the results back to the DR. There is also, presumably, a web UI to track and debug the workflows managed by WFL. Many details are yet to be worked out. WFL Concepts \u2693\ufe0e WFL is designed around several novel concepts. Manage workloads instead of workflows. This is the biggest difference between Zamboni and Zero (WFL). Zamboni manages workflows whereas WFL manages workloads . Zamboni's unit of work is the workflow . Zamboni manages each workflow separately. A workflow is a transformation specified in WDL or Scala code that succeeds or fails to produce a result. The input to a workflow and its result may consist of multiple files, but they represent a single unit of work managed by a workflow engine such as Cromwell. Zamboni prepares a new workflow for each message it receives by packaging up the input and submitting it to a workflow engine. It then monitors that workflow and reports on its success or failure. WFL manages a workload , which indirectly comprises multiple workflows. Each workflow maps an input to some output, but WFL generally tracks only the inputs and outputs instead of the workflows themselves. Think of a workload as a set of inputs transformed via a workflow engine into a set of outputs. Call that set of outputs the result set . WFL generally does not care whether any individual workflow succeeds or fails. It merely considers all possible inputs specified by the workload, and looks for inputs whose outputs are missing from the result set. If some input lacks an output in the result set, WFL starts a new workflow to process that input. Note: This characterization is unfair to Zamboni. Zamboni also had to manage multiple workflows before the advent of Cromwell and still does when running workflows on SGE. But WFL can take advantage of Cromwell's job management to simplify its implementation. Specify inputs and outputs by general predicates. Each Zamboni message explicitly specifies an input to be processed. Zamboni then starts a workflow for that input and reports its status. Zamboni reports failure so a user can debug and manually succeed , reconsider, or restart the workflow. The output of a successful workflow is not Zamboni's concern. WFL finds inputs by applying a predicate specified by the user subject to some run-time constraint. Then WFL applies a function to each input to find how that input maps to the result set. Another predicate applied to the input, and its output in the result set, determines whether WFL will launch a workflow on that input. Those predicates and function can be anything expressed in a programming language. The run-time constraint is some strings passed on the command line. Minimize user input and decisions at run time. WFL gathers the predicates and mapping functions described above into a module that also knows how to generate everything a workflow engine needs to launch the workflow to process an input into a result output. That module name is one of a few run-time constraints specified by strings in a web form or on a command line. Further constraints are usually one or two of the following: - a processing environment ( `dev` `prod` `pharma5` ), - a file system directory ( `/seq/tng/tbl/` `file://home/tbl/` ), - a cloud object prefix ( `gs://bucket/folder/` `s3://bucket/` ), - a pathname suffix ( `.cram` `.vcf` ), - a spreadsheet ( or JSON , TSV , CSV , XML ) filename - or a count to limit the scope of a predicate . The module interprets the other constraints, determines which processing environments are allowed, and parses any files named accordingly. Maintain provenance. WFL runs out of a single JARfile built entirely from sources pulled from Git repositories. WFL records the Git commit hashes in the JARfile and adds them to every Cromwell workflow it starts. WFL can also preserve the Cromwell metadata alongside any result files generated by the workflow. Run with minimal privilege. Zamboni runs as a service with system account credentials such as picard . WFL is designed to run as whoever invokes it, such as tbl@broadinstitute.org . WFL fetches the users credentials from the environment when invoked from the command line. WFL requires authentication when running as a server, and constructs a JSON Web Token (JWT) to authorize other services as needed. Limit dependencies. WFL depends on a Java runtime, and Gnu make and the Clojure CLI to manage dependencies. Of course, it also pulls in numerous Clojure and Java libraries at build time, and sources WDL files from the warp repository. A programmer need only install Clojure, clone the wfl Git repository, and run make to bootstrap WFL from source. WFL server \u2693\ufe0e The WFL client is a command-line batch program that a person runs intermittently on a laptop or virtual machine (VM). We are working to port the client functions of WFL to a ubiquitous web service (WFL server) running in Google Cloud. That port requires we solve several problems. State The WFL client is a stateless program that relies on consistent command line arguments to provide the constraints needed to drive the input discovery predicates and so on. Each user runs a separate process that lasts only as long as necessary to complete some stage of a workload. The WFL server is shared among all its users and runs continually. Therefore it requires some kind of data store (a database) to maintain the state of each workload across successive connections from web browsers. We intend to use the hosted Postgres service available to GAE applications for this. This work is already underway (GH-573). Authorization The WFL client assumes it runs in an authenticated context. It can pull credentials from the environment on every invocation that requires authorization to a service. The WFL server will also need to authorize services to run as some authenticated user, but cannot assume the credentials are always available, nor that there is a user present to provide them. WFL can already use OAuth2.0 to authenticate users against an identity provider and use the resulting credentials to build a JWT. It can also derive the bearer token required by most of our authorized services from a JWT. But WFL also needs some secure JWT store, so tokens are available to authorize services even when there is no active user connection. It also needs some mechanism to refresh tokens as they expire to support long-running workloads. Workload specification The user of a WFL service needs some way to specify a workload. A workload may be some set of inputs and the kind of workflow to run on them. A WFL client user now specifies a workload with a module name and a constraint . For example, ukb pharma5 110000 gs://broad-ukb/in/ gs://broad-ukb/out/ means find up to 110000 cloud objects with names prefixed with gs://broad-ukb/in/ , process them in the Cromwell set up for pharma5 , and store their outputs under gs://broad-ukb/out/ somewhere. The ukb module knows how to find .aligned.cram files under the gs://broad-ukb/in/ cloud path and set up the WDL and Cromwell dependencies and options necessary to reprocess them into .cram output files. The ukb module also knows how to find the Cromwell deployed to support pharma5 workloads, how to authorize the user to that Cromwell, and how to read any supporting data from other services. And finally, the ukb module knows how to determine which inputs do not yet have outputs under the gs://broad-ukb/out/ cloud path, and do not have workflows running in the pharma5 Cromwell. In an ideal design, this workload specification would integrate conveniently with the Data Repository's subscription or eventing service. In any case though, WFL needs some interface through which a user can specify what needs to be done. Workload management Workloads need to be started, stopped, and monitored somehow. This implies that there is some way to find active or suspended workloads, and affordances for acting on them. Users need some way to monitor the progress of a workload, and to find and debug workloads encountering unacceptable workflow failures. Monitoring and diagnostic code already exists in various WFL modules, but there is no easy way to use them from a web browser. Service interface WFL should be useful to programs other than web browsers. It is easy to imagine Terra users wanting to query WFL for the status of workloads directly without buggy and tedious screen scraping. WFL should at least export a query endpoint for use by other reporting services as well as its own browser interface. It would be nice to provide a familiar JSON or GraphQL query syntax to other services. Browser interface A browser interface should require little in addition to WFL's service interface. Ideally, one should be able to adapt WFL to new workloads via a browser interface without requiring a redeployment.","title":"WorkFlow Launcher's Role in Terra"},{"location":"terra.html#workflow-launchers-role-in-terra","text":"","title":"WorkFlow Launcher's Role in Terra"},{"location":"terra.html#summary","text":"The Data Sciences Platform (DSP) is building a new system (around Terra ) for storing and processing biological data. The system design includes a Data Repository where data is stored, and a Methods Repository that executably describes transformations on that data. In the new system, the DSP needs something to fulfill the role that Zamboni currently plays in DSP's current infrastructure to support the Genomics Platform (GP). Zamboni watches various queues for messages describing new data and how to process it. Zamboni interprets those messages to dispatch work to workflow engines (running on the premises or in the cloud) and monitors the progress of those workflows. The Zamboni web UI allows users to track the progress of workflows, and enables Ops engineers to debug problems and resume or restart failed workflows. Zamboni can run workflows on both a local Sun Grid Engine (SGE), and on Cromwell on premises and in the cloud. We think that WFL can fill the role of Zamboni in the new data storage and processing system that DSP is developing now.","title":"Summary"},{"location":"terra.html#history","text":"WFL began as a project to replace a Zamboni starter , with the old name \"Zero\". A starter is a Zamboni component that brokers messages among the queues that Zamboni watches. It interprets messages queued from a Laboratory Information Management System (LIMS), such as the Mercury web service, and demultiplexes them to other Zamboni queues. Zero was later adapted to manage the reprocessing of the first batch of UK Biobank exomes. It has since been adapted to drive workflows for other projects at the Broad. Zero is unusual in that it usually runs as a stateless command line program without special system privilege, and interfaces with services running both on premises and in Google Cloud. It also manages a processing workload as a set of inputs mapped to outputs instead of tracking the progress of individual sample workflows. A Zero user need only specify a source of inputs, a workflow to run, an execution environment, and an output location. Then each time it is invoked, Zero ensures that workflows are started and retried as needed until an output exists for every input. Zero has recently been adapted again to deploy as a web service under Google App Engine (GAE) though most of the value of Zero is still not available to the server. And now it has the new name WFL.","title":"History"},{"location":"terra.html#the-role-of-wfl-in-terra","text":"Diagrams of the new DSP processing system show a WFL service subscribed to event streams from the Data Repository (DR), with interfaces to both the Data and the Method Repositories. The implication is that something notifies WFL of new data in the Data Repository and WFL determines how to process it somehow. WFL then looks up whatever is required from the Method Repository, calls on other services as necessary to process the data and writes the results back to the DR. There is also, presumably, a web UI to track and debug the workflows managed by WFL. Many details are yet to be worked out.","title":"The role of WFL in Terra"},{"location":"terra.html#wfl-concepts","text":"WFL is designed around several novel concepts. Manage workloads instead of workflows. This is the biggest difference between Zamboni and Zero (WFL). Zamboni manages workflows whereas WFL manages workloads . Zamboni's unit of work is the workflow . Zamboni manages each workflow separately. A workflow is a transformation specified in WDL or Scala code that succeeds or fails to produce a result. The input to a workflow and its result may consist of multiple files, but they represent a single unit of work managed by a workflow engine such as Cromwell. Zamboni prepares a new workflow for each message it receives by packaging up the input and submitting it to a workflow engine. It then monitors that workflow and reports on its success or failure. WFL manages a workload , which indirectly comprises multiple workflows. Each workflow maps an input to some output, but WFL generally tracks only the inputs and outputs instead of the workflows themselves. Think of a workload as a set of inputs transformed via a workflow engine into a set of outputs. Call that set of outputs the result set . WFL generally does not care whether any individual workflow succeeds or fails. It merely considers all possible inputs specified by the workload, and looks for inputs whose outputs are missing from the result set. If some input lacks an output in the result set, WFL starts a new workflow to process that input. Note: This characterization is unfair to Zamboni. Zamboni also had to manage multiple workflows before the advent of Cromwell and still does when running workflows on SGE. But WFL can take advantage of Cromwell's job management to simplify its implementation. Specify inputs and outputs by general predicates. Each Zamboni message explicitly specifies an input to be processed. Zamboni then starts a workflow for that input and reports its status. Zamboni reports failure so a user can debug and manually succeed , reconsider, or restart the workflow. The output of a successful workflow is not Zamboni's concern. WFL finds inputs by applying a predicate specified by the user subject to some run-time constraint. Then WFL applies a function to each input to find how that input maps to the result set. Another predicate applied to the input, and its output in the result set, determines whether WFL will launch a workflow on that input. Those predicates and function can be anything expressed in a programming language. The run-time constraint is some strings passed on the command line. Minimize user input and decisions at run time. WFL gathers the predicates and mapping functions described above into a module that also knows how to generate everything a workflow engine needs to launch the workflow to process an input into a result output. That module name is one of a few run-time constraints specified by strings in a web form or on a command line. Further constraints are usually one or two of the following: - a processing environment ( `dev` `prod` `pharma5` ), - a file system directory ( `/seq/tng/tbl/` `file://home/tbl/` ), - a cloud object prefix ( `gs://bucket/folder/` `s3://bucket/` ), - a pathname suffix ( `.cram` `.vcf` ), - a spreadsheet ( or JSON , TSV , CSV , XML ) filename - or a count to limit the scope of a predicate . The module interprets the other constraints, determines which processing environments are allowed, and parses any files named accordingly. Maintain provenance. WFL runs out of a single JARfile built entirely from sources pulled from Git repositories. WFL records the Git commit hashes in the JARfile and adds them to every Cromwell workflow it starts. WFL can also preserve the Cromwell metadata alongside any result files generated by the workflow. Run with minimal privilege. Zamboni runs as a service with system account credentials such as picard . WFL is designed to run as whoever invokes it, such as tbl@broadinstitute.org . WFL fetches the users credentials from the environment when invoked from the command line. WFL requires authentication when running as a server, and constructs a JSON Web Token (JWT) to authorize other services as needed. Limit dependencies. WFL depends on a Java runtime, and Gnu make and the Clojure CLI to manage dependencies. Of course, it also pulls in numerous Clojure and Java libraries at build time, and sources WDL files from the warp repository. A programmer need only install Clojure, clone the wfl Git repository, and run make to bootstrap WFL from source.","title":"WFL Concepts"},{"location":"terra.html#wfl-server","text":"The WFL client is a command-line batch program that a person runs intermittently on a laptop or virtual machine (VM). We are working to port the client functions of WFL to a ubiquitous web service (WFL server) running in Google Cloud. That port requires we solve several problems. State The WFL client is a stateless program that relies on consistent command line arguments to provide the constraints needed to drive the input discovery predicates and so on. Each user runs a separate process that lasts only as long as necessary to complete some stage of a workload. The WFL server is shared among all its users and runs continually. Therefore it requires some kind of data store (a database) to maintain the state of each workload across successive connections from web browsers. We intend to use the hosted Postgres service available to GAE applications for this. This work is already underway (GH-573). Authorization The WFL client assumes it runs in an authenticated context. It can pull credentials from the environment on every invocation that requires authorization to a service. The WFL server will also need to authorize services to run as some authenticated user, but cannot assume the credentials are always available, nor that there is a user present to provide them. WFL can already use OAuth2.0 to authenticate users against an identity provider and use the resulting credentials to build a JWT. It can also derive the bearer token required by most of our authorized services from a JWT. But WFL also needs some secure JWT store, so tokens are available to authorize services even when there is no active user connection. It also needs some mechanism to refresh tokens as they expire to support long-running workloads. Workload specification The user of a WFL service needs some way to specify a workload. A workload may be some set of inputs and the kind of workflow to run on them. A WFL client user now specifies a workload with a module name and a constraint . For example, ukb pharma5 110000 gs://broad-ukb/in/ gs://broad-ukb/out/ means find up to 110000 cloud objects with names prefixed with gs://broad-ukb/in/ , process them in the Cromwell set up for pharma5 , and store their outputs under gs://broad-ukb/out/ somewhere. The ukb module knows how to find .aligned.cram files under the gs://broad-ukb/in/ cloud path and set up the WDL and Cromwell dependencies and options necessary to reprocess them into .cram output files. The ukb module also knows how to find the Cromwell deployed to support pharma5 workloads, how to authorize the user to that Cromwell, and how to read any supporting data from other services. And finally, the ukb module knows how to determine which inputs do not yet have outputs under the gs://broad-ukb/out/ cloud path, and do not have workflows running in the pharma5 Cromwell. In an ideal design, this workload specification would integrate conveniently with the Data Repository's subscription or eventing service. In any case though, WFL needs some interface through which a user can specify what needs to be done. Workload management Workloads need to be started, stopped, and monitored somehow. This implies that there is some way to find active or suspended workloads, and affordances for acting on them. Users need some way to monitor the progress of a workload, and to find and debug workloads encountering unacceptable workflow failures. Monitoring and diagnostic code already exists in various WFL modules, but there is no easy way to use them from a web browser. Service interface WFL should be useful to programs other than web browsers. It is easy to imagine Terra users wanting to query WFL for the status of workloads directly without buggy and tedious screen scraping. WFL should at least export a query endpoint for use by other reporting services as well as its own browser interface. It would be nice to provide a familiar JSON or GraphQL query syntax to other services. Browser interface A browser interface should require little in addition to WFL's service interface. Ideally, one should be able to adapt WFL to new workloads via a browser interface without requiring a redeployment.","title":"WFL server"},{"location":"usage-abort.html","text":"Aborting a WFL Workload \u2693\ufe0e Aborting a workload is done by aborting individual workflows directly with Cromwell. Tip This only works with Cromwell! Don't try this script for things running in Terra, it won't work. Here's a script that can help with that: # Usage: bash abort.sh QUERY [WFL_URL] [THREADS] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is optionally the WFL to abort workflows from # Default is the gotc-prod WFL # THREADS is optionally the number of threads to use to talk to Cromwell # Default is 2 # Usage: bash abort.sh QUERY [WFL_URL] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is the WFL instance to abort workflows from [default: gotc-prod] WFL_URL = \" ${ 2 :- https ://gotc-prod-wfl.gotc-prod.broadinstitute.org } \" AUTH_HEADER = \"Authorization: Bearer $( gcloud auth print-access-token ) \" getWorkloads () { # Query -> [Workload] curl -s -X GET \" ${ WFL_URL } /api/v1/workload? $1 \" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } getWorkflows () { # Workload -> [Workflow] uuid = $( jq -r .uuid <<< \" $1 \" ) curl -s -X GET \" ${ WFL_URL } /api/v1/workload/ ${ uuid } /workflows\" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } mapjq () { jq -c '.[]' <<< \" ${ 2 } \" \\ | while read elem ; do ${ 1 } \" ${ elem } \" ; done \\ | jq '[ .[] ]' } main () { # Query -> () workloads = $( getWorkloads \" ${ 1 } \" ) cromwell = $( jq -r 'map(.executor) | .[0]' <<< \" $WORKLOAD \" ) mapjq getWorkflows \" ${ workloads } \" | jq -s 'flatten | map(select(.status != \"Failed\" and .status != \"Succeeded\") | .uuid) | .[]' \\ | xargs -I % -n 1 -P ${ 3 :- 2 } curl -w \"\\n\" -s -X POST \" $CROMWELL /api/workflows/v1/%/abort\" \\ -H \" ${ AUTH_HEADER } \" \\ -H \"Content-Type: application/json\" } main \" $1 \" The 'QUERY' part is like you'd pass to retry.sh . You don't necessarily need to query WFL for the workload. As of this writing, the response from /start or /exec includes the workflow UUIDs, so if you stored that response in WORKLOAD then you could abort it without having to query WFL (and trigger WFL's potentially lengthy update process).","title":"Aborting a Workload"},{"location":"usage-abort.html#aborting-a-wfl-workload","text":"Aborting a workload is done by aborting individual workflows directly with Cromwell. Tip This only works with Cromwell! Don't try this script for things running in Terra, it won't work. Here's a script that can help with that: # Usage: bash abort.sh QUERY [WFL_URL] [THREADS] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is optionally the WFL to abort workflows from # Default is the gotc-prod WFL # THREADS is optionally the number of threads to use to talk to Cromwell # Default is 2 # Usage: bash abort.sh QUERY [WFL_URL] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is the WFL instance to abort workflows from [default: gotc-prod] WFL_URL = \" ${ 2 :- https ://gotc-prod-wfl.gotc-prod.broadinstitute.org } \" AUTH_HEADER = \"Authorization: Bearer $( gcloud auth print-access-token ) \" getWorkloads () { # Query -> [Workload] curl -s -X GET \" ${ WFL_URL } /api/v1/workload? $1 \" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } getWorkflows () { # Workload -> [Workflow] uuid = $( jq -r .uuid <<< \" $1 \" ) curl -s -X GET \" ${ WFL_URL } /api/v1/workload/ ${ uuid } /workflows\" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } mapjq () { jq -c '.[]' <<< \" ${ 2 } \" \\ | while read elem ; do ${ 1 } \" ${ elem } \" ; done \\ | jq '[ .[] ]' } main () { # Query -> () workloads = $( getWorkloads \" ${ 1 } \" ) cromwell = $( jq -r 'map(.executor) | .[0]' <<< \" $WORKLOAD \" ) mapjq getWorkflows \" ${ workloads } \" | jq -s 'flatten | map(select(.status != \"Failed\" and .status != \"Succeeded\") | .uuid) | .[]' \\ | xargs -I % -n 1 -P ${ 3 :- 2 } curl -w \"\\n\" -s -X POST \" $CROMWELL /api/workflows/v1/%/abort\" \\ -H \" ${ AUTH_HEADER } \" \\ -H \"Content-Type: application/json\" } main \" $1 \" The 'QUERY' part is like you'd pass to retry.sh . You don't necessarily need to query WFL for the workload. As of this writing, the response from /start or /exec includes the workflow UUIDs, so if you stored that response in WORKLOAD then you could abort it without having to query WFL (and trigger WFL's potentially lengthy update process).","title":"Aborting a WFL Workload"},{"location":"usage-across-directory.html","text":"Using WFL Across a Directory \u2693\ufe0e WFL supports starting workflows from a single file each--depending on the pipeline you specify, other inputs will be extrapolated (see WFL's docs for the specific pipeline for more information). If you have a set of files uploaded to a GCS bucket and you'd like to start a workflow for each one, you can do that via shell scripting. Suppose we have a set of CRAMs in a folder in some bucket, and we'd like to submit them all to WFL for ExternalExomeReprocessing (perhaps associated with some project or ticket, maybe PO-1234). We'll write a short bash script that will handle this for us. Tip Make sure you're able to list the files yourself! You'll need permissions and you may need to run gcloud auth login Step 1: List Files \u2693\ufe0e We need a list of all the files you intend to process. This'll depend on the file location, gs://broad-gotc-dev-wfl-ptc-test-inputs/ for example. We can use wildcards to list out the individual files we'd like. Make some scratch file like script.sh and store the list of CRAMs in a variable: # In script.sh CRAMS = $( gsutil ls 'gs://broad-gotc-dev-wfl-ptc-test-inputs/**.cram' ) Step 2: Format Items \u2693\ufe0e First, we need to turn that string output into an actual list of file paths. We can use jq to split into lines and select ones that are paths: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))' <<< \" $CRAMS \" ) Next, we need to format each of those file paths into inputs. WFL doesn't just accept a list of files because we allow configuration of many other inputs and options. ITEMS = $( jq 'map({ inputs: { input_cram: .} })' <<< \" $FILES \" ) Info If you want to process BAMs, you'll need to use input_bam instead of input_cram above. Step 3: Make Request \u2693\ufe0e Now, we can simply insert those items into a normal ExternalExomeReprocessing workload request: REQUEST = $( jq '{ cromwell: \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", output: \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output\", pipeline: \"ExternalExomeReprocessing\", project: \"PO-1234\", items: . }' <<< \" $ITEMS \" ) Info Remember to change the output bucket! And the project isn't used by WFL but we keep track of it to help you organize workloads based on tickets or anything else. Info You can make other customizations here too, like specifying some input or option across all the workflows by adding a common block. See the docs for your pipeline or the workflow options page for more info. Last, we can use curl to send off the request to WFL: curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \" $REQUEST \" Warning Curl will complain if the $REQUEST here contains more than thousand lines of data. Remember to dump the payload to a file such as payload.json and let Curl read from that file instead in that case. For example, the last step can be replaced by: echo \" $REQUEST \" >> \"payload.json\" curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \"@payload.json\" With this, the final result is something like the following: CRAMS = $( gsutil ls 'gs://broad-gotc-dev-wfl-ptc-test-inputs/**.cram' ) FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))' <<< \" $CRAMS \" ) ITEMS = $( jq 'map({ inputs: { input_cram: .} })' <<< \" $FILES \" ) REQUEST = $( jq '{ cromwell: \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", output: \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output\", pipeline: \"ExternalExomeReprocessing\", project: \"PO-1234\", items: . }' <<< \" $ITEMS \" ) curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \" $REQUEST \" Save that as script.sh and run with bash myscript.sh and you should be good to go! Other Notes \u2693\ufe0e Have a lot of workflows to submit? You can use array slicing to help split things up: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))[0:5000]' <<< \" $CRAMS \" ) Need to select files matching some other query too? You can chain the map - select commands and use other string filters on the file names: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\"))) | map(select(contains(\"foobar\")))' <<< \" $CRAMS \" ) If contains / startswith / endswith aren't enough, you can use test with PCRE regex: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\"))) | map(select(test(\"fo+bar\")))' <<< \" $CRAMS \" ) See this page for more jq info .","title":"Usage Across a Directory"},{"location":"usage-across-directory.html#using-wfl-across-a-directory","text":"WFL supports starting workflows from a single file each--depending on the pipeline you specify, other inputs will be extrapolated (see WFL's docs for the specific pipeline for more information). If you have a set of files uploaded to a GCS bucket and you'd like to start a workflow for each one, you can do that via shell scripting. Suppose we have a set of CRAMs in a folder in some bucket, and we'd like to submit them all to WFL for ExternalExomeReprocessing (perhaps associated with some project or ticket, maybe PO-1234). We'll write a short bash script that will handle this for us. Tip Make sure you're able to list the files yourself! You'll need permissions and you may need to run gcloud auth login","title":"Using WFL Across a Directory"},{"location":"usage-across-directory.html#step-1-list-files","text":"We need a list of all the files you intend to process. This'll depend on the file location, gs://broad-gotc-dev-wfl-ptc-test-inputs/ for example. We can use wildcards to list out the individual files we'd like. Make some scratch file like script.sh and store the list of CRAMs in a variable: # In script.sh CRAMS = $( gsutil ls 'gs://broad-gotc-dev-wfl-ptc-test-inputs/**.cram' )","title":"Step 1: List Files"},{"location":"usage-across-directory.html#step-2-format-items","text":"First, we need to turn that string output into an actual list of file paths. We can use jq to split into lines and select ones that are paths: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))' <<< \" $CRAMS \" ) Next, we need to format each of those file paths into inputs. WFL doesn't just accept a list of files because we allow configuration of many other inputs and options. ITEMS = $( jq 'map({ inputs: { input_cram: .} })' <<< \" $FILES \" ) Info If you want to process BAMs, you'll need to use input_bam instead of input_cram above.","title":"Step 2: Format Items"},{"location":"usage-across-directory.html#step-3-make-request","text":"Now, we can simply insert those items into a normal ExternalExomeReprocessing workload request: REQUEST = $( jq '{ cromwell: \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", output: \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output\", pipeline: \"ExternalExomeReprocessing\", project: \"PO-1234\", items: . }' <<< \" $ITEMS \" ) Info Remember to change the output bucket! And the project isn't used by WFL but we keep track of it to help you organize workloads based on tickets or anything else. Info You can make other customizations here too, like specifying some input or option across all the workflows by adding a common block. See the docs for your pipeline or the workflow options page for more info. Last, we can use curl to send off the request to WFL: curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \" $REQUEST \" Warning Curl will complain if the $REQUEST here contains more than thousand lines of data. Remember to dump the payload to a file such as payload.json and let Curl read from that file instead in that case. For example, the last step can be replaced by: echo \" $REQUEST \" >> \"payload.json\" curl -X POST 'https://dev-wfl.gotc-dev.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \"@payload.json\" With this, the final result is something like the following: CRAMS = $( gsutil ls 'gs://broad-gotc-dev-wfl-ptc-test-inputs/**.cram' ) FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))' <<< \" $CRAMS \" ) ITEMS = $( jq 'map({ inputs: { input_cram: .} })' <<< \" $FILES \" ) REQUEST = $( jq '{ cromwell: \"https://cromwell-gotc-auth.gotc-prod.broadinstitute.org\", output: \"gs://broad-gotc-dev-wfl-ptc-test-outputs/xx-test-output\", pipeline: \"ExternalExomeReprocessing\", project: \"PO-1234\", items: . }' <<< \" $ITEMS \" ) curl -X POST 'https://gotc-prod-wfl.gotc-prod.broadinstitute.org/api/v1/exec' \\ -H \"Authorization: Bearer $( gcloud auth print-access-token ) \" \\ -H 'Content-Type: application/json' \\ -d \" $REQUEST \" Save that as script.sh and run with bash myscript.sh and you should be good to go!","title":"Step 3: Make Request"},{"location":"usage-across-directory.html#other-notes","text":"Have a lot of workflows to submit? You can use array slicing to help split things up: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\")))[0:5000]' <<< \" $CRAMS \" ) Need to select files matching some other query too? You can chain the map - select commands and use other string filters on the file names: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\"))) | map(select(contains(\"foobar\")))' <<< \" $CRAMS \" ) If contains / startswith / endswith aren't enough, you can use test with PCRE regex: FILES = $( jq -sR 'split(\"\\n\") | map(select(startswith(\"gs://\"))) | map(select(test(\"fo+bar\")))' <<< \" $CRAMS \" ) See this page for more jq info .","title":"Other Notes"},{"location":"usage-retry.html","text":"Retrying Failures via WFL \u2693\ufe0e WFL remembers enough about submissions to let you quickly resubmit failed workflows with the same inputs/options as they were originally submitted. All you need is a query string like you'd pass to the /workflows endpoint, either: uuid=<UUID> where <UUID> is the identifier of the specific workload you'd like to retry failures from Ex: uuid=95d536c7-ce3e-4ffc-8c9c-2b9c710d625a project=<PROJECT> where <PROJECT> is the value of the project field of the workloads you'd like to retry Ex: project=PO-29619 With the below script, WFL will find matching workloads and resubmit any unique failures of individual workflows in a new workload (with the same parameters as the originals). Usage: bash retry.sh QUERY Ex: bash retry.sh project=PO-29619 # Usage: bash abort.sh QUERY [WFL_URL] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is the WFL instance to abort workflows from [default: gotc-prod] WFL_URL = \" ${ 2 :- https ://gotc-prod-wfl.gotc-prod.broadinstitute.org } \" AUTH_HEADER = \"Authorization: Bearer $( gcloud auth print-access-token ) \" getWorkloads () { # Query -> [Workload] curl -s -X GET \" ${ WFL_URL } /api/v1/workload? $1 \" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } getWorkflows () { # Workload -> [Workflow] uuid = $( jq -r .uuid <<< \" $1 \" ) curl -s -X GET \" ${ WFL_URL } /api/v1/workload/ ${ uuid } /workflows\" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } removeSucceeded () { # [[Workflow]] -> [Workflow] jq 'flatten | group_by( {inputs: .inputs, options: .options} ) | map( select( all(.status==\"Succeeded\") ) | .[0] | {inputs: .inputs, options: .options} ) | del(.[][] | nulls) ' <<< \" $1 \" } makeRetryRequest () { # [Workload], [Workflow] -> Request jq --argjson 'workflows' \" $2 \" \\ '.[0] | { executor: .executor , input: .input , output: .output , pipeline: .pipeline , project: .project , items: $workflows } | del(.[] | nulls) ' <<< \" $1 \" } mapjq () { jq -c '.[]' <<< \" ${ 2 } \" \\ | while read elem ; do ${ 1 } \" ${ elem } \" ; done \\ | jq -s '[ .[] ]' } main () { # Query -> () workloads = $( getWorkloads \" ${ 1 } \" ) workflows = $( mapjq getWorkflows \" ${ workloads } \" ) toSubmit = $( removeSucceeded \" ${ workflows } \" ) makeRetryRequest \" ${ workloads [0] } \" \" ${ toSubmit } \" > /tmp/retry.json curl -X POST \" ${ WFL_URL } /api/v1/exec\" \\ -H \" ${ AUTH_HEADER } \" \\ -H \"Content-Type: application/json\" \\ -d @/tmp/retry.json } main \" $1 \" Tips \u2693\ufe0e Customizing Inputs/Options \u2693\ufe0e If you want to inject a new input or option into all of the retried workflows, you can do that with a common block. For example, replace this: jq '{ executor: .executor, with this: jq '{ common: { inputs: { \"WholeGenomeReprocessing.WholeGenomeGermlineSingleSample.BamToCram.ValidateCram.memory_multiplier\": 2 } }, executor: .executor, That example uses WFL's arbitrary input feature to bump up the memory multiplier for a particular WGS task. Nested inputs will have periods in them, you'll need to use quotes around it You can't override inputs or options that the workflows originally had (the common block has lower precedence)","title":"Retrying Failures"},{"location":"usage-retry.html#retrying-failures-via-wfl","text":"WFL remembers enough about submissions to let you quickly resubmit failed workflows with the same inputs/options as they were originally submitted. All you need is a query string like you'd pass to the /workflows endpoint, either: uuid=<UUID> where <UUID> is the identifier of the specific workload you'd like to retry failures from Ex: uuid=95d536c7-ce3e-4ffc-8c9c-2b9c710d625a project=<PROJECT> where <PROJECT> is the value of the project field of the workloads you'd like to retry Ex: project=PO-29619 With the below script, WFL will find matching workloads and resubmit any unique failures of individual workflows in a new workload (with the same parameters as the originals). Usage: bash retry.sh QUERY Ex: bash retry.sh project=PO-29619 # Usage: bash abort.sh QUERY [WFL_URL] # QUERY is either like `project=PO-123` or `uuid=1a2b3c4d` # WFL_URL is the WFL instance to abort workflows from [default: gotc-prod] WFL_URL = \" ${ 2 :- https ://gotc-prod-wfl.gotc-prod.broadinstitute.org } \" AUTH_HEADER = \"Authorization: Bearer $( gcloud auth print-access-token ) \" getWorkloads () { # Query -> [Workload] curl -s -X GET \" ${ WFL_URL } /api/v1/workload? $1 \" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } getWorkflows () { # Workload -> [Workflow] uuid = $( jq -r .uuid <<< \" $1 \" ) curl -s -X GET \" ${ WFL_URL } /api/v1/workload/ ${ uuid } /workflows\" \\ -H \" ${ AUTH_HEADER } \" \\ | jq } removeSucceeded () { # [[Workflow]] -> [Workflow] jq 'flatten | group_by( {inputs: .inputs, options: .options} ) | map( select( all(.status==\"Succeeded\") ) | .[0] | {inputs: .inputs, options: .options} ) | del(.[][] | nulls) ' <<< \" $1 \" } makeRetryRequest () { # [Workload], [Workflow] -> Request jq --argjson 'workflows' \" $2 \" \\ '.[0] | { executor: .executor , input: .input , output: .output , pipeline: .pipeline , project: .project , items: $workflows } | del(.[] | nulls) ' <<< \" $1 \" } mapjq () { jq -c '.[]' <<< \" ${ 2 } \" \\ | while read elem ; do ${ 1 } \" ${ elem } \" ; done \\ | jq -s '[ .[] ]' } main () { # Query -> () workloads = $( getWorkloads \" ${ 1 } \" ) workflows = $( mapjq getWorkflows \" ${ workloads } \" ) toSubmit = $( removeSucceeded \" ${ workflows } \" ) makeRetryRequest \" ${ workloads [0] } \" \" ${ toSubmit } \" > /tmp/retry.json curl -X POST \" ${ WFL_URL } /api/v1/exec\" \\ -H \" ${ AUTH_HEADER } \" \\ -H \"Content-Type: application/json\" \\ -d @/tmp/retry.json } main \" $1 \"","title":"Retrying Failures via WFL"},{"location":"usage-retry.html#tips","text":"","title":"Tips"},{"location":"usage-retry.html#customizing-inputsoptions","text":"If you want to inject a new input or option into all of the retried workflows, you can do that with a common block. For example, replace this: jq '{ executor: .executor, with this: jq '{ common: { inputs: { \"WholeGenomeReprocessing.WholeGenomeGermlineSingleSample.BamToCram.ValidateCram.memory_multiplier\": 2 } }, executor: .executor, That example uses WFL's arbitrary input feature to bump up the memory multiplier for a particular WGS task. Nested inputs will have periods in them, you'll need to use quotes around it You can't override inputs or options that the workflows originally had (the common block has lower precedence)","title":"Customizing Inputs/Options"},{"location":"usage-workflow-options.html","text":"Customizing Workflow Options \u2693\ufe0e Tip This page covers customizing workflow options , which are different from the inputs passed to the WDL. Workflow options are interpreted directly by Cromwell, though WDLs can customize them too. For more information see Cromwell's documentation . Another important piece of context for this page is the difference between a workflow that actually gets run on Cromwell versus a workload (a WFL-managed set of individual workflows). Usage \u2693\ufe0e Summary Workflow options are an arbitrary JSON object stored in a key of options Can be provided per-workflow, for an entire workload, or both Optional -- you only need to specify options if you'd like to override something Suppose the following valid workload request that you might POST to /create or /exec : { \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"project\" : \"PO-1234\" , \"items\" : [ { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" } } ] } You may optionally add arbitrary JSON objects as options either for individual workflows, for the entire workload, or both: { \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"project\" : \"PO-1234\" , \"common\" : { \"options\" : { \"write_to_cache\" : false , \"google_project\" : \"broad-google-project\" } }, \"items\" : [ { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-something-execution\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-different-execution\" , \"default_runtime_attributes\" : { \"maxRetries\" : 3 }, \"google_project\" : \"broad-google-project-2\" } } ] } Info This behavior isn't supported for All-of-Us-related processing. To recap, in the above example the following workflow options will be set: \"jes_gcs_root\" will have different values for the different samples \"default_runtime_attributes\" will override the \"maxRetries\" value to be 3 \"write_to_cache\" will be false for all samples \"google_project\" is broad-google-project for the entire workload but is overridden in the second sample to be broad-google-project-2 (providing an option with more granularity gives it higher precedence) In other words, WFL will recursively merge the options objects together to resolve the options for individual workflows. You can see this in WFL's response, which includes all workflow options calculated for each workflow: [{ \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-something-execution\" , \"write_to_cache\" : false , \"google_project\" : \"broad-google-project\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-different-execution\" , \"default_runtime_attributes\" : { \"maxRetries\" : 3 }, \"write_to_cache\" : false , \"google_project\" : \"broad-google-project-2\" } }] One note is that WFL already has some default values it passes for workflow options and you'll see those defaults when you look at the returned options for a given workflow. See below for more information. Behavior \u2693\ufe0e The diagram below lists the different sources of options for a particular workflow. Precedence is from the bottom up, so \"higher\" sources override lower ones. The green \"sources\" are where you may optionally provide configuration via options , the white \"sources\" are where WFL may create and supply options by default, and the gray \"sources\" are outside of WFL's visibility but can still affect the result. WFL supplies its own derived options usually on a per-module basis, meaning different pipelines that make use of different modules may have different options they derive and supply by default. Individual module documentation can help provide more info, as will simply looking at WFL's response from the /create or /exec endpoints, which includes those defaults.","title":"Workflow Options"},{"location":"usage-workflow-options.html#customizing-workflow-options","text":"Tip This page covers customizing workflow options , which are different from the inputs passed to the WDL. Workflow options are interpreted directly by Cromwell, though WDLs can customize them too. For more information see Cromwell's documentation . Another important piece of context for this page is the difference between a workflow that actually gets run on Cromwell versus a workload (a WFL-managed set of individual workflows).","title":"Customizing Workflow Options"},{"location":"usage-workflow-options.html#usage","text":"Summary Workflow options are an arbitrary JSON object stored in a key of options Can be provided per-workflow, for an entire workload, or both Optional -- you only need to specify options if you'd like to override something Suppose the following valid workload request that you might POST to /create or /exec : { \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"project\" : \"PO-1234\" , \"items\" : [ { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" } } ] } You may optionally add arbitrary JSON objects as options either for individual workflows, for the entire workload, or both: { \"executor\" : \"https://cromwell-gotc-auth.gotc-dev.broadinstitute.org\" , \"input\" : \"gs://broad-gotc-dev-wfl-ptc-test-inputs/single_sample/plumbing/truth\" , \"output\" : \"gs://broad-gotc-dev-wfl-ptc-test-outputs/wgs-test-output/\" , \"pipeline\" : \"ExternalWholeGenomeReprocessing\" , \"project\" : \"PO-1234\" , \"common\" : { \"options\" : { \"write_to_cache\" : false , \"google_project\" : \"broad-google-project\" } }, \"items\" : [ { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-something-execution\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-different-execution\" , \"default_runtime_attributes\" : { \"maxRetries\" : 3 }, \"google_project\" : \"broad-google-project-2\" } } ] } Info This behavior isn't supported for All-of-Us-related processing. To recap, in the above example the following workflow options will be set: \"jes_gcs_root\" will have different values for the different samples \"default_runtime_attributes\" will override the \"maxRetries\" value to be 3 \"write_to_cache\" will be false for all samples \"google_project\" is broad-google-project for the entire workload but is overridden in the second sample to be broad-google-project-2 (providing an option with more granularity gives it higher precedence) In other words, WFL will recursively merge the options objects together to resolve the options for individual workflows. You can see this in WFL's response, which includes all workflow options calculated for each workflow: [{ \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample1234\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-something-execution\" , \"write_to_cache\" : false , \"google_project\" : \"broad-google-project\" } }, { \"inputs\" : { \"input_cram\" : \"develop/20k/NA12878_PLUMBING.cram\" , \"sample_name\" : \"TestSample5678\" }, \"options\" : { \"jes_gcs_root\" : \"gs://broad-gotc-different-execution\" , \"default_runtime_attributes\" : { \"maxRetries\" : 3 }, \"write_to_cache\" : false , \"google_project\" : \"broad-google-project-2\" } }] One note is that WFL already has some default values it passes for workflow options and you'll see those defaults when you look at the returned options for a given workflow. See below for more information.","title":"Usage"},{"location":"usage-workflow-options.html#behavior","text":"The diagram below lists the different sources of options for a particular workflow. Precedence is from the bottom up, so \"higher\" sources override lower ones. The green \"sources\" are where you may optionally provide configuration via options , the white \"sources\" are where WFL may create and supply options by default, and the gray \"sources\" are outside of WFL's visibility but can still affect the result. WFL supplies its own derived options usually on a per-module basis, meaning different pipelines that make use of different modules may have different options they derive and supply by default. Individual module documentation can help provide more info, as will simply looking at WFL's response from the /create or /exec endpoints, which includes those defaults.","title":"Behavior"}]}